{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "import xml.dom.minidom as md\n",
    "\n",
    "df_anotation_master = pd.read_csv(r'../csv/annotation_master.csv')\n",
    "anotation_master = df_anotation_master.to_dict()\n",
    "\n",
    "df_user_master = pd.read_csv(r'../csv/user_name_master.csv')\n",
    "user_master = df_user_master.to_dict()\n",
    "\n",
    "class PageDataContainer:\n",
    "    \n",
    "    def __init__(self, df_thread):\n",
    "        #self.tech_topics で使うの変数\n",
    "        cnt_dict = {word: \" \".join(df_thread.talk_text.to_list()).count(word) for word in anotation_master['keyword'].values()}\n",
    "        \n",
    "        #ページタイトルに使用するindex\n",
    "        self.id = 0\n",
    "        #itle_idxから\"Q&A-xxxx\"を設定\n",
    "        self.title = None\n",
    "        #質問したチャンネル名\n",
    "        self.question_channel = None\n",
    "        #質問した日付\n",
    "        self.question_date = None\n",
    "        #質問したメンバーの表示名のタプル\n",
    "        self.question_members = tuple(user for user in df_thread[df_thread.reply_num == 0].user_name)\n",
    "        #回答したメンバーの表示名のタプル\n",
    "        self.answer_members = tuple(user for user in df_thread.user_name.unique() \n",
    "                                             if user != df_thread[df_thread.reply_num == 0].user_name[0])\n",
    "        #会話の中から単語リストに該当する単語のタプル。出現順位順\n",
    "        self.tech_topics = tuple(word_tuple[0] for word_tuple in sorted({k: v for k, v in cnt_dict.items()\n",
    "                                                   if v != 0}.items(), key=lambda x:x[1], reverse=True))\n",
    "        #質問本文\n",
    "        self.question_contains = tuple(text for text in df_thread[df_thread.reply_num == 0].talk_text)\n",
    "        #回答本文\n",
    "        self.answer_contains = tuple(text for text in df_thread[df_thread.reply_num != 0].talk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #できれば実行時の引数として渡したい\n",
    "    input_path = r'../csv/question_talk_data.csv'\n",
    "    output_path = r'../xml/temp.xml'\n",
    "\n",
    "    df_talks = pd.read_csv(input_path)\n",
    "    \n",
    "    for ts in df.thread_ts.unique():\n",
    "        df_thread = df[df.thread_ts == ts].reset_index()\n",
    "        container_list = PageDataContainer(df_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('masso',)\n",
      "()\n",
      "('DX',)\n",
      "('<@URDDX224S>さんがチャンネル名を「03-1-質問-実務」から「03-01-質問-実務」に変更しました。',)\n",
      "()\n",
      "('masso',)\n",
      "()\n",
      "('DX',)\n",
      "('<@URDDX224S>さんがチャンネル名を「03-2-質問-学習」から「03-02-質問-学習」に変更しました。',)\n",
      "()\n",
      "('masso',)\n",
      "('K',)\n",
      "()\n",
      "('ツイート\\n<https://twitter.com/monosoi_akarusa/status/1316139571269169155?s=21|https://twitter.com/monosoi_akarusa/status/1316139571269169155?s=21>\\n(元記事 <https://toyokeizai.net/articles/amp/333980?page=2|独身か有配偶かで異なる男女の｢人生｣の長さ> | <https://toyokeizai.net/articles/amp/333980?page=2| 東洋経済>)\\nと\\nグラフ(添付画像)\\n\\nについて、\\nなんか違和感あるのですが、同じ意見をお持ちの方いらっしゃいますでしょうか？\\nもしいらっしゃいましたら、考え方を教えていただきたいです。\\n\\n\\n個人的に違和感を覚える部分を言語化すると……\\n\\n```\\u202a①「未婚」vs「既婚(有配偶、死別、離別)」の比較なのに、高確率で未婚であろう15〜19歳のデータ含む\\u202c\\n\\n\\u202a②未婚、有配偶、離別、死別で平均年齢が違うはず\\u202c\\n\\u202a(そもそも早死にする人は未婚である確率が高い。逆に長生きする人は結婚する確率も離別・死別する確率も高い。)\\u202c\\n\\n\\u202a③割合じゃなくて人数で出すべきでは？\\u202c\\n\\n\\u202a例えば、グラフより\\u202c\\n\\u202a男性・未婚死亡者・65〜69歳≒17%\\u202c\\n\\u202a男性・有配偶死亡者・80〜84歳≒22%\\u202c\\n\\u202aな訳だが\\u202c\\n\\n\\u202a仮に、\\u202c\\n\\u202a男性・未婚死亡者総数=1万人\\u202c\\n\\u202a男性・有配偶死亡者総数=5千人\\u202c\\n\\u202aとすると、\\u202c\\n\\n\\u202a65〜69歳男性・未婚死亡者総数=1700人\\u202c\\n\\u202a80〜84歳男性・有配偶死亡者総数=1100人となって、\\u202c\\n\\u202aグラフ📈では少なそうに見える方が多くなる。```\\n',)\n",
      "('割り算によって失われる情報、、、', 'タイムリーだ、、 <#CT1S314AG|07-13-輪読会-初級> ')\n",
      "('masso',)\n",
      "()\n",
      "('DX',)\n",
      "('<@URDDX224S>さんがチャンネル名を「03-3-質問-その他」から「03-03-質問-その他」に変更しました。',)\n",
      "()\n",
      "('mory',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('マーケティング', 'GAN', 'API', 'VR', 'レコメンド', 'ML')\n",
      "('以下のような事例を調べています。\\nML×VRの様な。\\nGANやCV系の3Dデータの自動生成系の技術などお詳しい方がいればご教授いただきたいです。\\nNvidia researchとかによくあるのですが。\\n<https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://www.itmedia.co.jp/news/spv/1812/04/news118.html&amp;ved=2ahUKEwiS5baGm5HjAhWoHqYKHeIJDq4QFjAAegQIBRAB&amp;usg=AOvVaw37G-qKqqNvj3VUTJYy1VbN&amp;cshid=1561897895412>',)\n",
      "('SMFなどは少しやっていたのですが、3D画像生成となると、門外漢ですねー。。。\\n\\nどういった用途で使うことを想定されてるんですか？？', '<http://createwith.ai/paper/20170625/831>', 'ここら辺の領域でしょうか？？', 'マーケティングなどに使われるデータ分析、つまり経営判断のためのデータ分析よりUXのためのデータ分析を会社から必要とされてまして、現在リサーチ段階です。', '↑ありがとうございます、参考にさせていただきます！', 'マーケティング、UX改善でGANを使うシーンってあるんですね！！\\n\\n差し支えなければ、どういったユースケースとかって教えて頂くことは可能でしょうか？\\n\\nユースケースに合わせてご回答できればと思います^_^', 'もしかすると会社がわかってしまうかもしれませんが、美容院を検索するときに、髪型の名称をテキストで入力するとそれをイメージした髪型が生成される。などのイメージです。\\n逆に髪型からテキスト生成もありです。\\nすいません3Dでなくてもいいです。\\nマルチモーダルとかのワードも関連してくるかもしれません。', '画像→テキスト\\n\\nであれば、Google Visionが一番ライトかもしれませんね！！\\n\\nこの辺りって、試してみてますか？？', '<https://cloud.google.com/vision/?hl=ja>', 'たしか近いうちに検証する予定だったと思います。\\n費用感含めて調べてみます。\\nありがとうございます！', 'Google  Visonを使うと以下のような機能の実装は出来そうですねー！\\n\\n■ ワード検索\\n写真に関してはGoogle Visionを使って事前にタグ付けをしておく。\\n\\nツーブロック、ベリーショート、などのキーワードで検索して、タグとマッチする画像を表示。\\n\\n\\n■ 画像検索\\nユーザーには、「こんなイメージ」という写真をアップしてもらう。\\n\\nAPIを使用して、画像からタグを抽出してそのタグから検索。\\n\\nスコアが近い場合は「もしかして。。。」的な別タグのレコメンドをする。', '&gt;スコアが近い場合\\nこれとかいいですね！\\nありがとうございます！', 'こういった要件整理みたいなのが得意領域なので、アイディアに困った時は気軽に聞いてくださいー♪', ':smiley_cat:')\n",
      "('はやと-休学中の文系学生',)\n",
      "('れごん-島根のﾌﾘｰﾗﾝｽ',)\n",
      "('AutoML', 'ML', 'API', 'Git')\n",
      "('Signateの参加について、「オープンソースかつ無料のものは使用可能」とありますが、これはautomlは使用可能なんでしょうか？？\\nちなみに自分が言ってるのはグーグルのCloud AutoMLのことです。',)\n",
      "('私の考えですが、Cloud AutoML はオープンソースになっていないので、難しい気がします。\\n\\nライブラリ自体がGithub等でソースコードが公開されているものが、対象になるはずで、\\n<https://github.com/googleapis/google-cloud-python/tree/master/automl> の場合はAPI Clientといって、実際の学習や予測はGoogleの隠されているサーバー上で実行されて、その結果の取得をできるようにしているライブラリなので、中身がオープンソースとして公開されていないと思います。\\n\\nautoml系ですと、Uberが出している、Ludwigとかは学習部分のソースコードも公開されているので、大丈夫なのかなと勝手に思ってます。\\n <https://github.com/uber/ludwig>', 'なるほど、れごんさんありがとうございます！中のサーバーでやってるからオープンソースになってないんですね、、、\\nだしかに、他にもautomlありますしそっちもチャレンジしようと思います！')\n",
      "('相川\\u3000仁',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('slackなかなかわからんので、調べながら調べきれない項目は、ちょいちょい質問することにしました。\\n\\nこれチャンネルが数字順に並んでないんですが、ぼくだけでしょーか？なにか設定したらこの並び順変わるとか？？',)\n",
      "('多分参加してないチャンネルっすね！\\n\\nこのプラスマークを押すと、まだ参加してないチャンネルに登録できます！',)\n",
      "('S',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('Python', 'SQL', 'Treasure Data', 'レコメンド')\n",
      "('データ分析を本業でやられている方々は何を使ってやられていますか？Python: Jupyter notebook? R: RStudio? また、Library/pkgってどんなもの使ってます？それとも一から構築してます？',)\n",
      "('<@UL70KNF4P> \\n直近使ってるものだと、\\n\\n■ 言語\\n・R\\n・python\\n・SQL\\n\\n■ ツール、サービス\\n・Data Robot\\n・tableau\\n・DataPortal\\n・Treasure Data\\n・Bigquery\\n・postgres\\n\\nなどですかねー！\\n\\nRとpythonの使い分けは明確な基準ないのですが、使いたい領域のライブラリググって使いやすそうな方選ぶ事が多いですねー♪', '回答ありがとうございます。ツール・サービスも使われるんですね。あまりpythonやRだけで、データ分析されないんですか？ライブラリは一般的なscikitlearnとかcaretは使用されます？', 'もちろん、使うことはありますよー！！\\n\\nクライアントの状況次第で色々変わってきますし、実務におけるモデル構築の時間って案外少ないような気がします。\\n\\n教師なし学習、レコメンドロジック開発、集計・レポーティングなどの領域をやったりすることも多いので、使うライブラリなども、場合によって全然変わって来ますねー！', 'そうなんですね、私はライブラリに頼りぱなしで、本当にそれで良いものかと思って。でも確かに、やりたいことやれればツールは何でもって感じですかね。\\nどうもありがとうございます。', '利用用途によると思いますが、パッケージメインで使って、行き詰まったら考えるって感じですねー！！\\n\\n自分の場合は、ライトな分析だけな用途ならR、システム化前提ならpythonとすることが多いですね！')\n",
      "('澤祐斗\\u3000東工大3年',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '小竹(fishb)')\n",
      "('SQL', '機械学習', '初学者', 'データサイエンティスト', 'データマイニング', '教科書', '入門', 'kaggle', '可視化', '初心者', '書籍')\n",
      "('こんにちは。\\n自分は機械学習初学者で、ビジネス関連での活用を中心としたデータサイエンティストになりたいと思っています。今後の勉強の方針に関してアドバイスを頂けたらと思います。\\n\\n現在の学習状況は「python機械学習プログラミング 達人データサイエンティストによる理論と実践」 で機械学習を学び、プロゲートでSQL、JSを学んだ程度です。ビジネスサイドの勉強はまだ出来ていないです。\\n\\nまた、機械学習初学者としてこのサロンを通して成長出来た例となり、ここの活性化にも寄与出来たらと思います。 \\n長々とすみません、よろしくお願い致します。',)\n",
      "('質問としては、何から勉強したら良いかって感じですかね？\\n\\nビジネス寄りの学習をしたいのか、プログラミング、SQLの勉強を深掘りしたいのかなどによって、やる内容は変わって来ると思いますー！', '返信ありがとうございます！\\nそうです、独学で周りに見本になる人もいないので、皆さんがどのように勉強してきたかや、良かった参考書やサイト、方法などの勉強方針を教えて頂けたらと思っています。\\n\\nまずはプログラミング、SQLの勉強を深掘りしたいです。自分では本を読んだりkaggleのカーネル読んだりはしていますが力になっているのか分からないです。', '勉強方法としては、基本的に、やりたい事からの逆算の方が、出来た感は強いような気がしますね！！\\n\\n自分はちゃんとした分析をスタートしたのはインターンがきっかけでした。\\n\\nなので、誰かと一緒にプロジェクトなどできると良いかもですね！！\\n\\nそれこそ、雑談チャンネルで上がっているコンペに参加してみるとか！\\n\\nSQLだと、以下の本がおススメです！\\n\\n■ 入門\\n10年戦えるデータ分析入門 SQLを武器にデータ活用時代を生き抜く (Informatics &amp;IDEA) <https://www.amazon.co.jp/dp/4797376279/ref=cm_sw_r_cp_api_i_IU-jDbXA6429Q>\\n\\n■ 中級以降\\n<https://www.amazon.co.jp/dp/4839961263/ref=cm_sw_r_cp_awdb_c_8U-jDb5X990QQ>\\n\\n他の方も、「自分はこんな勉強してるよー」ってシェアをしてみてください:grin:', '自分も初心者なので助かります！', '<@UKPAM2942> \\n学習の距離感が近いと思うので、「この教材がタメになった」という話などを共有しても良いと思います！\\n\\n自分の例だという5年前とかの話になっちゃうので、今ならもっと良い方法あるかもですし^_^', 'そうですね\\n自分も積極的に情報発信したいと思います。\\n\\n上記2冊は色んな人が勧めているのを見るのでやっぱりこれなのか、という感じです。「レシピ」の方は買ったまま積ん読になってたので読まないと･･･\\n\\nSQLって、書籍や講座のテストデータ扱ってても、「この量ならExcelで吐き出して処理して戻した方が早くね？」とか思っちゃうんですよね。実データを扱う状況に放り込まれたらイヤでも向き合うと思うんですが･･･\\n\\n自分は「SQLなにそれ？」って状態で\\n<https://www.udemy.com/standard-sql-for-beginners/>\\nの動画を見て手を動かしました。\\nちなみにudemyはしょっちゅうセールをやってるので、1800円以上の時は絶対買っちゃダメです（笑）', '<@UJRAL005U> ありがとうございます！！\\n最初は足を引っ張るとは思いますが積極的に参加させてもらえたらと思います！\\nおススメの本の紹介すごくありがたいです、購入させていただきます！', '上記はSQLにフォーカスした場合ですが、基礎固めや、全体感を掴むという意味では、以下の3冊がおススメです！\\n\\n今後、全くの初学者に対しては、「とりあえずこれ読めばOK」って話そうかと思ってます。\\n\\n■ ビジネス、コンサル領域基礎\\n仕事の説明書\\n<https://www.amazon.co.jp/dp/4991087007/ref=cm_sw_r_cp_awdb_c_a0akDbMSJD3V9>\\n\\n■ データマイニングエンジニアの基礎\\nデータマイニングエンジニアの教科書\\n<https://www.amazon.co.jp/dp/4863542704/ref=cm_sw_r_cp_awdb_c_p2akDb3QYB3DT>\\n\\n■ 可視化の基礎\\nデータビジュアライゼーションの教科書\\n<https://www.amazon.co.jp/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%93%E3%82%B8%E3%83%A5%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8-%E8%97%A4-%E4%BF%8A%E4%B9%85%E4%BB%81/dp/4798053481>', 'あざます！\\n「データビジュアライゼーション～」は買ったばっかりだった。もう2冊も読んでみようッと。', 'ビジュアライゼーションは、分析者1年目でよく言われる事を詰め込んだような内容になってまよね！\\n\\n査読した友達に聞いたのですが、「社員に読ますために書いた」っていう話だったので、現場の人が書いてる本は実践的ですね。', 'ありがとうございます！\\n先にこの三冊から読んでいこうと思います！')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('SQL', 'BI', 'クロス集計')\n",
      "('アクセスログの解析で何かこれはやっているというところありますか？地味に継続率を指標にクロス集計を山のようにしていますが答えが見えないですw',)\n",
      "('目的は、継続率に効く要因を知りたいって感じでしょうか？', 'そうですね。継続しているユーザーと離脱しているユーザーの違いですね。ECではないので因子が少ない', 'とりあえず鉄板な所としては、こんな感じですかね？\\n\\n・流入経路、流入時期でセグメント切る\\n\\n・説明変数が多い時はとりあえず決定木系のアルゴリズムにかけて、変数重要度が高いやつをちゃんと見る\\n\\n・退会ユーザー or 継続ユーザーの行動分析（RFMとか）', '素直に決定木ですかねー。結局 特徴量作るSQLをガリガリ書いた方が早いかなー', 'SQLガリガリ書いて、決定木とかは、何かしら結果出る率は高いかと！（誰もが知ってる結果になりやすいので要注意ですがw）', 'あとは、現場の勘と経験マイニングですかねw\\n\\nこれも結構大事で、仮説検証型のアプローチするなら、ヒアリングをかなりガッツリやるのもオススメですねー！', '同じ理由でユーザーインタビューも効果的かと！（これに関しては自分はやったことない）', 'やはりその辺になりますねー。現場の勘所が一番正しかったりするのでw', '王道で行くと、上記に挙げた辺りかなーと！\\n\\nあとは、サービスの質やデータセットの特徴、取れるアクションなど、現場次第かとー！', 'サービス根本の解決ができるのか、デザイン変更や広告戦略変更なのか、出口によっても見る観点変わって来ると思うので！', 'ありがとうございます。\\n先方トップが銀の弾丸見つけて状態・・・探せず心労。', 'その状況はツラいですね。。。', 'プランABCを作って、メリデメ説明して、相手に選ばせるみたいな方法取れば割と納得感は得られたりするんですけどね。', 'う～ん、単価交渉入ったので一旦アウトでもいいかな～と思います。BI環境作らずに基礎分析が何となくわかっている状態でデータ分析でバリュー見つけることできる確率低いな～と改めて痛感。\\nしっかりとステップ踏む重要性感じました。実力足りない。（泣）', '結果出る時はサクッと出たりしますが、出なかった時のツラミは結構ありますよね。。。\\n\\nヒットが出なかった時の戦い方とか、分析とは違う観点ですけど、そういった所も案外大事ですよね。')\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('AI', 'kaggle')\n",
      "('お疲れ様です、カテゴリー化する時の質問です\\n今回の飯田産業コンペのような\\nColumnその他の特徴1\\n特徴1から特徴15までもし特徴があれば\\nColumnその他の特徴2\\n特徴1から特徴15までもし2つ目の特徴があれば\\nColumn その他の特徴3\\n特徴1から特徴15までもし3つ目の特徴があれば\\n\\nこれらの特徴は全てnullの可能性もある、という場合、線形モデルなら0と1で全ての特徴をカテゴリー化すればいいですが、決定木系だと全てカテゴリー化すると特徴量が増えすぎて困ります。なおかつラベルエンコードするとその他の特性1から3の関連を捉えることができない（例えば特徴1がcolum1に入ってるのと特徴1がcolumn2に入っているのは全く同じことなのに、それが反映されないなど）という問題があります。\\n自分としては全てワンホットエンコードした後にPCAなどで次元削減するのが1番なのかなって考えてるんですけど、何かアイデアがあれば教えて下さると嬉しいです！もし分かりにくかったらすみません:man-bowing:',)\n",
      "('決定木系の場合で特徴量が増えたらマズい理由って、なんでしたっけ？\\n\\n裏の処理ではフラグ化されてるけど、カテゴリ化した上で特徴量として使えば良いような気もします。\\n\\n<https://blog.amedama.jp/entry/2018/06/05/231703>', 'あ、カテゴリ化は検討してるのか。', '村上さん返信ありがとうございます！カテゴリ化は検討してます〜\\n5個くらいなら大丈夫だと思いますけど、自分が見たcourseraのkaggleコースではTree系だと特徴量が多くなりすぎると決定木の分割方法が多くなりすぎて分割しきれないということが書いてあったんですよね、、、\\n10個とか多いものだと100個くらいになってしまうものもあって、そういう場合は次元削減しかないのかなと考えていました', '特徴1～15が、列1～3に分かれて入ってるって感じですか？', 'そういう感じです！飯田産業コンペにいくつかあったカラムの感じです', '&gt;自分としては全てワンホットエンコードした後にPCAなどで次元削減する\\n\\nこれは、15列にした後に次元数を削減するって感じですかね？', 'はい、そのように考えております〜', 'それで良いような気がします。\\n\\n&gt;kaggleコースではTree系だと特徴量が多くなりすぎると決定木の分割方法が多くなりすぎて分割しきれないということが書いてあったんですよね、、、\\n\\nこれ、light GBMやXG boostのような購買ブースティング系でも解決できないか自信ないので、一回ロジック調べてから回答しますねー！', '村上さんありがとうございます！助かります:sweat_drops:', '予測の誤差を学習させる、「弱学習機」を作って行く手法なので、\\n\\n1つ目の木の作成では考慮されていない比較的重要な特徴量は、次の弱学習機を作る時点で特徴量として出てくるはずですね！\\n\\nなので、サンプル数にもよりますが、PCAとかは特にしなくて、15列のダミーにした上でlight  GBMかけるとかで良いかなーと思います！\\n\\nただ、PCAした方が精度出る可能性もあるので、交差検定して誤差少ない方でいいんじゃやいかなーと！\\n\\n<https://www.codexa.net/lightgbm-beginner/>', '&gt;予測の誤差を学習させる、「弱学習機」を作って行く手法なので、\\n\\n&gt;1つ目の木の作成では考慮されていない比較的重要な特徴量は、次の弱学習機を作る時点で特徴量として出てくるはずですね！\\n\\nここら辺のロジックはイメージつきますか？', '返信ありがとうございます、今日夜確認して返信します！', '確認しました、はいロジック面については大丈夫です、そのままダミーにしてかければいいって言うのは初耳でした、ありがとうございます:blush:特徴が10個くらいのカラムは全部ダミーにかけて30とかそれ以上あるものとかだけをカテゴリー化や次元削減しようと思います〜', 'あ、特徴ダミー化するのと、カテゴリ化するの、内部処理的に一緒だったはずなので、今回みたいに列またがって無ければ全部カテゴリ化で良いはず！', 'なるほど、それは決定木の時は全部一緒で線形の時はワンホットって感じですよね？', '<http://marugari2.hatenablog.jp/entry/2016/12/14/235747>', '&gt;処理を完全には追っていないのですが、rpartのようなカテゴリ併合をしてくれる訳ではないようで、数値変数であればx &lt;= thresholdで分割されるところが、x is categoryで分割されるようになるだけのようです。', 'is category（そのカテゴリか、そうじゃないか）で分岐してるので、実質的にはダミー入れて分岐するのと同じ処理っすね。', '&gt;なるほど、それは決定木の時は全部一緒で線形の時はワンホットって感じですよね？\\n\\nなんかすれ違ってる気がしますねw\\n\\nlight  GBM、XG boostとかだと、誤差を目的変数に予測するから、一つ目のモデルでカバーしきれないけど重要な変数などがカバーできるよねって文脈で話をしましたー！', '確かに、言われてみれば分岐してるのはダミーでも同じですね', 'ので、どっちでも同じだけど、処理的にはカテゴリ化のが楽かとー！\\n\\nPCAとかやるならダミー作った方が良いけど、それで精度が上がるのかはちょっと自信無いっすね。。。', '文脈は理解できてるんで大丈夫です！恐らく完全に把握しました〜', '線形の話は別で確認したかっただけです、誤解させてしまってすみません:sweat_drops:', '線形のやつはどんな感じの質問でしょう？\\n\\nちょっと把握しきれてなさそうです。。。', '線形モデルを作る時は、数値が隣り合うとかで影響を受けてしまうのでカテゴリーよりもワンホットの方がいいのでは？って質問のつもりでした:pray::pray:', '線形モデルだと、\\n\\n・変数をダミー化\\n・PCAなどで次元削減したり、ステップワイズなどで変数選択したりして特徴量を減らす\\n・AICやWAICなどの評価指標を使って汎化性能を評価\\n\\nみたいな手順が一般的かなと思います。\\n\\n今回のようなモデルだとスパーズモデリングになると思うので、LASSO回帰や、リンクの最後で触れているグループLASSOなどを使えば良いのかなーと思います！（これは使ったことないので詳細は不明ですがw）\\n\\n<https://codezine.jp/article/detail/11148>', 'グループlassoは自分も始めて知りました、なるほど、線形こそ次元削減しないとまずいんですね、、、自分のSV Mのスコアが低かったのも納得です:thinking_face:\\nAICやwaicは使ったことがないんで試してみようと思います、村上さん、いろいろ詳しくありがとうございました！', '余裕ある時とかで良いので、scrap boxとかに上記の内容まとめるの、お願いできないでしょうか！？', '了解です〜、scrap boxって使ったことないんですが、どこから見れますか？？', '<https://scrapbox.io/dl-guild/>', 'こちらから見れますー！', '<https://scrapbox.io/dl-guild/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%82%AE%E3%83%AB%E3%83%89%E3%81%AEScrapBox%E3%83%81%E3%83%A5%E3%83%BC%E3%83%88%E3%83%AA%E3%82%A2%E3%83%AB>', 'ここの記事中のリンクから登録すれば、編集できるようになります！', '了解しました〜、今いろいろ立て込んでるんで週末やります', '了解です！よろしくお願いします！！', 'まとめましたー:palms_up_together::palms_up_together:')\n",
      "('mory',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Satoru Mikami')\n",
      "('SQL', 'ML')\n",
      "('どなたかDFDやER図を作成する際のいいツールありませんか？\\n出来ればMarkdown的にテキストファイルとして管理できるのが理想です。\\nmermaid.jsの様な感じで、もうちょい高度に各オブジェクトの情報を追記できるとよいです',)\n",
      "('ER図がフリーで使えて便利なのでA5とかのSQLクライアント使ってる方はいましたねー！\\n\\nクライアントに渡したり、色んな会社が色んな環境で見たりすることが多いので、EXCELで作っちゃうことが多いです。。。\\n\\nが、ニーズとは全然違いますよねw', '<https://qiita.com/uzuki_aoba/items/a01f8b0b52ced69c8092>\\n\\nこの辺っぽいですが、mermaidが主流なんですかね？', 'mermaid.jsの類がニーズにはヒットするのですが、dfdとかまで作るのやや貧弱なんですよね、、、\\n大体の現場ではやっぱまだEXCELベースが多数派なんですかね:sob:', '自分の場合、結構SIerっぽい動きが多いので、そういう形が多いですね。。。\\n\\nドキュメントはtyporaとか使ってmark downで書いちゃうことが多いので、テキストベースで書けると嬉しいんですけどねー！\\n\\n寄せて行きたくはありますね！', 'ただ、コードとビジュアライズが混ざったようなものは結構見せたい形に出なかったりするので、カスタムできないとツライですよね。。。', 'なるほど…！', '<@UKY4VFB5E> さんとかこの辺詳しそうですが、何か良いソリューション知らないですか？？', 'ER図だと昔はMySQL Workbenchを使っていて、Rails使ってからはRailsERDで自動生成させてました', '<https://github.com/voormedia/rails-erd/blob/master/README.md>', '試してないけどメルカリ にこんな事例がありました\\n<https://tech.mercari.com/entry/2018/05/25/133818>', 'ありがとうございます！\\n参考にさせていただきます！', 'DFDは、vscode+PlanetUML+markdownかな', '<@UKY4VFB5E> \\n流石！頼りになります！！')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('可視化',)\n",
      "('可視化に重きを置いた決定木だと、これが良いのですかね？\\n\\nビジュアライズ良さそうなので使ってみようと思っているのですが。\\n\\n<https://www.google.co.jp/amp/s/www.st-hakky-blog.com/entry/2018/09/30/172910%3famp=1>',)\n",
      "('前の現場リーダーの人のブログだw', 'おぉ！世の中狭いですねーｗ', 'とりあえず便利でした！')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('mory', '澤祐斗\\u3000東工大3年')\n",
      "('API',)\n",
      "('質問チャンネルで質問した際は、質問者がscrap boxに回答内容をまとめるってやり方いかがでしょう？\\n\\n・質問者は「質問をまとめる」というタスクを負担するので、気兼ねなく質問できる\\n\\n・回答者は、質問した内容に答えていくと、自分の知見がどんどんドキュメントとして蓄積される\\n\\n・他の回答者の意見も見れる\\n\\n・Q&amp;Aがどんどん蓄積されていく\\n\\nという、みんなメリットある運用フローになるかなーと思ってます！',)\n",
      "('ただの思いつきなのですが、質問と回答をAPIで自動取得してscrapbonxに自動生成とかも手間がかからずにいいかもしれないですね！', 'プロジェクトのdocは割ときれいに残したいですが、FAQ的なものであればログ的に残すだけでもいいかなって考えですね、', '確かに！APIはあるか怪しいですが、ノートのインポートはできるようなので、月一ぐらいまとめてインポートするのはありかもしれませんねー！', 'いいと思います！\\n質問の分野ごとに大まかに分ければ、後から入った人が興味ある分野を見やすいと思います！やり方とかは分からないんですが、、')\n",
      "('仲村勇輝',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('ML', 'API', '機械学習')\n",
      "('ニュースタイトルを入力すると、クリック数が出力されるウェブアプリケーションを作成しようとしているのですが、Djangoで作るのは可能でしょうか？\\nそれとも、HTML, CSS, JAVAscriptで作成するべきでしょうか？\\n両者の方法に向き不向きなどが有りましたら、教えて頂きたいです。\\n\\nタイトルからクリック数を予測するモデルは作成してあります。',)\n",
      "('モデルは、pythonなどで作成しているのでしょうか？', 'そうです! pythonです', 'なので、djangoで作れたら連携が上手くいくのかなぁ？\\nのようなぼやっとしたイメージだったのですが', 'となると、APIサーバーは必要なので、\\n\\nDjango+HTML+CSS+javascrpt\\n\\nって感じになるかと！もう少し厳密に言うと、\\n\\n使用フレームワーク:Django\\nフロント:HTML+CSS+javascrpt\\nバックエンド:python\\nインフラ、サーバ:？？？\\n\\nといった感じになるかと思います！なので、比較軸としては、\\n\\n・Djangoかflaskか？（flaskはライトなwebフレームワーク）\\n・javascriptのフレームワークを使用するか？\\n・サーバはどうするか？\\n\\nというような検討となるかと思いますー:grin:\\n\\nサービスにおいて、どういった機能が必要なのか、整理してみると良いかもしれませんねー！', 'ちなみになのですが、皆さんはwebアプリケーションの作成を経験された事は有りますか？\\n機械学習系エンジニアでも、経験する事なのでしょうか？', '経歴にも寄りますが、いわゆる「機械学習エンジニア」と呼ばれる方々はアプリ作ったり、APIを作ったりすることが多いので、webサービスの知見を持っていることが多いですね！', 'なるほど・・・\\nその際には、何か参考になさった資料などはございますでしょうか？\\nHTML,CSS, Javascript, Django\\n全てプロゲートレベルなので、基礎を固めて行きたいと思っているのですが。', 'ただ、チーム開発だと、分析周りのコアな機能を作ることが多いと思うので、一般的なwebアプリというより、マイクロサービスっぽいものを開発することが多いかと！', 'おんなじ感じにサービス開発検討していてFlaskでやる予定です。\\n分析結果の表示とかさらにdashなど検討中')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('BI', '予測分析')\n",
      "('顧客の生存率の分析しようと思うのですが、おすすめありますか？\\n<https://qiita.com/Salinger/items/400b4bff896013c447aa>\\nこの返かな～。',)\n",
      "('ツールとか手法とかって感じですか？\\n\\nコホートとは違った感じですかね？', '王道だと、\\n\\n・コホートでざっくり生存率を見る\\n\\n・半年後生存有無の予測分析をして、効いている特徴量を分析（予測というより単純な決定木とかでどの特徴量が効いているか見る）\\n\\nみたいなイメージですかねー。', 'コホート→BIの慣れているやつ\\n\\n決定木→python、R\\n\\nみたいなイメージです。', '数理モデル的にやってみたかっただけですね。\\nまぁ普通のアプローチが一番しっくりなりそうです', '<https://qiita.com/saltcooky/items/409329485be499a5b270>', 'そういう意味ならこういう感じですかねー？', '<https://www.jstage.jst.go.jp/article/marketingscience/22/1/22_220102/_pdf/-char/ja>', 'パラメータをユーザー間の傾向の差に分けて推定するって感じなんですね。\\n\\n確かに、その方が上手く行きそうですね。\\n\\n「ユーザーの再訪問の分布が指数じゃなかった」って話は、結局モデリングがめちゃくちゃ難しいって話なので、結構悩ましいですね。。。', '時間軸ですからね～。意外とありそうで、この辺のモデルってないんだな～と久々にアプリ系の分析やっていて感じます。:joy:', '結局は心理モデリングなので、キレイな分布にならず、頓挫するというのが多いのでしょうね。\\n\\n広告予算めちゃくちゃかけた時期があったり、SNSでバズったりみたいな要素とか、復活の要因も山ほどあって、数理モデルでやっても案外良い結果出ないというのはありそうですよね。。。', 'そういったイベントログも全部入れた上で、人間の心理学的振る舞いも考慮して（単純接触効果でクリック率が上がって行くとか）モデリングするとなると、スーパーマンじゃないとこなせない感じありますよねw', 'なので、比較的安定してる入会時期と活動時期を絞って、通常の分類問題として扱うというのが現実的なんでしょうね。。。')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('AI',)\n",
      "('どなたか、xserverのSSL設定詳しい方とかいませんか？SSL設定ミスったっぽくて、以下の内容を問い合わせに投げたのですが、もしわかる方いればサポート頂けると嬉しいです。\\n\\nDNS周りとか、毎度何かしらハマるのですが、どういう思考パターンでやると良いのですかね？ｗ\\n\\n----------------------------------------\\nご質問内容\\n----------------------------------------\\n以下の設定内容、問題、実施事項の際に、どのような設定手順を踏めば、SSL対応ができますでしょうか？\\n\\nDNS設定、htaccessの設定を修正する必要があるかと想定しております。\\n\\n\\n----------------------------------------\\n設定したい内容\\n----------------------------------------\\n「<http://guild.data-learning.com|guild.data-learning.com>」のサブドメインに関して、SSL設定をしたいと考えています。\\n\\n<https://data-learning.com>\\n\\nに関しては、別サイトにて使用しているので、「<http://guild.data-learning.com|guild.data-learning.com>」配下のみでSSL設定をしたいと考えています。\\n\\nまた、以下のアドレスに関しては、「<https://guild.data-learning.com>」に統一したいと考えています。\\n\\n・<https://www.guild.data-learning.com>\\n・<http://www.guild.data-learning.com>\\n・<http://guild.data-learning.com>\\n\\nまた、前提として、Gsuiteで取得したドメインでネームサーバーを指定して、xserverのドメインを使用しております。\\n\\n----------------------------------------\\n問題\\n----------------------------------------\\nSSL接続の反映した際に、IP直入力、URL入力時にそれぞれ以下のエラーが発生しています。\\n\\n\\n----------------------------------------\\nURL入力時エラー内容\\n----------------------------------------\\nこのサイトにアクセスできません\\n<http://guild.data-learning.com|guild.data-learning.com> のサーバーの IP アドレスが見つかりませんでした。\\nWindows ネットワーク診断ツールを実行してみてください。\\nDNS_PROBE_FINISHED_NXDOMAIN\\n\\n\\n----------------------------------------\\nIPの直入力の際の画面\\n----------------------------------------\\n無効なURLです。\\nプログラム設定の反映待ちである可能性があります。\\nしばらく時間をおいて再度アクセスをお試しください。\\n\\nSSL反映後12時間程度経っても、反映されない\\n\\n\\n----------------------------------------\\n実施事項\\n----------------------------------------\\n・「<http://data-learning.com|data-learning.com>」ドメインに対して、無料独自SSLを設定\\n・htaccessのhttpアクセスをhttpsにリダイレクトするように設定変更（今は初期状態に戻しています。）\\n\\nお手数ですが、ご確認のほど、よろしく願いします。',)\n",
      "('無事解決できました！お騒がせしましたー！',)\n",
      "('ﾋﾛﾘｰ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('書籍', 'データエンジニア')\n",
      "('データエンジニアリングの本って色々ありますけど、\\nそのデータからどういうアドバイスができるか、っていう、コンサルの仕方について学べる本とかブログってありますかねぇ',)\n",
      "('最近押している本だとこちらですが、若干ニュアンス違いそうですね。\\n\\n具体的な事例など含めて紹介されているような本ですよね？\\n\\n<https://www.amazon.co.jp/%E4%BB%95%E4%BA%8B%E3%81%AE%E8%AA%AC%E6%98%8E%E6%9B%B8%E3%80%9C%E3%81%82%E3%81%AA%E3%81%9F%E3%81%AF%E4%BB%8A%E3%81%A9%E3%82%93%E3%81%AA%E3%82%B2%E3%83%BC%E3%83%A0%E3%82%92%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%8B%E3%80%9C-%E7%94%B0%E5%AE%AE-%E7%9B%B4%E4%BA%BA/dp/4991087007>', 'あー これTLで見かけて気になってましたみてみます！', 'KPIマネジメントなどはKPIからどう成果に結びつけるかという話なので、ニーズと近いかもしれません。\\n\\n他にも何か無いか、調べてみますねー！\\n\\n最高の結果を出すKPIマネジメント <https://www.amazon.co.jp/dp/4894519844/ref=cm_sw_r_cp_api_i_IoMqDbXKYTMH2>', 'タイトル的にはこれが一番しっくりきますね！', 'このスタンスであれば、ビジネス寄りの書籍だと思いますので、何個かピックアップしてお送りしますねー！', '<http://www.amazon.co.jp/exec/obidos/ASIN/4822258912/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4822237729/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4873116856/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4492555552/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4862760856/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4478039631/sharela06-22/ref=nosim/>', '<http://www.amazon.co.jp/exec/obidos/ASIN/4478100764/sharela06-22/ref=nosim/>', '<@ULKPET3UK>\\nデータ分析のビジネス寄りの書籍となると、ここらへんですかねー！', 'この辺り一通り理解できて最近の流行が分かってればデータ分析のプリセールスとかは大体大丈夫なんじゃないかと思っております。', 'ありがとうございます！', 'ただ、社内の組織構造や状況によって対応が変わって来るので、実践的な練習が結構大事な気がしますね。。。')\n",
      "('makio',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('OCR', 'AutoML', 'ML')\n",
      "('【NGワード検出とか誤字検出に使えそうなツール知っていませんか？】\\n医療系の会社で働いていて薬事部の友人から、「広告物やトレーニング資料に関する査読リソースの削減」について相談されてまして、なんか良いアイデアないかなと書いてます。\\n具体的にはポスターやデジタル広告などをマーケ部門が作成した後に、医療広告規制などに乗っ取って、薬事部が査読をする必要があるんです。製品名が正式名称じゃなかったり、製品番号が対応していなかったり、®️が上付きじゃない、“効果がある“などNGワードがあるなど基本的なところが対象です。この人間がやらなくても良いところが意外と間違って出されることが多くて、いちいち訂正するのに人的リソースを結構割いているとのこと。\\n\\n以上の背景から、NGワードや正式名リストなどを教師データで読み込んで、文字数カウンター的なブラウザに突っ込むとアラート検知するような簡易システムを作りたいなと思うのですが、うちのチームもほぼ趣味レベルでのリソースしか避けなく。。。。何かAutoMLで簡単に学習して、システム化できるような方法思いつく方いたら教えてください。',)\n",
      "('校正系の話ですねー。校正を全部完璧にするのって結構難しいので、補助的なツールとして活用する方向性が良いかと思います。\\n\\n恐らく、薬事法違反系の話と、表記ゆれ・誤字脱字系のOCRなどの話題が混ざってる気がするので、いくつか問題を切り分けた方が良い気がしますねー！\\n\\n偽陰性率が課題になりそうなので、なかなか難しい課題ですよね。。。\\n\\n■誤字脱字系\\n・ドキュメントに関して、抽出語を登録しておいて、「未知語」に分類された語を改めて確認しておく。\\n\\n・固有名詞登録をしておいて、その名詞に対してマハラノビス距離が1～2のものを（もしくは他のあいまい検索系のアルゴリズムを活用する）\\n\\n・「効果がある」、「🄬」の文字などをNGワードに登録しておいて、分類する\\n\\n■OCR\\n・Google Visionなどを活用する\\n\\nといったイメージですかねー！またアイディア出たら共有しますー！\\n\\nネットワーク図や頻出語の計算などで若干領域は違うかもですが、ライトにテキスト分析するなら、KH coderおススメです！\\n<https://khcoder.net/>', 'あと、泥臭い方法ですが、基礎分析として、分類ごとの校正発生率などの分析もできると良いですよね。\\n\\n・誤字発生率\\n・検出漏れ\\n・作業時間\\n・オペレーターのレベル\\n\\nみたいのを総合して、どの課題に着手するかの優先順位付けて、簡単で効果が出やすそうなものから取り組むって感じになるかと思います！')\n",
      "('makio',)\n",
      "()\n",
      "('AutoML', 'ML', 'OCR')\n",
      "('査読したい媒体は、ポスターなどの紙媒体やプレスリリースなどの電子化文字情報の両方あるのですが、OCRまで噛ませると結構しんどうそうなので最初は今現在デジタル文字情報があるものを、査読するモデル作成をスコープとしようかなと考えています。\\nまずは、薬事部からテキストリストとサンプルデータもらって、Cloud AutoML Visionがテキスト分析にも使えるみたいなのと、AutoML Natural Languageを試してみようと思っています。',)\n",
      "()\n",
      "('ﾋﾛﾘｰ',)\n",
      "()\n",
      "('機械学習',)\n",
      "('機械学習ちっくにやるなら迷惑メールフィルタリングの手法が使えそうだけど、\\nその程度ならスプレッド&amp;GASで拡張でプロトタイプいけそう\\nNGワード登録したおいて検出ってやればいいわけで',)\n",
      "()\n",
      "('ﾋﾛﾘｰ',)\n",
      "()\n",
      "()\n",
      "('そして、グーグルフォームで査読申請フォーム作って、査読受付フロー確立させるだけでだいぶ工数減るのでは',)\n",
      "()\n",
      "('makio',)\n",
      "()\n",
      "()\n",
      "('<@ULKPET3UK> \\nありがとうございます。難しく考えず、まずは簡単に作って触れるプロトタイプ作るべきですよね。\\nミスする頻度はNGワードより誤字が多いみたいなので、既存ツールに乗っかってできること考えてみます。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('一般的な語であれば、以下の校正ツールなども使えるかもしれないですね。ガイドラインがあるのであれば、それにどう合わせるのかという話になるのですが、校正ガイドラインなどはあったりするのでしょうか？\\n<https://developer.yahoo.co.jp/webapi/jlp/kousei/v1/kousei.html>',)\n",
      "()\n",
      "('ﾋﾛﾘｰ',)\n",
      "()\n",
      "()\n",
      "('文章の監修チェックサポートツールって考えると機能的にはリーガルフォースに似てますよね\\nリーガルフォースさんに機能追加を相談してみるといいかも\\n<https://legalforce-cloud.com/>\\n\\n１から開発するにしても、完成度高めれば医薬業界向けに１プロダクトできそう',)\n",
      "()\n",
      "('makio',)\n",
      "()\n",
      "('OCR',)\n",
      "('<@UJRAL005U> \\nデータ分析受託会社の友人に相談したら、同じように要件定義の分解をおすすめされました。\\n外部に依頼するにも、定型的でない文書のOCRはかなり難しいので、それだけでモデルが１つ増えて値段跳ね上がるそうです。\\n\\n・紙からOCRはスコープ外\\n・置換は難しいなら間違えてそうなところをマークのみでもOK\\n・あくまでも全機械化ではなく、査読にかかる時間を減らす',)\n",
      "()\n",
      "('makio',)\n",
      "()\n",
      "()\n",
      "('基礎分析したかったんですが、デジタル情報か紙か？すらフラグなくて、情報を整理して要件定義するだけで一仕事になりそうです笑',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('恐らく、結構難しい領域の開発が多岐に渡っているので、スコープ調整は必須になると思いますね。\\n\\n&gt;・置換は難しいなら間違えてそうなところをマークのみでもOK\\n\\nここに関して難しいのが、査読、校正という性質上、90%のエラーが検知できればOKというものだと使いどころが難しいので、「この領域であれば99.9%」検知できる、もしくは、「90%の検出で問題にならない工程はどこか？」というような領域や工程を見つけなければならないと思うのですよね。\\n\\n例えば、「ライターが書いている時点での校正チェックでOKとなったものを提出する。」という内容であれば、ミスの絶対数自体は減らすことができるんじゃないかなと思います。（それで校正の作業時間が減るかは要検討ですが。。。）\\n\\n恐らく、要件定義がめちゃくちゃしんどいと思いますので、（オペレーターが絡む分析プロジェクトは大体そんな感じですｗ）現場の協力を得る政治的な方法としては、デジタルの文字データでそれっぽいモデルを一つ作って（この時点では検出率がそこまで高くなくてもOK）、「この分析が進めば仕事が効率化できそう」という雰囲気を作るようなプロタイピングも案外大事ですねｗ',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('校正後の最終チェックに使って、印刷後の改版を減らすみたいな方向性でもいいかもしれません。',)\n",
      "()\n",
      "('makio',)\n",
      "()\n",
      "()\n",
      "('要件定義固めるためにも薬事部の協力が不可欠ですよね。とりあえず期待値コントロールはしました。\\n\\n今年は予算がないので秋から社内で簡単なプロトタイプ作って評価してもらい、来年に予算がっつりとって外部リソース使う案件になりそうです。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('形態素解析',)\n",
      "('期待値調整できているのは素晴らしいですね！\\n\\n単純集計だったり、形態素解析＋集計レベルくらいでできるレベル感のもので確実に結果を出して予算取るって感じですかねー！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@UL22NNXBP>\\n公開できる範囲なども制限されているかと思いますが、ギルドで集合知的にフィードバック出来たり、プロトタイピングのお手伝いやリサーチのお手伝いなどもできるかなーと思いますので、困りごとがあればドンドン聞いてください！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('こういった実務上の話などってなかなか触れられることが無いので、かなりいい情報なんじゃないかなーと思います。',)\n",
      "()\n",
      "('makio',)\n",
      "()\n",
      "()\n",
      "('たしかにデータ分析の実務上の話はできないですよね。この件もビジネスに直結する話じゃないので、出来てますね。\\n\\n気軽に質問できる場所はありがたいです。',)\n",
      "()\n",
      "('AIKI',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'sota_sakuma')\n",
      "('G検定', 'E検定', '機械学習', 'AI', 'ディープラーニング')\n",
      "('はじめまして、エンジニアやっているAIKIです。\\n来年2月にディープランニングのE資格を受ける予定あるので、過去問や出題されそうな範囲を探しています。情報がある方いらっしゃいますか。',)\n",
      "('自分はG検定、E検定そこまで詳しくないのですが、\\n\\n<@UKQHU14D9> さん、 <@UKT3G90U8> さんが以前G検定に関してお話してましたね。', '<@UME7ABXV4> \\n私は11月にG検定受験予定です。\\nE検定は、認定講座を受講し、数学等の試験に合格していないとそもそも受験が出来ないので、もう少し先になりそうです。\\nE検定の認定講座はどこのやつ受けましたか？(受けますか？)', 'sota_sakumaさん、初めまして。\\n言う通りです。\\nE資格を受けるための基準としては3つあります。\\n１.ディープラーニング講座を受講修了\\n最終試験合格（受講必須）\\n２.機械学習講座の修了試験に合格（試験を合格すればOK）\\n３.数学講座の修了試験に合格（試験を合格すればOK）\\n\\nちなみに私はAIジョブカレの”ディープランニング講座”を受講しました。\\n講座の受講方法2種類\\n・オンランイン（授業の動画を見て勉強する）\\n・オフライン（授業に実際に出席する）', '<@UME7ABXV4>\\nジョブカレ受講生なんですか〜\\nちなみに私も今機械学習講座受けてます。終わったらDL講座受けた後にE資格受講予定なので来年の夏かなーと考えています。\\n\\n<@UKQHU14D9>さんがG検定を合格されていますが、E検定受けた人はまだいないと思います。。\\n\\n受けるまでのハードル(金銭的に)が高いのでなかなか受講が進んでないイメージですね〜。\\n')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'ﾋﾛﾘｰ', 'Satoru Mikami', '西岡健一')\n",
      "('digdag', 'BQ', 'GCP')\n",
      "('ゆるぼ\\ndigdagでBQのワークフロー管理したことある人いますか？\\nまぁこういう情報ってどこまで無料で聞いていいもんだろう。\\n設定のアドバイスとかくれたらそれなりに支払うべきだと思うしその価値はあるんだけどね。',)\n",
      "('<https://titi-shakr.com>', 'こういったの使えば、受発注楽になりますかね？？', 'まぁ法人なので 銀行振込ですかね。本当はアマゾンギフトでもいいけど', '昨日Airflowテストでやったら1日で2000yくらいかかってGKEにサーバ建てた方がいいかなと\\nその辺詳しくないのでちょっとアドバイスが欲しい', '<@UKY4VFB5E> <@ULQ3D7T2Q> <@ULKPET3UK> <@UKT3NHRM3>\\n\\nメンションした方々、分析基盤のエンジニアリング周りがお強い方だと思うのですが、digdag経験あったりしますでしょうか？', '気にはなってたけど使ったことないなぁ\\n機能的には、前の案件で使ってたアステリアみたいなやつかな', 'digdag使ってるけどBQは経験ないですね。自分も知りたいです', '<https://twitter.com/sonots/status/1154181156905996288>  こういうの見ると、Digdagにも慣れてきたしDigdagでいいんじゃないかっていう気分になってしまいますね', 'ってあるしDigdagやってみるかな', 'Yamlの設定は楽チンです。Digdagサーバーも安定してますよ。エラー時のハンドリングがちょいめんどくさいくらいです', 'GCP上でどうやって作ろう\\nそしてs3とかBQのコントロールさせるのかちょっと面倒', 'DigdagはJavaが必要ですね', '週末リサーチかな', '個人的に手軽さと柔軟さはAirflowがいいと思ってます', 'まあ、導入したの2年前なので、今ならAirflowがいいなと思ってます。複雑じゃなきゃLuigiもいいよって勧められたことあります。まあ、Google標準？はAirflowっぽいですね', '昨日いじったらえらく高くついた', '<@UJRAL005U> digdagは経験ないですね。\\nタスクフローはbashとpythonで対応していました:sweat_drops:', '不安定記事が多い。Digdagかける人いる\\n', '世に出回っている記事は、情報が分散しすぎて、えらく苦労しましたね。公式のドキュメントがオススメです')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'ﾋﾛﾘｰ')\n",
      "('AI', 'OCR')\n",
      "('あとさらにゆるぼ\\n金券ショップにAI活用というテーマで提案したい人いますか？\\n上場ネタが欲しく革新的な成長っぽさが欲しい ブロックチェーンでも可能w',)\n",
      "('おぉー！良いですねー！！\\n\\n中古の買い取り価格的な所ですか？', 'ですね。そこそこの規模で利益はありますが成長性を見せないと投資対象とならないので投資家が喜ぶネタ作りです。\\n実際の利益は二の次ですw', 'IRのためのAI開発要素もあります', 'ちょうど、営業代行などのプランを整備して行きたいなーと思っていたので、詰めますか！', 'ちょっとエンジニア飽きたのでそういう仕事もしたいですw', '面白い！金券ショップって薄利なのに家賃高いとこに出してて不思議に思ってた\\u3000気になる', 'その辺も全部教えてもらえますよ。ビジネスモデルとか', 'AIじゃないけど\\n市場調査って多分人力でやっているだろうから\\nRPA的なアプローチで結構喜んでもらえそう\\n１日1回だった価格更新を毎時間にしました！とかw', '欲しいのは投資したくなるネタ', 'RPAじゃ投資家が動かない', 'こういう視点がエンジニアとビジネマンの違いって典型ですよね', '言ってること多分ヒロリーさんと同じですが、文脈的にダイナミックプライシングとかですかね？', 'たぶん企画書書いて 証券会社がどう判断するかでお金出るパターンですねw', 'cash的なノリで買取するとかw', '企画コンペとかやっても面白そうですね！！', '確かにcashの画像審議判定はAIいい鴨', 'cashの外貨とか金券買い取りって機能はあるのに買い取りサービス停止してるんですよー', '偽造が多いんですかね？', '免許的な問題かも\\u3000あそこ古物商取ってないし', '便利な駅前にあるから、買い取り窓口として使うのは良さそう\\u3000cashは郵送になっちゃうから郵送料とのバランス合わないからかな', 'うちの会社古物免許ありまっせw', '①cash的な買取サービス（OCR&amp;検索で行ける？）\\n\\n②在庫に合わせたダイナミックプライシング\\n\\n③金券買取のアプリ化\\n\\nまで行ければ、IR的には良さそう。③に関してはまずは店舗導入とかが現実的な気がしますがー。', 'アプリ面白いけどターゲット世代的に行けるか？', 'かと言いつつ 私もマックの優待券とかフルあまりです', 'お金あまり稼げない若年世代がターゲットかなと思ってたんですけど、\\nターゲット層ってどこなんですか', '企業とかも多いんですよね。', '株主優待がそこそこ大きなマーケットなはず', '最近 お歳暮御中元もないですし', 'その辺の金券需要や回数券などで成り立ってきた感じです', 'あと節税', '買取は株主って感じなんですね。\\n\\n販売ターゲットはどんな感じなんでしょう？？', '一般人ですね。株主優待券', 'お盆とか飛行機優待券が人気', '遊園地チケットとか', '今気になって知ったことだけど法人でも株主優待ってもらえるんだ・・・\\nそれを受け取った企業がどさっと買い取ってもらうのか\\n&gt;株式の持ち合いやファンドなども優待は受け取っている\\n<https://money-magazine.org/yutai-corporation/>', 'GPIFが受け取っている株主優待とんでもない量だろうなぁ\\nどこの金券ショップに売ってるんだろ', '<https://www.tickety.jp/sell/anajal-kabuyu/lp/>', 'なるほど、半額チケットとかあるんすね。。。', '依頼元はゴルフ場も経営していますw\\nあっちの案件は雑食に流して見たけど', 'かなり大きなクライアントなんですね。調べれば大体分かっちゃいそうw', '法人買取って、営業力勝負みたいな所ないんですかね？\\n\\n中小零細とかなら結構ありそうですが。')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "()\n",
      "('という感じの案件は頑張れば結構獲得できる',)\n",
      "()\n",
      "('Tatsuya Matsushita',)\n",
      "('ﾋﾛﾘｰ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('Tableau',)\n",
      "('データポータルに詳しい方いれば、教えて頂きたいですー。\\n\\n「期間」オプション( <https://support.google.com/datastudio/answer/7059697?hl=ja> )使った時に、\\n終了日だけのデータを抜き出したいときってどうしたもんでしょうか。\\n\\nつまり\\nデータソース側が\\n```\\nday num\\n8/1 100\\n8/2 200\\n8/3 300\\n```\\nとかの時\\n\\nレポート側の期間選択で、\\n・（開始日関係なく）終了日に8/3を選択→300\\n・終了日に8/2を選択→200\\nが表示されるような枠を作りたいです。',)\n",
      "('フィルタを別でかけるしかなさそうですねー', 'リアクション有難うございます。\\nフィルタかけるのに基本固定値しか使えない認識なので、\\n`「期間」選択を変更する度に、値が変わる`\\nような使い方は難しいのかなぁと思っています。。。', 'そうですねー\\u3000連動させる機能はデータポータル には乏しいですねぇ\\nTableauでも難しいような気がする', 'うーん、やっぱりそうですかね、、、\\n\\n先にデータソース側の計算フィールド追加で\\n`MAX(day)`\\nを追加しておくような方法も検討したんですが、どうにもうまく行かず。', '明日か明後日あたり時間見つけて、試してみますー！！', 'あざまーす', 'でも無理かもと思い始めてるとこです。', '日付周りのフィルタは貧弱だった記憶があります。。。', '<@UKTRK6EE4>\\nなんかすごく負けた感じの手順ですが、カードではなかなか実装難しかったのですが以下の手順ならそれっぽいものは出せました。\\n\\nなかなか痒い所に手が届かないですね。。。\\n\\n・表形式のテーブルで並べ替えを日付の降順にする\\n・ヘッダー、ページ切替などの不要なものを消す\\n・一行目の要素のみ抽出するようにする\\n\\nみたいな感じであれば、できるっちゃできるっぽいです。', 'こんな感じですかね。。。')\n",
      "('seiyakitazume',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('pandas',)\n",
      "('【自然言語解析勉強したいという人います？？】\\n仕事で1年ほど自然言語解析はやっておりまして、以前技術書店でこんな本を出しました。\\nもしニーズあれば貸し会議室借りて、自然言語解析の基礎から勉強会みたいの出来たらと思うのですが、興味ある人いますでしょうか？？\\n<https://note.mu/hanawa11ify/n/nfe5d3867fb41>',)\n",
      "('おぉー！！良いですねー♪\\n\\nトピックモデルとか、ザックリ理解になってしまってるので、改めて学び直してみたいですー！！\\n\\nあと、bertとかはキャッチアップできてないので、キャッチアップしたいです！！', 'slackのトークデータをテーブル形式で取れるようにしたので、実践演習のネタとして使って貰うと面白いかもですー！', 'コーパス作りと辞書整備のベストプラクティスなんかも知りたいですが、応用って感じですかねー？？', 'slackのトークデータも面白いですね！！\\n辞書整備は地道な作業になるので実務でやるって感じですね〜〜！！', '趣味的にはやりたいなーと\\nプロフィール分析したいw', '5人以上は集まりそうな感じですね！！\\n\\nちなみに、レベル感としては、pythonの基礎構文が分かって、pandasとかでデータフレームが扱えるくらいのレベル感で大丈夫なのでしょうか？', 'はい、pythonの基礎構文分かれば大丈夫です！\\nトピックモデルについて解説していきます！！\\nとりあえず調整さん作りました〜！\\n<https://chouseisan.com/s?h=d956c6faeeff4d4a9a44aed0278b2a2f>', '<@UKY4VFB5E> <@UL22NNXBP> <@UMG0947NY> <@UKT3NHRM3>\\n見逃してるかもしれないので、参加のリアクションしている方にリマインドです！\\n\\n上記、調整さんを立てて頂いているので、希望の日程を入力して頂ければ！')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('書籍', 'データサイエンティスト', 'データマイニング', '教科書', '統計', 'kaggle', '可視化', '初学者')\n",
      "('質問なのですが、自分は現在、数学とプログラミングの経験があまりない状態ですが、データサイエンティストとして採用してもらい、研修中の身です。\\n\\n\\n皆さまが、データサイエンティストなりたての当初、どうような勉強をしていましたか？？？それと、現在習慣的にどのような勉強をしていますか？？',)\n",
      "('自分の場合、高校大学と情報系なのであまり参考にならないかもしれないですが、\\n\\n・実務に紐付いた書籍や記事を読んで使ってみる\\n\\n・技術書を買ってコードなどを書きながら、理解出来るまで、ゆっくりと内容を進める\\n\\nといったような感じで進めていましたー！！\\n\\n最近の流行りだと、pyQみたいな所でプログラムとデータの扱い学ぶのは良いかもしれませんねー♪\\n\\n<https://pyq.jp>\\n\\n自分も、ここ1、2年でデータサイエンティストになった方がどんな勉強してるのか聞いてみたいですー！！', 'ご回答ありがとうございます！！\\n実務に一番役に経った本って教えていただけたりしますか？・・・・', '10年弱くらい前の書籍になるので、自分が初学者の時の書籍は参考にしない方が良い気がしますね。。。\\n\\n今おススメしている書籍は以下ですが、もっと数学寄りって感じですかね？', '■ ビジネス、コンサル領域基礎\\n仕事の説明書\\n<https://www.amazon.co.jp/dp/4991087007/ref=cm_sw_r_cp_awdb_c_a0akDbMSJD3V9>\\n\\n■ データマイニングエンジニアの基礎\\nデータマイニングエンジニアの教科書\\n<https://www.amazon.co.jp/dp/4863542704/ref=cm_sw_r_cp_awdb_c_p2akDb3QYB3DT>\\n\\n■ 可視化の基礎\\nデータビジュアライゼーションの教科書\\n<https://www.amazon.co.jp/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%93%E3%82%B8%E3%83%A5%E3%82%A2%E3%83%A9%E3%82%A4%E3%82%BC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8-%E8%97%A4-%E4%BF%8A%E4%B9%85%E4%BB%81/dp/4798053481>', '・現在のレベル感\\n・目指しているキャリアの方向性\\n・勉強しようとしていっる領域\\n\\nなどに合わせておススメする書籍などが変わってきますので、上記教えて頂けると！', '自分が参考になった書籍などをおススメするとなると、「Rによるやさしい統計学」とか、大学時代のテキストとかになっちゃうので、最近学習を始めた方の書籍を参考にすると良いかとー！\\n\\nRによるやさしい統計学とか、2008年の本なので、さすがに古すぎな気がします。。。', 'ありがとうございます！！\\n上記２冊はいま読み進めてます！\\n\\n今のレベルとしては、駆け出しエンジニアってやつでしょうか・・今年の４月からこの世界に飛び込みました。\\n\\n目ぜしている方向性、勉強しようとしている領域はどのような方向性があるのか自分が認識できていないのが現状です。現在は統計を中心にkaggleをちょこちょこやってます', '仕事の説明書とデータマイニングエンジニアの教科書読んだら全体感は掴めると思うので、まずは2冊を読み込んで決めるのが良いかと！！', 'ありがとうございます！！\\nがっつり読み込みたいと思います！！！')\n",
      "('はやと-休学中の文系学生',)\n",
      "('yuji.imuta',)\n",
      "('kaggle', '機械学習')\n",
      "('<@UMG0947NY> 学生なんで参考になるか分かりませんが、文系からで数学は行列と微積の基礎だけ洗ってpythonはprogateでやり、udemyとかpyqで機械学習の基礎さらった後にcourseraのmachine learningやった後にkaggleのタイタニックみたいな流れが個人的にはおすすめです〜',)\n",
      "('ご回答ありがとうございます！\\n参考にさせていただきます！！',)\n",
      "('seiyakitazume',)\n",
      "('Yan',)\n",
      "()\n",
      "('自然言語解析勉強会なのですが、せっかくなら希望者ができるだけ多い日程が良いので再度スケジュール調整させてください！！\\n<https://chouseisan.com/s?h=56b072761a934ccf870e20cfd49c0ede>\\n申し訳ありません、もう一度入力をお願いします！',)\n",
      "('完全にダメ元での質問なので、流していただいてよいのですが...オンラインで繋ぐ予定とかないですか？',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('なかなか気軽に質問し辛いと思うので質問なのですが、「これ、質問しても大丈夫なのかな？」、「詳しい人がいたら聞いてみたい」ってような話がある方、教えて頂けませんかー？？',)\n",
      "()\n",
      "('Minotity',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('転職', 'データサイエンティスト')\n",
      "('はじめまして！\\nこれまでレジャー業界の新規事業などに携わっていた者です。\\n34歳、プログラミングもゼロからスタートなのですがデータサイエンスの道を考えています。\\n皆さんなら、勉強してから就職しますか？それとも未経験から採用してくれるところに就職しますか？\\nまた、オススメのキャリアアップの道などあれば教えてください！',)\n",
      "('まずは、全く肌感が無いのであれば、市場リサーチから入るのが良いかなぁと思います！\\n\\nデータサイエンスに関するリサーチや勉強方法などの調査って、どの辺りまで完了していますでしょうか？？', 'ありがとうございます。\\n①市場リサーチは、求人情報を数十件程度見る中で少し掴めてきたかと思います。\\nしかし、予想以上にデータサイエンスの幅が広く各社で求めるスキルが異なっていると思いました。\\n②勉強方法は、こちらの過去の質問や、他のサイトから調べています。\\n今はpyqでpythonの基礎から学んでいます。\\n', 'こらは個人的な考えですが、ミスマッチを少なくするためにも、\\n\\n「その現場でどんな技術が必要とされているか、身に付けられるかを判断できる」\\n\\nというラインまでは最低限スキル上げてから転職するのが良いよかなぁと思います。\\n\\n全くの未経験で受け入れてくれる会社に関しては、未経験でも大丈夫なような仕事しかアサインして貰えない可能性が高いので、最低限の技術をつけてから転職するのが吉かなぁと思います。\\n\\n上記を理解した上でアルバイトだったり派遣のような形で、実務をやっている人の側で知見を溜めるという方法はありかもしれません。\\n\\nただ、今ある程度安定しているのであれば、こちらの方がリスクは高いです。', 'ありがとうございます！\\n今さほど安定している状態でもないので悩んでいます。\\n大変参考になりました！', 'であれば、繋ぎの仕事という形のアルバイトとかで入るのとかは結構良さそうかなーと思いますねー！', 'ありがとうございます！\\n今データサイエンティスト枠での最終面接があったのですが、全く関係の無い業務になりそうです。状況はかなり厳しいです。\\n求人も未経験は多くなく、非正規も含めて難しいのが現状です。引き続きがんばります！', '最初が一番大変だと思いますが、頑張ってください！！\\n\\nちなみに、ギルドの活動の中で実力が十分なのが分かる方などはうちから発注したり、\\n\\n紹介したりって動きをしようと考えていますので、slack内でアウトプットして行くと良いことあるかもしれませんよー♪', 'なるほど、ありがとうございます！\\n10月以降も参加したいと考えています^_^引き続きよろしくお願いします！')\n",
      "('sota_sakuma',)\n",
      "('あんどう', '小竹(fishb)')\n",
      "()\n",
      "('こちらのイベント、前回行った方とかいますか？\\nもしくは、会場の混雑度など情報ある方。\\n\\n行きたい方何人がいれば一緒にいければと思うんですがチケット買うべきか迷いますね。\\n千円なので待たされるならチケット買う方が良さそうな気がするんですが。。\\n\\n<https://blog.techbookfest.org/2019/09/07/tbf07-advance-ticket/>',)\n",
      "('これ私も気になっています。13時までは有料でそこから無料の理由が知りたいです。。ファストパス的な位置づけなんでしょうか、有名なものは早く売れちゃうから、早く入るためのものなんでしょうか。どちらにしろ行ってみたいと思っています！', 'ファストパス的な感じなら買った方が良いかなーとも思うんですが。。情報が欲しいですね！', 'そういえば、前にブレインパットさんのセミナーというかLT会で技術書典のサークル配置に関するプレゼンがありました。\\n<https://speakerdeck.com/shuheif/tbf05-seat-optim>\\n\\n以前はチケットとかなかった気がしますが、回を追うごとに来場者が増えているので有料制度を導入したようですね･･･\\n\\n基本はコミケというか、各自が数十部程度刷って持ってくるというカタチだと思うので、有名／無名によってと言うより、ものによってすぐになくなってしまうと言う感じかと思います。（行ったことないけど）')\n",
      "('wataru.saito',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('AI', 'AR', '可視化', '前処理')\n",
      "('こんばんは。勉強で行き詰ってしまい質問させていただきました。\\n<https://qiita.com/nekoumei/items/b1afca7cfb9e54303ab4>\\nこちらの記事を参考に、WordCloudで自分の好きな歌手の歌詞を可視化したいと考えています。そのためにスクレイピングしてきた歌詞に前処理をしたいのですが、記事中の箇所(1.2 各曲の歌詞、発売日、商品番号を取得する)\\n```\\ncd_num_name_dict = {\\n    \\'AICL-3481\\' : \\'#5\\',\\n    \\'ANTX-1009\\' : \\'Inspiration is DEAD\\',\\n    \\'AICL-3382\\' : \\'DIE meets HARD\\',\\n    \\'AICL-2174\\' : \\'still a Sigre virgin?\\',\\n    \\'AICL-2014\\' : \\'just A moment\\',\\n    \\'ANTX-1006\\' : \\'Feeling your UFO\\',\\n    \\'ANTX-1002\\' : \\'#4\\',\\n    \\'AICL-2804\\' : \\'Best of Tornado\\',\\n    \\'AICL-2451\\' : \\'abnormalize\\',\\n    \\'AICL-2949\\' : \\'es or s\\',\\n    \\'AICL-2761\\' : \\'Enigmatic Feeling\\',\\n    \\'AICL-2526\\' : \"i\\'m perfect\",\\n    \\'ANTX-1011\\' : \\'Telecastic fake show\\',\\n    \\'AICL-2795\\' : \\'Who What Who What\\',\\n    \\'AICL-1985\\' : \\'moment A rhythm\\'\\n}\\nartist_df[\\'Album_Name\\'] = artist_df.CD_Number.apply(lambda x : cd_num_name_dict[x])\\n```\\nの最後の行である\\n```\\nartist_df[\\'Album_Name\\'] = artist_df.CD_Number.apply(lambda x : cd_num_name_dict[x])\\n```\\nがどうしてもKey Errorを起こしてしまいます。この理由が分かりません。分かる方がいましたら教えていただきたいです。よろしくお願いします。',)\n",
      "('dictの中に存在しないものを参照している可能性が高いかと思いますので、\\n\\n`artist_df.CD_Number`\\n\\nの中身って見れたりしますでしょうか？',)\n",
      "('wataru.saito',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('AI',)\n",
      "('```\\n0     ：ANTX-100\\n1     ：AICL-338\\n2     ：AICL-217\\n3     ：AICL-201\\n4     ：ANTX-100\\n5     ：ANTX-100\\n6     ：ANTX-100\\n7     ：AICL-280\\n8     ：AICL-217\\n9     ：AICL-201\\n10    ：AICL-245\\n11    ：AICL-217\\n12    ：AICL-217\\n13    ：AICL-348\\n14    ：AICL-294\\n15    ：AICL-276\\n16    ：AICL-348\\n17    ：ANTX-100\\n18    ：AICL-294\\n19    ：ANTX-100\\n20    ：ANTX-100\\n21    ：AICL-294\\n22    ：ANTX-100\\n23    ：AICL-252\\n24    ：AICL-217\\n25    ：ANTX-100\\n26    ：ANTX-100\\n27    ：ANTX-100\\n28    ：AICL-252\\n29    ：AICL-217\\n        ...    \\n45    ：ANTX-100\\n46             \\n47    ：ANTX-100\\n48    ：AICL-348\\n49    ：AICL-294\\n50    ：AICL-201\\n51    ：ANTX-100\\n52    ：ANTX-100\\n53    ：AICL-348\\n54    ：AICL-372\\n55    ：AICL-348\\n56    ：AICL-201\\n57    ：AICL-201\\n58    ：AICL-252\\n59    ：AICL-252\\n60    ：AICL-348\\n61             \\n62    ：AICL-280\\n63    ：AICL-252\\n64    ：AICL-201\\n65    ：AICL-294\\n66    ：AICL-245\\n67    ：AICL-252\\n68    ：AICL-252\\n69    ：AICL-198\\n70    ：ANTX-100\\n71    ：ANTX-100\\n72             \\n73    ：AICL-217\\n74    ：AICL-372\\nName: CD_Number, Length: 75, dtype: object\\n```',)\n",
      "(\"例えば、 `cd_num_name_dict` の中に `ANTX-100` などのキーが存在していないのに、そのキーを元に参照しているのでKeyErrorが発生するのかと思いますー！\\n\\n```\\nartist_df['Album_Name'] = artist_df.CD_Number.apply(lambda x : cd_num_name_dict[x])\\n```\\n\\nイメージ付きますでしょうか？\", '解決しました。ありがとうございました。\\n単純な理由で申し訳なかったです。。。\\n引き続き頑張ります！', '解決して良かったですー！！\\n\\n自分では気付けないことも多いと思いますので、気にせずどんどん質問しちゃってくださいー♪', \"解決出来たと思っていましたが解決出来ていませんでした。。。教えていただいた通りに修正してみましたが\\n```\\nartist_df['Album_Name'] = artist_df.CD_Number.apply(lambda x : cd_num_name_dict[x])\\n```\\nが結局Key Errorを起こしてしまいました。。。\", 'エラーの内容を頂くだけだと、状況判断できないので、以下のような内容を頂けると、より的確にエラーに対するフィードバックができるようになるかなーと思いますー！！\\n\\n・何をやったのか（ソースコードなど）\\n・原因として何を疑っているのか？\\n・検証内容\\n・検証結果', '質問力の重要さを痛感しました。。。\\n言葉をまとめてから出直してきます！', \"無事解決いたしました！\\n\\n```\\nartist_df['Album_Name']\\n```\\nで中身を見ると\\n```\\n0     ：ANTX-100\\n```\\nというようにデータが格納されていて、これはつまりバリューが「：ANTX-100」であることを指しています。\\nそのため、\\n```\\ncd_num_name_dict = {\\n    'ANTX-100' : 'Inspiration is DEAD'\\n}\\n```\\nという記述ではなく、\\n```\\ncd_num_name_dict = {\\n    '：ANTX-100' : 'Inspiration is DEAD'\\n}\\n```\\nという記述に修正すると\\n```\\nartist_df['Album_Name'] = artist_df.CD_Number.apply(lambda x : cd_num_name_dict[x])\\n```\\nがKeyErrorを起こすことはなくなりました！(説明下手ですみません)\", '解決したみたいで良かったですー♪\\n\\n引き続き頑張ってください！！')\n",
      "('吉村\\u3000政彦',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('AI', '機械学習', '深層学習')\n",
      "('Courseraのコースで勉強を始めたばっかりです。頓珍漢な質問かも知れません。ひょっとして、AI＝地頭の良さで判断、機械学習＝経験則に基づいて判断・・・的なイメージでだいたいあってますでしょうか？(^_^；',)\n",
      "('うーん、難しいのがAIも機械学習も使う人によって言葉の意味が微妙に変わってくるのでなんとも言いずらいですが どの文脈でしょうか？\\n\\n\\n機械によってなんらかの意思決定をさせる方法\\n\\nAI: 一般人がわかりやすい言葉で人口知能\\n機械学習:特定の技術手法\\n\\n\\nぐらいが個人的なイメージです。\\n\\n\\n<https://markezine.jp/article/detail/29471>\\n\\n', 'AI:地頭の良さで判断\\nマシンスペックが高いってイメージですかね。\\n', 'ご返答ありがとうございます。\\n\\n表現を変えてみますと、\\n\\n●優秀なAI：最初からそこそこの結果を出すが、その後場数を踏んでもそんなに結果に変わり映えは無い。\\n\\n●機械学習：かなりの学習が必要だが、その結果は最終的には優秀なAIを凌ぐ\\n\\n・・・こんな印象を持ちました(^_^；', 'リンクの例だとAIの中に機械学習が含まれる感じですので対比というより、\\n\\n「AIだけど機械学習じゃない部分」\\n\\nを整理すると理解が深まるのかなーと思いました！', 'ご返答ありがとうございます\\n\\nまた今晩Courseraのコースの説明を復習してみます(^_^；', 'ちなみに、AIは人によって用途が違いすぎるので、個人的には使ってないですね。', 'まだホントに始めたばかりなので良く判ってないのですが(笑・・・今時点での漠然とした印象として、フワッとしたAIよりも、「自分で調教出来る」という点で機械学習に大変強い興味を持ちました。\\n\\n因みに「深層学習とは？」まではまだ辿り着いて居ません(笑', 'なるほど、まずは機械学習をしっかりと理解して、それを足がかりに色々と理解して行くのがいいんじゃないかなーと思います♪', 'そうしてみます。ありがとうございます。')\n",
      "('Riita Satsuki',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('Python',)\n",
      "('Pythonでのプログラミングで詰まってしまったのですが、numbaやcythonを用いたコーディングの経験のある方いらっしゃったら質問させてください。お願いします。',)\n",
      "('内容によってはご回答可能かと思います！！\\n\\n具体的な事例などをご記載頂ければ、回答しやすくなると思いますが、どのような内容で詰まったのでしょうか？', \"現在1000万行程度の行動ログから\\n各サイトへの遷移率などのKPIを算出したいのですが\\nPythonが遅すぎて話にならず高速化をしたいと考えています。\\nその際にCythonや numbaを用いてdataframeを扱う方法がよくわからず、\\n苦戦しています。\\n\\n高速化したいコードは以下になります。\\n\\n```\\n@numba.jit\\ndef processing():\\n    datas = [['id', 'action_from', 'action_to', 'num_layer', 'flag_end']]\\n    for id in ids:\\n        tmp = data.ix[data['remote_ip'] == id, :].copy()\\n        end_index = len(tmp)\\n        action_names = tmp['request_path'].values\\n        action_timestamp = tmp['timestamp'].values\\n        i = 0\\n        num_layer = 0\\n        if end_index &gt; 1:\\n            while i &lt; end_index:\\n                if i == end_index-1:\\n                    list_ = [id, action_names[i], 'end', num_layer, 1]\\n                    num_layer += 1\\n                else:\\n                    if action_names[i+1] == start_point:\\n                        list_ = [id, action_names[i], 'end', num_layer, 1]\\n                        num_layer = 0\\n                    else:\\n                        list_ = [id, action_names[i], action_names[i + 1], num_layer, 0]\\n                        num_layer += 1\\n                        if action_names[i+1] in end_points:\\n                            i += 1\\n                            num_layer = 0\\n                i += 1\\n                datas.append(list_)\\n        else:\\n            list_ = [id, action_names[0], 'end', 0, 1]\\n            datas.append(list_)\\n\\n    datas = pd.DataFrame(datas)\\n    datas.to_csv(result_dir_path.joinpath('action_sequence.tsv'),\\n                 index=False,\\n                 sep='\\\\t',\\n                 encoding='utf-8',\\n                 header=False)\\n    action_sequence_data = pd.read_csv(result_dir_path.joinpath('action_sequence.tsv'),\\n                                       sep='\\\\t', encoding='utf-8')\\n    action_sequence_data_sum = action_sequence_data.groupby(['action_from', 'action_to']).count()\\n    action_sequence_data_sum = action_sequence_data_sum.reset_index()\\n    action_sequence_data_sum = action_sequence_data_sum.ix[:, 0:3]\\n    action_sequence_data_sum.columns = ['action_from', 'action_to', 'value']\\n\\n    action_sequence_data_sum.to_csv(result_dir_path.joinpath('sum_data.tsv'), sep='\\\\t', encoding='utf-8', index=False)\\n    return action_sequence_data_sum, action_sequence_data\\n```\")\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('この一連の処理の中で、どのあたりの処理がボトルネックになっているかなどって分かったりしますでしょうか？\\n\\n&gt;その際にCythonや numbaを用いてdataframeを扱う方法がよくわからず、\\nまた、実際にjitなどに関しては使用したことがないのですが、事前にコンパイルして実行するとのことですので、dataframeの扱いに差があったりはしそうになさそうなのですが、numbaを使用するに当たって、処理がこける、スピードが改善しないなど、どういった点が問題になっているのでしょうか？\\n\\n<https://myenigma.hatenablog.com/entry/2017/03/02/155433>',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "('Python',)\n",
      "('<@UJRAL005U> \\n```\\n&lt;ipython-input-8-0a921254280b&gt;:one: NumbaWarning: \\nCompilation is falling back to object mode WITH looplifting enabled because Function \"processing\" failed type inference due to: Untyped global name \\'ids\\': Unsupported array dtype: object\\n```\\n```\\nNumbaWarning: Function \"processing\" was compiled in object mode without forceobj=True, but has lifted loops.\\n```\\n\\n```\\nNumbaDeprecationWarning: \\nFall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\\n```\\nこのような感じのエラーが出て、コンパイルできず、普通のPythonと同様に実行されてしまって改善されません。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('恐らく、以下の例などが近そうですね。型が明示的に分からない場合は、nopythonのモードを使用するべきではないといった感じのようです。\\n\\n<https://teratail.com/questions/80129>',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('pandas', 'Python')\n",
      "('以下のリンクの1.1.3あたりに\\n\\n<https://numba.pydata.org/numba-doc/latest/user/5minguide.html>\\n\\n```\\n1.1.3. What is nopython mode?\\nThe Numba @jit decorator fundamentally operates in two compilation modes, nopython mode and object mode. In the go_fast example above, nopython=True is set in the @jit decorator, this is instructing Numba to operate in nopython mode. The behaviour of the nopython compilation mode is to essentially compile the decorated function so that it will run entirely without the involvement of the Python interpreter. This is the recommended and best-practice way to use the Numba jit decorator as it leads to the best performance.\\n\\nShould the compilation in nopython mode fail, Numba can compile using object mode, this is a fall back mode for the @jit decorator if nopython=True is not set (as seen in the use_pandas example above). In this mode Numba will identify loops that it can compile and compile those into functions that run in machine code, and it will run the rest of the code in the interpreter. For best performance avoid using this mode!\\n```\\n\\nとああるので、方向性としては以下のいずれかが良いのではないかなぁと思います。\\n\\n①型が明示的に分かるようにした上でnopythonモードで実行\\n②多少のパフォーマンスを犠牲にしてobjectモードで実行',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@UNFAV5EDB>',)\n",
      "()\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "('SQL',)\n",
      "('遷移率ぐらいならSQLがいいのかと思う。\\n1000万行とか瞬殺レベル',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('SQL',)\n",
      "('自分も恐らくSQLで処理してしまいそうですが、pythonで処理したいという前提でのお話なので、そこはスコープ外って感じですかねｗ\\n\\nSQLに使える環境があるなら恐らくそちらの方が良いかと思います！',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "('BigQuery', 'Python')\n",
      "('<@UL2TY2ERL> \\nKPIとしての遷移率を出すことが最終目標ではないんです…！\\nN1ユーザーベースでデータが必要なので、forループが回しやすいPythonを使っています！\\n一応、BigQueryはあります。というかそこから、read_gbqで引っ張ってきてます。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('SQL',)\n",
      "('どんな集計やる想定なのでしょう？\\n\\nSQLでやるのが良いか、pythonでやるのが良いか考えてみます！',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "('ML', 'Python')\n",
      "('<@UJRAL005U> \\n社外秘なので詳しくは言えないんですけど、MLも必要ですし、(CloudMLもありますが)\\n顧客一人一人の行動データが必要なので、Pythonでないと厳しいかなと思いました。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('SQL', '機械学習', 'ML')\n",
      "('ML前のテーブルデータまではBigqueryとかSQLで作っておいて、機械学習の所をpythonでやるって役割分担するのが良くあるパターンですね。',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "('SQL', '統計')\n",
      "('統計データが欲しい訳ではなくて、user_idごとのデータが欲しくて、SQLでは厳しいです。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('ソースコード見た感じだと、\\n\\n・ユーザーのアクセスした順に連番振る\\n・アクセス時の遷移元、遷移先の一覧を作成\\n・離脱時には `end`を入れる。\\n\\nという処理のイメージなのですが、処理の内容、合っています？？',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "()\n",
      "('その通りです！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('であれば、\\n\\n・LAG関数で一つ前（もしくは後）の値を持ってくる、\\n・ROWNUMBER関数で連番を振る\\n・LAG関すでとってきた値がNULLならENDを入れる\\n\\nみたいな処理でサクッと書けるはずですー！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('詳細分からないのでもしかしたら書けないかもですが。。。',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "()\n",
      "('なるほど！！\\nありがとうございます！\\n調べてみます！:man-bowing::man-bowing:',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<https://cloud.google.com/bigquery/docs/reference/legacy-sql?hl=ja#lag>',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<https://cloud.google.com/bigquery/docs/reference/legacy-sql?hl=ja#row-number>',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('このへんですかね。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('API',)\n",
      "('1行ごとに何かしら外部関数化した処理をしたいとか、APIとの連携が必要ってときにはpythonが向いているんですけど、今回の場合だと得意な方で良さそうですね。\\n\\nパフォーマンスが問題になっているなら、Bigqueryでやっちゃうのが効率良いのかなーという感じです！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('treasure dataの例ですが、イメージこんな感じですかねー？\\n\\n<https://support.treasuredata.com/hc/ja/articles/216083497--%E9%9B%86%E8%A8%88-%E3%83%9A%E3%83%BC%E3%82%B8%E9%81%B7%E7%A7%BB%E5%9B%9E%E6%95%B0->',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "()\n",
      "('このような関数があるのですね。\\nご丁寧にありがとうございます！！',)\n",
      "()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '吉村\\u3000政彦')\n",
      "('データサイエンティスト', 'マーケティング', '時系列', '自然言語処理')\n",
      "('自然言語処理に関する質問なんですが、\\n例えば、コスメサイトのような分布が、女性が圧倒的に多いようなサイトの検索ワードとかでも、性別での分類は可能なのでしょうか？？',)\n",
      "('恐らく、以下のような内容をクリアできれば可能だと思いますー！\\n\\n・分類するのに十分な正解データがあるか？（5%の発生率などだと、数百のアンケートデータ等だと厳しかったりするかと。会員情報と紐付けが可能であればサンプル数確保できるのでやりやすい。）\\n\\n・検索ワードが説明量として機能するか？（メンズ化粧品や、男性特有の問題などの分かりやすいワードがあれば分類することは恐らく可能）', 'あと、かなり効果は低いと思いますが、多少の積み上げとしては、「毎年2/14〜3/14の期間だけアクセスする」傾向がある人はホワイトデーのお返し需要の可能性高いと思うので、そういった、「男性ならでは」の動きを仮説出しして、説明変数として加えて行くようなことはできるかと。', '回答ありがとうございます！\\n言葉の特徴ですよね、、、人間がみたらなんとなく行けそうな気がするけど、うまくいかないってことが起きそうですよね、、、', '<@UJRAL005U>\\nデータから、その「ホワイトデーのお返し」のような「エンジニアは知らない事情だけど、購買者としては大きなトリガー」が存在する的なものって、あぶり出す事って可能なのでしょうか？\\n\\nつまり、エンジニアは「バレンタイン＆ホワイトデー」という社会的イベントは全く知らない前提で、「指摘されていない要因が存在する可能性を示唆/指摘」＝仮説をこちらで立てなくてもという意味でです。', '「男性 or 女性だけが買うような時期があるのでは？」\\n\\nという仮説立てまで出来てしまえば、時系列の特徴量として出すことは可能ですねー！', 'えっと、そうではなくて、「他に仮説を立てる必要があるか否か」の判断基準が、エンジニアの勘ではなく、数値として炙り出せるかって意味です(^_^;', '自分の知る限りでは、そこを機械的に判断する方法は知らないですね。。。\\n\\nモデルに関する評価指標は出せますが、人間でいう所の、「無知の知」的な評価をする基準はないはずです。', 'なるほど！つまり、データサイエンティストとしては、その立てる仮説のセンスも重要＝ある程度のマーケティングやプロモーションのノウハウも必要という事ですね。', 'そうですね。現状はそこが結構重要視されるポイントだと考えています。', '大変参考に成りました。ありがとうございます( ´ ▽ ` )ノ', '参考になったようで良かったです！！', 'この意見を聞けただけでも、SLACKに参加していた価値がありました(*^_^*)', '10万近い単語の中、一番多い数で30とかだとなかなか難しいものですかね？、、、、', 'その場合だと、何かしらの方法で変数まとめた方が良さそうですね！', 'word2vecで100次元くらいに情報圧縮するとかすれば、解釈性は低くなりますが、分類という意味では使える気がします。\\n\\n最近とかだとbertの方がいいですかね？', 'どうまとめようか悩みますね。。。\\nジャンルごととかですかね:thinking_face:', '<https://mieruca-ai.com/ai/research-tf-idf-lsi-lda/>', '自然言語解析だと、LSIなどを使うと良さそうですねー！', '時間使って大丈夫であれば、該当サイトの記事などのコーパスから、ワードをベクトル化するのがいいのかなーと思いますー！', 'あと、地道な努力ですが、同音異義語を寄せるのも結構大事そうですね！', '立て続けに質問で申し訳ないのですが、\\nコーパスがいまいち理解できないのですが、ないと難しいものなのでしょうか？。。。', 'コーパスっていうのは、単純に文章の集まりみたいなものだと思って頂ければ良いかと思います。\\n\\n新聞の中だと化粧品に関する用語があまり使われたりしなかったり、化粧品会社の商品的な文脈で使われると思います。\\n\\n一方で、化粧品サイトなどであれば、その商品を軸にメリットや用途、成分などに関する情報とセットで使われると思います。\\n\\n新聞データを元に出した「似た使われ方」だと、「会社名とセットで使われやすい」、\\n\\n化粧品サイトだと、「成分と一緒に使われやすい」、\\n\\nという違いがあったりするので、そういった元となる文章セットを変えてあげると、適切にその単語の意味をベクトルで表現してあげられるようになるんですよね。', '単語の出現頻度などの情報までで分析を進めるなら問題ないのですが、\\n\\n・tfidfのような特徴を使って特徴語を抽出したい\\n\\n・前述のLSIやword2vecを使って特徴量を圧縮したい\\n\\nなどまでやりたいとなると、コーパスなども意識しないと厳しくなってきますね。', 'フリーで使えるコーパスのセットや学習済みのモデルなどはあったりするので、そういうのを使うのもありです。\\n\\n例えば、bertの学習済みモデルとかだとここら辺でダウンロードできるようです。\\n\\n<http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT日本語Pretrainedモデル#k1aa6ee3>', 'そういうことだったんですね！！\\nコーパスの自作って大変ですか？。。。', '自然言語解析系は単語抽出レベルまでしか案件でやったことないので、どのくらい大変かは把握してないのですが、結構大変そうなイメージはありますね。\\n\\n記事データをDBから引っ張ってこれれば多少楽になるかもですね', 'なるほど、ありがとうございます！！\\nがんばります！！', '分からない事あればまた何でも聞いてください！！')\n",
      "('Kenjiro Kawasaki',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'junpe', 'Riita Satsuki')\n",
      "('回帰分析', '設計', 'kaggle')\n",
      "('【正しいデータ分析方法を教えてください:palms_up_together:】\\n■データの利用目的\\n飲食店のネット・プロモーター・スコア(以下:NPS)を計測し、NPSに与える影響が大きい内容を改善し、NPSを高める事を目的としています。\\n\\n■データ回収方法\\n来店したお客様にお願いしてアンケートに回答していただく\\n\\n■質問内容\\n大まかには下記①〜⑤の内容を含めた20問程度です。\\n\\n①NPS(このお店を友人・知人におすすめするか)\\n\\u3000・0〜10の11段階評価(下記のように分類しNPSを計測)\\n\\u3000\\u30000〜6→非推奨者\\n\\u3000\\u30007〜8→中立者\\n\\u3000\\u30009〜10→推奨者\\n\\u3000※回答者全体に占める推奨者の割合(％)から、批判者の割合(％)を引いて出てきた数値がNPSの値となります。\\n\\n②商品\\n\\u3000・食べ物や飲み物の「味」「盛り付け」「ボリューム」「価格に対する価値」などの満足度を1〜５の５段階評価で質問\\n\\n③サービス(接客)\\n\\u3000・スタッフの「挨拶」「笑顔」や\\n\\u3000・注文した商品の「出てくる速さ」などの満足度を1〜５の５段階評価で質問\\n\\n④空間\\n\\u3000・「席」「照明」「音楽」など「店内の雰囲気」についての満足度を1〜５の５段階評価で質問\\n\\n⑤清掃\\n\\u3000・「テーブル」「トイレ」など「店内」の清潔度度合いの満足度を1〜５の５段階評価で質問\\n\\n\\n■現在の私たちの考え\\n・「相関分析」と「悪い数値と良い数値の比較」などでNPSに与える影響が大きいものを特定しようと考えています。\\n\\n実際に187件のアンケートを取得してNPSと、質問項目の相関分析をしてみました。\\n※注意※\\nこの時のアンケートは「コスパ」「メニューアイテムの充実具合」「提供速度」「盛り付け」「味」「接客」の６つの質問で行いました。\\n\\n結果、NPSと相関が大きいのは「味」と無難な答えがでたのですが、本当に味なのか？という疑問が生まれました。\\nなぜなら、味はお店の雰囲気や接客、盛り付けなどで大きく感じ方が変わるからです。\\nテレビ番組の芸能人格付けチェック的な番組で、高級品を見分けられなかったりするのと同じ考えです。\\n\\nなので、次に「味」と相関が高いのは何か調べたところ「盛り付け」つぎに高いのが「接客」とでたので、この飲食店が「味」はすぐには変えられないよ。というのなら、「盛り付け」「接客」を改善したら「味」は相関の関係で改善され、NPSは改善されるのかな？という仮説ができました。\\n\\nしかし、相関の結果を見るとどれも数字が近すぎて信用できる結果なのかが心配になりました。\\nマイナスになっているものなどがあれば信用しやすいのですが。。。\\n\\nそこで、そもそもこの考え方はあっているのでしょうか？？？というのが疑問になりました。\\n\\n■質問\\n①上記の考えは正しいでしょうか？\\n\\n②相関分析以外の分析方法で、このお店のNPSをあげる事ができそうな原因追求方法はありますでしょうか？\\nどのように分析して、何故そうなのかも分かると助かります。\\n\\n③上記は187件ですが、信用できる結果を得るためには何件のアンケートが必要になるのでしょうか？\\n全部のお店が同じ数字になるわけではないと思っています。\\n例えば、1人100人くる店なら◯%くらいの◯件必要。や\\n◯件あれば信用度が±◯% など、様々な角度でお答え頂ければと思っております。\\n\\n④ネットで「因果分析」や「回帰分析」などという分析方法も発見したのですが、この結果に当てはめて活用する事はできますでしょうか。また、その場合の計算方法を知りたいです。\\nもしくは、できない場合、どうすればできるか。\\nそもそも「因果分析」や「回帰分析」は不要だ！などの意見がお聞きできれば幸いです。\\n\\n\\n■サンプルデータ\\n187件のアンケート取得のサンプルデータを添付致します。\\nシート1にアンケート結果の数字が出ています。\\nシート2枚目(真ん中)にはアンケート結果の詳細が乗っています。\\n\\n他にも、ご意見やご質問があれば是非お願い致します。\\n\\n\\n長くなってしまいすみません。\\n\\n皆さま、是非よろしくお願い致します！！！',)\n",
      "('情報のご共有、ありがとうございます！！\\n\\nめちゃくちゃ良い課題ですね！！\\n\\n他の方の回答を待ってから、週明け目途に回答しますねー♪', '<@UJRAL005U>\\nありがとうございます:blush:\\nよろしくお願いします！！', '週末NFL kaggle やる傍らデータ分析してみますね。\\nちなみに NPSである0~10の11段階評価の数値はどのようなデータでしょうか？\\nお客さんが選んだ数値という認識でよろしいでしょうか？\\n\\nあと、アンケート項目の相関に関して「マイナスになっているものがあれば信用しやすい」というのはどういう意味でしょうか？\\n\\n取り急ぎよろしくお願い致します。', '<@UNC7ZP60Y>\\n早速、ありがとうございます！！\\n\\n＞ちなみに NPSである0~10の11段階評価の数値はどのようなデータでしょうか？\\n＞お客さんが選んだ数値という認識でよろしいでしょうか？\\n\\nはい！そうです。詳細としては\\nNPSは「このお店を友人・知人におすすめする可能性がどのくらいありますか？」\\nという質問に対して、アンケート回答者(来店したお客様)が、0〜10の11段階で可能性を回答していただくものです。\\n\\n一応、NPSの参考記事も貼ります。\\n<https://www.nttcoms.com/service/nps/summary/>\\n\\n\\n＞あと、アンケート項目の相関に関して「マイナスになっているものがあれば信用＞しやすい」というのはどういう意味でしょうか？\\n\\n相関分析の結果は-1〜+1の間で結果が出ると認識しています。\\n-1は最も相関が低い(もしくは無い)、+1は最も相関が高いといった具合に。\\nですが、サンプルデータでは全部似たり寄ったりの数値でした。\\n一番相関が低いものと高いものの差が0.17といった感じで。\\n全部相関がある。という捉え方もできるんのですが、それでは飲食店は改善しきれないので、改善するための的を絞りたい訳です。\\nなので、低いものと高いものの差が大きければ、信用度があがるのになぁ。。。と思った感じです。\\n\\n\\nよろしくお願いします！！', '<@UPAHD46RL> さん\\n非常に興味深い話題でしたので、少し首を突っ込ませていただきます。データ分析に関しては勉強中の素人ですので、あまり参考にならないかもしれませんが、ご容赦ください。\\n\\nまず、最終的な目的はNPSの向上ですか？\\nそれとも、このリストの中からボトムネックを探すことですか？\\n前者であれば、アンケートの下準備が少し足りないのかと思います。(相関分析をしても成果を上げるのは難しいと思います。)\\n\\nまず、いきなりクローズドなアンケートを始めるのではなくて、オープンでより本質的な質問のほうがいいかもしれません。\\nなぜなら、そのほうが本質的なものが見えてくると思うからです。本質の一部として現れた二次情報を分析するより、クリティカルで本質的な質問を直接していき、集めた回答から、真のイシューを特定するほうがはるかに成果が出せると思うからです。\\n\\n具体的に述べるならば、\\n利用者のペルソナにもよりますが、\\n周辺の飲食店の競合の状況(学生が多かったらコンビニなんかも競合になりますし、高級店であれば同程度の所得の方の外食で利用されている店舗は周辺でなくても競合になりえます。)を踏まえて、なぜそこではなくこちらを利用するのか、利用者に直接聞くほうが、想定していなかった変数が得られる可能性が高く、課題発見に直接的につながると思います。\\nまた、他の外食で利用するお店を直接聞いて、競合を特定しそちらの店の優位性を聞くことで、より本質的な課題に近づけるかもしれません。\\n\\nもっと言えば、ロイヤリティの高い顧客には直接このお店を気に入った「きっかけ」を聞くといいかもしれません！！\\nそれがお店の強みになりえます！！', '<@UNFAV5EDB> \\nありがとうございます。\\nアンケートの内容に関して参考にさせて頂きます！\\nアンケート内容も様々な質問を用意しているのですが、今回のこの質問については、NPSを高めることが目的となります。\\n\\nRiitaさんが仰る通り、これだけのサンプルだと成果を上げることは難しいかとは思いますが、定性的なものと、定量的なものの結果を見ながら、質問は定期的に変更し、何度も実施して行く予定です。(一回の質問で量が多すぎると回答率が下がる)\\n\\nその中で、どこに重点を置いて改善や質問を重ねるべきか。などを知るためにも、この質問ではNPSの原因追及方法を聞いております。', '----------------------------------------\\nアンケート設計に関して\\n----------------------------------------\\n\\nまず、アンケート結果の得点に影響している要素として、\\n\\n①ユーザーの特性\\n②ユーザーの好み\\n③店舗の提供クオリティに関するバラツキ\\n④店舗の提供しているサービスレベル\\n\\nの4つが影響していると考えられます。\\n\\n理想を言うと、これらを切り分けて分析できるようにアンケート設計をする必要がありそうです。\\n\\nそれぞれ解説しますと、\\n\\n①ユーザーの特性\\nこれは極端な例になりますが、例えばアンケートに答えた方が、「全てのアンケートに4点をつける」といった特性がある場合、その4点にはほぼ価値がありません。\\n\\n一方で、100件中95件は3点をつける人が4点をつけた場合には、非常に価値を持ちます。\\n\\nなので、1店舗、1ユーザーの集計ではその数個別の値が高いか低いかの判断は難しいです。\\n\\n1人のユーザーに複数店舗をレビューして貰って、レビューがどの程度の価値を持つのか、評価した上で使用する必要があるかと思います。\\n\\n\\n②ユーザーの好み\\n「味に満足いかなかった」と回答した人が、苦手な味だったのか、そもそもクオリティが低かったのかを切り分ける必要があるかと思います。\\n\\nこの場合は、同じようなレパートリーを出している店と比較して味の評価が悪いなど、店舗間での比較が必要になってくるかと思います。\\n\\nまた、誰かが苦手な味だったとしても、その味が好きな人もいるので、「NPSの平均値を上げる」という結果になっても、「高NPSの人（口コミで広げてくれる人）が減る」という結果になるかもしれません。\\n\\n\\n③店舗の提供クオリティに関するバラツキ\\n\\n恐らく、捕らえたいものとして、「均質なサービスが提供できているのか？」という部分があるかと思います。\\n\\nこれに関しては、同カテゴリの店舗と比較してバラツキ（分散）が大きいのか、低評価が多いのかといった視点が必要になって来ると思います。\\n\\nマニュアル化されてきっていない店舗などではバラツキ、もしくは低評価の割合が多くなる可能性が高いかと思います。\\n\\n悪いサービスをするのはもちろん、高級レストランといったレベルが高い店が普通のサービスをするというのもバラツキに入ると思います。\\n\\n\\n④店舗の提供しているサービスレベル\\nこれが一番捕らえたい物だと思います。\\n\\n単純にNPSの集計をして、同業他社と比較するだけで概ねNPSの集計値としては問題ないと思います。\\n\\nただ、NPSに与える要因を調査するとなった場合は、上記のような要因を考慮して分析をする必要がありそうです。（データも少なくなりそうなので、1データの質を高めないと間違った判断をしてしまいがちなため。）\\n\\n\\n■ 方向性\\nたくさんデータを取るのも大変でしょうし、まずは、1カテゴリである程度信頼をおけるモデルを作るのが良いのかと思います。\\n\\n完全にイメージですが、30店舗 × 同じ100人程度のデータがあれば、プロトタイプを作るには十分なデータが溜まるんじゃないかなぁと思っています。', '分析方針はまた後ほど！', '成る程！！ありがとうございます！！\\nよろしくお願いします！', 'ちなみに、前述での相関係数の話ですが、\\n\\n1に近い・・・正の相関がある\\n-1に近い・・・負の相関がある\\n0に近い・・・無相関（関係がない）\\n\\nですので、特にマイナスが出てなくても不自然ではないかと！', '----------------------------------------\\n分析方針案\\n----------------------------------------\\n以下のような心理バイアスがかかってしまうので、定性的な質問項目は非常に難しいのではないかと思います。\\n\\n<https://uxmilk.jp/74434>\\n\\n&gt;なぜなら、味はお店の雰囲気や接客、盛り付けなどで大きく感じ方が変わるからです。\\n\\nこちらに関して、アンケートの結果から見ても、「体験」と、「味」の区別がついていないんじゃないかなぁと思います。\\n\\nなので、定性的な評価はNPSだけにフォーカスするなどと割り切って、「直接的にアクションに繋げられる項目」を質問項目に入れてあげるのが良いのではと思います。\\n\\nもう少し具体的に改善に移せるような質問項目、もしくはトラッキングをするのが良いのかぁと思います。\\n\\n例えば、「遅い」と感じる原因を考える場合は「オーダーから提供までにかかった最長のフードの時間」というデータを取る必要がありますし、\\n\\n衛生面のチェック項目で言うと、「トイレにごみは落ちていなかったか？」、\\n\\n接客で言うと、「おススメのメニューを聞いた時に答えてくれたか？」\\n\\nといった項目であったりと、\\n\\n「これが分かれば、こういった改善ができる」\\n\\nという、具体的な改善策とセットで質問項目を作ってあげる必要があるかと思います。\\n\\n----------------------------------------\\n上記データセットが揃った上での分析\\n----------------------------------------\\nNPSに対して重回帰分析をするというアプローチもありなのですが、「ファン」を増やしてくのが重要だと考えると、\\n\\n・各ユーザーに対して「高NPS」を出すかどうかを判定するモデル（決定木系）\\n\\n・店の特徴、提供サービスから、「高NPSユーザーの比率」を予測するモデル（決定木系）\\n\\n・変数間の関係を図示するモデル（共分散構造分析）\\n\\nなどを作ってあげると良いのかなと思います。そうすることで、各変数がどのように影響しているのか、影響度はどの程度かなど、評価してあげることができます。\\n\\nまた、全体的なアンケートの方向性として、\\n\\n①どんなアクションがどの変数に影響を与えるかの事前分析をしておくための多数のアンケート項目があるアンケート\\n\\n②実際の店舗で聞く際の簡易的なアンケート\\n\\nを別ものとして考えてあげて、②のアンケートで「接客が悪い」と評価された際に、①を元に「AとBとCに問題がある可能性がある」といったことが提案できるような方向性を示してあげるような使い方が良いのかなぁと思います。\\n----------------------------------------\\n\\n色々書きましたが、まずは、「何が分かるとどんなことができるようになるか？」という具体的なイメージを固めるのが最優先かなーと思います！！', '<@UNFAV5EDB> <@UMQ7CDJUR> <@UJRAL005U>\\n\\nみなさん、ご回答ありがとうございます。\\n\\nちょっと理解が追いつかない部分もあるので、まずは整理して質問項目の構築に力を入れてみようと思います:thinking_face:\\n\\nその上で行き詰まることがあればまたお力を貸していただければと思います。\\n\\nよろしくお願いします:pray:', 'ちょっと情報多すぎましたかねｗ\\n\\nまた何かあったらご質問ください♪')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('↑是非、皆さん考えてみてください！\\n\\n特に、問題整理やコンサル、PMのような動きをしたい方には良い練習になると思います！！',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('マーケティング', '可視化', '回帰分析')\n",
      "('練習がてら分析してみました。マーケティングではなくあくまで分析手法の観点になります。\\nまた、多変量解析はちゃんと勉強していないのでツッコミ所満載になると思います笑\\n是非、ツッコミお願いいたします。下記、１〜３の順で考えてみました。\\n１、２は大きく間違っていないと思うのですが、３はかなり怪しいです。。（取るべき手法として適正か？）\\n\\n１、データを可視化\\u3000→\\u3000傾向を感覚的に捉える\\n２、相関分析\\u3000→\\u3000NPSと各パラメーターの相関を捉える、パラメーター間の相関を捉える\\n３、重回帰分析\\u3000→\\u3000NPSに対する各パラメーターの影響度を調べる',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('コストパフォーマンス',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('メニューアイテム',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('提供速度',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('盛り付け',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('味',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('接客',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('グラフにしてみると、\\nNPSに対して、コストパフォーマンス、提供速度、味、接客\\u3000あたりが効いてそうです。（中央値が高いとNPSも高い傾向あり）',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('次に相関係数を求めますが、\\n順位データの相関係数は「ポリコリック相関係数」で求めるとのことなので、\\nこれをRで算出しました。\\n<https://www.slideshare.net/mitsuoshimohata/ss-24419059>',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('川崎 さんが出されていた相関係数（おそらくピアソンの積率相関係数）と大きく結果は変わりませんでした。\\n味、コスパ、盛り付け、接客、メニュー、提供速度の順にNPSと相関が高いです。',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('回帰分析',)\n",
      "('重回帰分析にかけるに当たって、悩ましいのは各パラメータ間の相関係数が大きく「多重共線性」の問題が懸念されることです。例えば、上の表で「盛り付けー接客」間の相関係数は0.73と大きな値となっています。取り敢えず、相関係数が0.7以上のパラメータの片方を除いて重回帰分析にかけることにしました。捨てるパラメータ数を最小にしたかったので「盛り付け」パラメータを除くことにしました。\\n<https://xica.net/vno4ul5p/>',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('回帰分析',)\n",
      "('重回帰分析した結果が以下になります。',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('回帰分析',)\n",
      "('結果を見ると、それぞれのパラメーターの係数で有意なのは「コスパ」と「味」のみになりました（p値が0.05以下）。\\nなので、「コスパ」と「味」以外のパラメーターを除いて重回帰分析をやり直します。',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('NSP\\u3000＝\\u30000.7395×コスパ\\u3000＋\\u30000.9446×味\\u3000\\nとう結果になり、やや味の方が影響が大きい結果となりました。',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('また、必要なサンプルサイズについてですが、それぞれの係数の精度という観点で考えました。\\n例えばコスパの係数（0.7395）を信頼係数95%で、信頼区間を5%以下にするためには37000程度のサンプル数が必要と\\nいう結果になりました（以下のサイトと東大赤本を参考に計算）\\n<https://bellcurve.jp/statistics/course/9129.html>',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('回帰分析',)\n",
      "('まとめますと、\\n\\n【結果】\\n重回帰分析で有意になった係数は「コスパ」、「味」であり、これらを改善すればNPSが上がりそう\\n\\n【信用できそうなこと】\\n・ポリコリック相関係数\\n\\n【怪しいこと＝有識者にお聞きしたいこと】\\n・順位データに重回帰分析を適用して良いのでしょうか？\\n・もし不可であれば、順位データ向けの分析手法には何がありますでしょうか？\\n・多重共線性の問題をどうやって回避するか？\\n\\u3000（コレスポンデンス分析などで説明変数を纏めるとかでしょうか？\\n\\u3000今回の例で言うと「コスパ」は色々な要素が混ざっているように思われます）\\n\\nデータ分析がかなり難しいことが分かりました笑',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@UPAHD46RL> ( <@UMQ7CDJUR> <@UNFAV5EDB> <@UNC7ZP60Y> )\\n分析方針に関してまとめてみましたー！\\n\\n分析するというより、「分析をするに当たってどんなデータを取得すれば良いか？」の話が主でしたが、参考になれば幸いですー！',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('分析始める前のデータ取りが非常に重要と言うことですね。\\n分析手法は勉強すれば、ある程度身に付きそうだけど、どうデータを取るかといったところは\\n実戦で鍛えていくしかなさそうですね。。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('小竹(fishb)', 'yuji.imuta')\n",
      "('設計',)\n",
      "('そうですねー！\\n\\n結構時間かけてやって頂いたと思うのですが、「分析する前から良い結果が出る可能性が低い」という状況などが想定される場合は、着手する前にしっかりと状況を整えるといった対応が非常に重要になりますー！\\n\\n分析するのって、結構時間かかりますからねー！！',)\n",
      "('ちょっと脱線しますけど、「アンケート設計に間して」を読んでいて、最近話題になってる食べログ問題を思い出しました。\\n\\n・採点の単純な平均だとサクラやbotに点数を操作される\\n・なので、たくさんレビューをしてる人、レビューが評価されてる人の点数を重み付けするなどして調整する\\n・「調整式」は開示してしまうとまたハックされてしまうので開示できない\\n・しかし、調整後の評価、が納得感のあるものでないと、「恣意的に調整してるのではないか」と疑われてしまう', 'レビューサイトの評価は難しいですよね。。。\\n\\n公開前提としていないクローズドなアンケートなので、上記のような感じは少ないかなぁと思っています。', '遅い反応になってしまうのですが、\\nなにが利いてるのかって判断する時って手法は主成分分析なのかなと考えたのですが、どうなのでしょう:thinking_face:', 'モデルの仮定作りが職人芸でめちゃくちゃ難しいですが、共分散構造分析とかは一つの手なのかなーとおもいますー！\\n\\n<https://note.mu/hasegayu1002/n/nfb701bed412d>', '<@UMG0947NY> ', 'なるほど。そういう慣れのような要素が必要になってくるのですね・・ありがとうございました！')\n",
      "('はやと-休学中の文系学生',)\n",
      "()\n",
      "()\n",
      "('キャリアの質問について、オフ会の聞きそびれだったり自分の方の開示情報不足でここで質問させていただきます。質問内容が被っちゃって答えて頂いた方に不快感を与えてしまったらすみません。',)\n",
      "()\n",
      "('はやと-休学中の文系学生',)\n",
      "('Riita Satsuki', '西岡健一', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('AWS', 'GCP', 'BQ', 'クラウド', '機械学習', 'ML', 'BigQuery', 'digdag', 'IoT', 'kaggle', 'SQL', 'データサイエンティスト', 'ポートフォリオ', 'マーケティング', '初学者', '統計')\n",
      "('将来データ基盤整備（クラウドの）とモデル作りの二つを軸としながら勝負したいと考えてて、データ基盤についてはとりあえずまず来月からAWSとGCPをやろうと思ってますが（もちろんインターンも探しながら、内容は資格とスクールで検討、両方？）この考えは大丈夫でしょうか？\\n\\nクラウドインフラをやるのについて、\\n勉強好き＋コード書くのが好きというか適正あるからで、物の片付けなのの整理ができないという欠点が自分にはありインフラの構築はそういう素質が大事なイメージがあるのですが大丈夫でしょうか？（自分がやる予定はクラウドインフラ限定）\\n\\nこの二つについて教えてもらえると嬉しいです。',)\n",
      "('ぼくも似たようなスキルセットを新卒までの2年半くらいで揃えたいと思ってます！\\n\\n経営改善をマーケティングと業務効率化を用いて推進する\\nそのための手段として必要であれば、統計や機械学習を利用し、\\nデータ収集や実装にクラウドを利用する。\\n\\nといった経営改善がまるっとできるようになるのが理想だなって感じです！！\\n\\n勉強の仕方とかはぼくも興味あるので、是非聞きたいです。', '<@UKT5BQD3P> 今日はお疲れさまでした。\\nデータ基盤についてはAWSかGCPのどちらかに絞ったほうがいいと思いました。１つを極めるのが結果的に最短です。私自身はGCP派ですが、質量ともに軍配が上がるのはAWSだと思います。若人はAWSが無難かなぁと。\\n\\nあと、方針としては口頭で伝えたとおり、侍エンジニア塾で有識者のインストラクターにお願いしてAWS(orGCP)環境で機械学習環境を一緒に構築して学んでいくのが最強かと思います。費用は安くはないですが、時間は超最短です。\\n有識者に相談しながらオリジナルカリキュラムを作くり、自分に必要なものを見極めてプラン立てをしましょう。\\n自社サービスの強烈プッシュとなってしまいますが、サービスについては胸を張ってお勧めできます。', '<@UKT5BQD3P>\\n２つ目の片付け整理の適性についてなのですが、仕事には全く関係ないと思っています。\\nこれまで何人かの超絶インフラエンジニアと仕事をしましたが、片付けできるできないの相関は全く感じられませんでした。\\n間違いなく共通しているのは、プロフェッショナリズムや仕事の美学/インフラの美学を持っているか？ですね。\\n\\nデータ基盤構築とモデルづくりに心がトキメクなら間違いなくその素養はもっているはず。突き進んで頑張って下さい。\\n\\nちなみにその二軸は私ともろ被りなのでライバル関係になりますね', '<@UNFAV5EDB> \\n僕のやりたいことを少し経営に寄せたって感じっぽいですね:thinking_face:\\n機械学習面はやっぱりkaggleが安定かなって思います、データ基盤はまだ検討中ですね笑笑', '<@ULQ3D7T2Q> \\nうおおお長文でありがとうございます！\\nなるほど、確かに一気にやろうとすると中途半端になりそうですね、、、awsに絞ってみます、スクールは値段と相談ですね笑', 'インフラエンジニアについてですが、その適正面で大丈夫っていうことを聞いて安心しました、安心してインフラをやろうと思います〜', '西岡さんと競合になるのは辛そうですが、AWSなら少しずれてる気がするので頑張ります笑笑', '（あと、仕事の説明書の方の返信もらえると嬉しいです）', '<@UKT5BQD3P> ごめん(&gt;_&lt;) 返信しました（汗）', '<@UNFAV5EDB> インフラからデータモデリング、更に経営コンサル方面とは！コンサル方面は別の意味で修羅の道ですからね。\\nこれが体現できれば無双ですよ:star-struck:', '<@UKT5BQD3P> \\nGCPかAWSにフォーカスする方向性は、賛成です！！\\n\\nAWSからリプレースがあったりするくらいなので、分析中心のキャリアであればGCPの方が良いかなーと思います。\\n\\n具体的な学習は、どういった方向性で考えているのでしょうか？\\n\\n多分そこの方が大事な気がする。\\n\\n補足ですが、今関わってる感じだと、ロジカルシンキング、抽象化思考周りで「考える技術、書く技術」とかの勉強した方が今持ってるスキルは活きると思いますー！\\n\\n大学4年の論文だったり、社会人なってからでも比較的身につけやすい領域かとは思うので、後回しでも良い気はしますがw', '<@ULQ3D7T2Q> \\nありがとうございます〜！！\\nそうですね！コンサルティングファームでデータサイエンティストってイメージのキャリア想像してます！\\n\\n<@UKT5BQD3P> \\nAWSとGCPに関してなんですけど、\\nぼくはWeb系のキャリアがあって両方使っているんですが、基本的にはGCPの方が使い勝手がいいような感じがします。\\nネットワーク上の難しい部分も隠されているような感じがありますし、ドキュメントも非常に分かりやすいです。\\nGKEもEKSより手厚くて、kubernetesもGoogleなのでやりやすいと思います。\\n\\nAWSはAuroraDBが非常に使いやすいです。\\nサポートチームが充実していて、テキストチャットでのサポートがGoogleよりもさらに親切な感じがあります。\\n\\n分析で言えば、やはりGCPですかね。\\nログ集めとモニタリングをしてくれるstackdriverが使いやすくて、\\nデータ量が多くなってくると、bigqueryが安くて早いです。\\nCloudMLはあまり詳しくないのですが、どちらもML系のサービスがあります。\\n', '<@UJRAL005U> \\n今のところAWSならスクールでがっつりやるが一番の選択肢でインターンも受からせてくれるならインターンでもいいなって考えてました。GCPなら正直資格くらいしか思いつかなかったですね、、、\\n分析というか、大きなデータでモデリングするとかweb系の領域に近いことを行うのもいいかなって考えてるんで（あとなんとなくAWSをやってみたいって思ってたというのが大きいです）そこはどっちにするかはもうちょっと考えてみます。\\n就活では目に見えるものを増やしたいんでクリティカルシンキング周りは就活終わったらやろうと思います笑笑', '<@UNFAV5EDB> \\nやっぱり分析だとGCPなんですね、個人的にAWSの方に気分が寄ってたんでくぬぬって感じです、、、\\n両方使用経験があるんですね！\\n分からない単語がたくさん出てきてるんでちょっとググりながら考えてみます', '<@UKT5BQD3P>\\nまずはここら辺で紹介されている無料カリキュラムで勉強しつつ、分からない所をここで質問するみたいな使い方をして頂けるといいのかなーと考えています。\\n\\n<https://cloud.google.com/training/>\\n\\n英語しかないコンテンツもあると思いますが、英語大丈夫っぽいので、それであれば、Couseraのコースとかも検討してみるのが良さそうですね！\\n\\n先日の ml study jam でもインフラよりの講座もありましたし！\\n\\nそれでお手上げであれば、スクールを選ぶというのがリスクない順序なのかなぁと。\\n\\nスクールを検討するのであれば、「メンターが付く」、「演習などで実践的な経験が積める」といった所に比重を置くのが良いかと思います。\\n\\nコンテンツだけなら安価なものだったり、公式が出しているものがあったりするので。', '<@UJRAL005U> 丁寧にリンクありがとうございます！今からリンク見てみます', '確かに無料のところから始めるのがいいかもですね〜', '<https://www.coursera.org/search?query=google%20cloud%20platform&amp;>', 'couseraにも結構コースあるっぽいです', 'とりあえずawsとgcpどっちも軽く触ってみようと思います〜', '触ってみて判断するって感じですかねー？\\n\\n使いやすさや若干の差はありますが、基本的な機能は大体同じものを揃えてるので、一旦は片方切り捨てた方が理解スムーズだと思いますー！\\n\\n最初は慣れないこと多くて多分混乱するので！', 'そうなんですね！じゃあそれも考えないと、、、笑笑多分やるのは来月からになりそうなのでそれまでに決めようと思います:thinking_face:', '<@UNFAV5EDB>\\n二つの違いを調べてて気になったのですが、機械学習やデータ分析以外の場面でGCPがが使われるのってどんな場面があるんですか？', '少し前まではAWSがWeb系では良く使われてて先行してたイメージがありましたが、基本的なサービスに関してはあまり変わりが無いのかなぁと思います。\\n\\nAWSからGCPに移行した話、GCPからAWSに移行した話などはちらほら出て来るので、そこら辺の理由とかを調べてあげると、メリデメが分かるのかなーと思います。', '<https://developers.cyberagent.co.jp/blog/archives/12739/>', '<https://www.apps-gcp.com/gcp-aws-service-correspondence-comparison-2019-02/>', '<@UJRAL005U> リンクありがとうございます、二つ目はまだ読んでなかったので実際に読んでみようと思います。', 'まぁ、初学者が気にするほどに違いはない気がしますねｗ\\n\\n分析が関連する所だと、IoTはAWS、分析基盤やMLはGCPに軍配があるって感じでしょうか。', 'IOTっていうとハードウェア系っていう感じでしょうか？\\nなんか最初にweb系行くのにrailsかphpどっちで勉強するかみたいな些細な違いなんですかね笑笑', '<@UKT5BQD3P> \\nAWSを使う場面とGCPを使う場面があるというよりは、基本的に同じようなものを提供しているので、どちらを勉強してもあまり変わらないですよ〜\\nGCPの勉強をすればAWSも同じなので使えるようになりますし、逆も然りです！！\\n\\nどちらかと言えば、僕のおすすめは、Web系ではGCPです。\\n理由は上記です。\\n\\nGCPの基盤(GKEが僕は得意なのでそれ)とAWSのelastic searchを繋いだりとかは頻繁にある事ですし、一旦GCPでいいと思います…', '<@UNFAV5EDB>\\nあ、そうなんですね！どちらか学べばもう片方もわかるようになるのはそれは心強いです\\n割とAWSの方がシェア広いイメージだったんで、web系でGCPがいいっていうのは結構意外でした、今までawsかなって感じでしたが割とトントンくらいになりました笑\\n結局どっちやってももう片方もセットで使うこともあるって感じですかね、むっちゃ丁寧にいろいろありがとうございました:man-bowing:', 'rubyとphpの違いくらいの違いって認識がそうって感じです！笑\\nAWSはGCPが出来上がる前からずっと大きなシェアを持ってますから、Qiitaとかは充実してると思いますが、\\nWeb系の流れとしては、AWSで構築したインフラをGCPに移行しているというような感じです。', '<@UKT5BQD3P>\\n結局BigQueryがあるか無いかが一番のポイントって話の記事です。\\n<http://uma66.hateblo.jp/entry/2019/10/17/012049>', 'あとビジネスとか、運用の視点入れるとパイプライン管理が重要になってきます。\\n今のところ過去のどの現場でもdailyの処理が失敗しないで動いているデータ分析基盤は見たことがありません。\\nそうなると独学よりどこかインターンで現場行く方がありかなーと思いますよ。\\nAirflowとか個人だと高すぎて使えないw\\n', '<@UJRAL005U> 共有ありがとうございます！そんなにBigquery ってすごいんですね、、、', '<@UL2TY2ERL> \\n基盤系は実務経験はほんと積みたいなって考えてます、ちょっと自分でポートフォリオ作っていろんな会社に話聞きに行こうと思います:thinking_face:', 'bigqueryって普通はstackdriverから繋ぐので、VPNの外にあるからと言って困ることそんなにないですよ。\\nだから、別にAWSのEKSとAuroraDBをベースにしたWeb基盤に差し込めますよ。\\nkubernetesのWebサーバーのpodにfluentd置いて、stackdriverにログを流す感じです。\\n実際、そういうAWSベースの基盤何回も作ったことあります。', 'AuroraDBのデータはdumpSQL走らせないと行けないですけど。\\nもしくは、embulkのbulkloadか…\\ndigdagで日毎とかに実行すれば不便はないです。', 'うおおおおなんか聞いたことのない単語がたくさんあります、、、\\nとりあえずbigquery単体で使うならawsでも大丈夫っていう感じっぽいですね笑笑', '<@UNFAV5EDB> 丁寧にありがとうございます:clap:', '結局GCPを学んでいくことにします、皆さんありがとうございます！')\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('API', 'GCP', 'クラウド', '機械学習', '設計', 'BQ', 'SQL', 'データサイエンティスト')\n",
      "('この間のクラウドの件で、GCPを勉強することにしました。\\nその上で、勉強をしながらも実際にクラウドを扱うインターンに実際に行ってみたいと考えているのですが、その際にデータ分析系とインフラ両方にまたがる職がとても少ないので、今回は一旦GCPをインフラとしているというところまで条件を広げてWebアプリケーション製作系のインフラエンジニアにも応募をかけてみようと思っていますが、自分はこの判断についていいか良くないかが分からないのですが、これについてどう思いますか？',)\n",
      "('<@UKT5BQD3P>\\n個人的には、それでインターン先が見つかるのであればその方向性で全然問題ないと思いますー！！\\n\\n理想としてはBigqueryを使ってる会社（広告系など、業界絞れば結構ある？）ですが、マイクロサービスを作ってシステム間で連携しながらサービスを開発してるような開発体制を取っているような会社が良さそうですかね！！\\n\\n理由としては、分析のサービスを実装する際にメインのシステムと切り離してマイクロサービス化することが多いので、「マイクロサービスを立ち上げてAPI連携する仕組みを作る」という部分で応用が利くからです！', '<@UJRAL005U>\\nなるほど、みどりさんありがとうございます！\\nAPIの連携とかも絡んでくるんですね、ちゃんとrailsに組み込んだりとか勉強しないと、、、', 'あー、railsに組み込む側と分離してAPIを作るって感じだから、railsやフロントエンドから呼び出す所は結構大事だったりするけど、むしろ呼び出す先だったり、REST API設計だったりって所が大事なんすよね。\\n\\nアプリケーションエンジニアを目指したいならRails勉強しておいて損はないけど、データサイエンティストや機械学習エンジニアはマイクロサービスの側を作ることが多いから！', 'あ、そうなんですね！設計とかあんまりイメージつかないんでやってみたいです笑\\nとりあえずrailsチュートリアルを一周したらアプリケーション系は今の業務だけに留めておいて、wantedlyだとあんまり見つからなかったんで色々なサイトググって探してみます:joy:', 'APIを実行するだけだったら簡単だから、API実行してみると良いっすよ！', 'notebookから、requestsとかをインポートするとAPI叩けるから、そこから取ってきたJSONをパースして集計してみると、データ分析に関するAPIってどんなのが必要なのか分かるようになると思いますー！', '<https://api.slack.com/methods/channels.history>', '業務でpostman使ってapi叩いてそれをhash型に直したことはあります！', 'なるほど！であれば、イメージは掴めてそうね！！', 'そんな感じで、機械学習だったりデータ分析システムって、内部API作るような感じになるから、Railsでゴリゴリアプリケーションだけ作ってるような会社でやっても、若干進む方向性ズレちゃいそうだなって思った感じです！', 'インフラの仕事でアプリ制作のインフラをやる時はやることがズレやすそうなので気をつけないとですね、、、回答ありがとうございました！', 'あくまで個人的な意見なので、他の方の意見なども聞けると良いですねー', 'ちょうど相談受けた案件でmySQLの乗り換えっぽそうな案件入りそうだけど興味ある？', '<@UL2TY2ERL> \\n興味あります！乗り換えの具体的内容な会社の出社場所などについて詳しく聞きたいです。', '在宅です。\\nうちでもいいけど', 'なるほど、増田さんありがとうございます！詳しいことについて聞きたいことまとめて電話の方が早そうな気がするので15分ほどどこかでお電話しても良いですか？\\n直近だと\\n今日の夜9時半〜11時\\n明日の11時〜17時、20時〜22時で対応可能です。\\n\\n', '来週話すからそのあとで良ければ', '来週って何のイベントですか？', '案件についてですw', 'あ、そういうことか把握しました笑笑', '了解です、また話したら教えて下さい！')\n",
      "('maimai',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'ﾋﾛﾘｰ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('GCP', '時系列', 'AWS', '設計', 'AutoML', 'テキストマイニング', '機械学習', 'ML', 'AI')\n",
      "('メーカーの営業支援アプリに、クライアントからの要望で\\n分析機能を追加することとなりました。\\n現在実装されているの「意見箱」で収集したデータを活用したいです。\\n\\n意見箱の項目は、性別、年齢、製品、製品に関する不具合報告や要望、フリーテキスト、画像の添付です。\\n\\n製品が例えばPCだとして、PCのパーツ毎に分類して、どのパーツの不具合が多いかなどを出したいと考えています。\\nGCPのAutoML Natural Languageを利用してフリーテキストをエンティティ感情分析になるのかな？と考えています。（GCP未経験ですが）\\n\\n何のために分析したいか、という目的がはっきりしていないため\\nどのような分析方法を用いればいいかもわからない状態での質問で\\n恐縮ですが、意見箱のデータを使うなら着目した方がいい点や、GCPよりAWSの●●がいいよなどを教えていただけますと助かります。宜しくお願いいたします。\\n\\nアカウントはGCP、AWS、IBM、MS全てあります。',)\n",
      "('ちょうど、本日ユーザーからの問い合わせ分析の依頼を受けました。\\nいろいろ夢はありますが、やることは1つ1つです。\\n- データを自由に加工出来る環境に置く。\\n- 時系列で並べてグラフを作る。\\n- そもそも何が問題なのか議論する。\\n- データで何をしたいのかビジネス側と相談するです。\\n正直テキスト解析は、本質の意味を見抜くのは無理なのでタグ付けにします。\\n\\nそして、何がビジネスインパクトがあるのか考えます。', 'MVPはこれを目指すのが良さそう\\n&gt;テキスト解析は、本質の意味を見抜くのは無理なのでタグ付け\\n\\nウチもゲーム案件で\\n似たような感じの、PJTが具体化しそうなとこで、全体設計悩んでます。。。\\nリリースしたアップデートやイベントのユーザーの声をアンケート以外からも拾いたいということで、\\nゲーム関連まとめサイトコメント欄、SNS、掲示板クローリングして集めるところまでは技術的実現可能性あるけど、\\n集めた後どう表示させたらビジネス的にうまく使えるか定まらず悩み中。。。', '<@UMTMKBB1Q>\\n「目的を決めてください！」と突き放すのは簡単なので、自分がこういったケースに当たった場合にどうするかという視点で記載しますねー！！\\n\\nまず、機械学習を用いる以前に意見箱を設置した目的と、意見箱の活用事例に関してヒアリング、聞き込みをするのが良いのかなーと考えています。\\n\\n基本的に元々の目的の延長戦上に目的を置いて、既存業務のサポートとして、品質向上、時間の短縮といった所にゴールを置いた方が上手く行きやすいので！\\n\\nその上で、目的がはっきりしない状況で新たな取り組みをしたいのであれば、\\n\\n「何ができるか分からない」←→「目的が分からない」\\n\\nという所をループしている所があると思いますので、「この目的ならこういうことができます」というのをできるだけ多く（イメージとしては5種類程度）ピックアップしてあげれば良いのかなぁと思います。\\n\\nとりあえず3つ程度ピックアップしてみますねー！！\\n\\n■ユーザーの意見を分類したい\\n大量の意見がありすぎて、そもそもどんな意見があるのか分類できていないときなどですね。\\n\\nトピックモデルなどの教師なし系のアルゴリズムを用いて、その意見箱で話題になっているトピックを分類して、それぞれの特徴を分析し、知見を得るような形を想定しています。\\n\\u3000\\n\\n■話題の検知\\n&gt;製品が例えばPCだとして、PCのパーツ毎に分類して、どのパーツの不具合が多いかなどを出したいと考えています。\\n\\n話題になった言葉を検知して、その言葉と一緒に使われている言葉や、ネガティブ、ポジティブなどを判定し、話題に対して早急に施策を打つことを目的とします。\\n\\nやることとしては、お二人のお話にある通り、タグ付け＆時系列表示みたいな感じが良いかと。\\n\\u3000\\n\\n■属性情報ごとの反応を知りたい\\nこちらに関しては、単語の分割＆集計を単純に色んな軸でやってあげるだけで結構な知見が得られると思います。\\n\\n全体と比べてその属性の中でだけ言われていることを言及しているなどですね。\\n\\n例えば、年齢が高めの方が、「文字の大きさ」に関する単語を多く使っていたら、年齢に合わせて文字サイズの調節機能を促したり、別の老眼の人に向けた商品購入を促したりに活用するといったイメージです。\\n\\n----------------------------------------\\n\\n落とし所としては、こういったテーマを何個かピックアップっぷして、「いやいやそうじゃない、もっとこういう風なことはできないの？」という意見を引き出せたら勝ちって感じですねー！！\\n\\nある程度意見を言いやすい環境なら、目的を整理するためのブレストと、スコープ決めのディスカッションはやった方が良いですねー！！\\n\\n発散中心の会議と内容をまとめる会議は別会議にした方が上手く行きやすいです。\\n\\nあと、会議の時だけで良いので、ある程度の有識者に同席して頂いた方が良いと思いますー！', '<@UL2TY2ERL>\\nコメントありがとうございます！\\n&gt;- 時系列で並べてグラフを作る。\\nどんなグラフを作ればいいのかということばかり考えていて時系列の比較という大事な部分見落としてました！\\nビジネスインパクトについても考えなくてはいけないですね…初めてこのようなことに関わるのでその辺のリスクなどもしっかり勉強していきます。\\n\\nメインはテキスト解析になりそうなので、タグ付けの仕方？についてももっと調べてみます。まだテキストマイニングをしたことがないので、実際にやってみます。よければまた教えてください！ありがとうございました！\\n\\n<@ULKPET3UK>\\nコメントありがとうございます！\\nMVPとなるのでその方向で進めていきます♪\\n全体設計のアドバイスなどはできませんが、アンケート以外の声収集方法として、不満買取センターとFastaskはいかがでしょうか。\\n\\n不満買取センターの方はどれだけピンポイントでそのゲームについてタグ登録をしているのかがわからないので何とも言えませんが…（みんなの声も買わないとピックアップと新着の50件くらいしか確認できなかったので…）\\nfantaskはリーズナブルに声が集計できそうだったので紹介してみました。前に参加したAI展で聞いただけなのですが…\\n<https://www.fast-ask.com/>\\n\\n<@UJRAL005U>\\nコメントありがとうございます！\\n目的をこちらからいくつか提案して引き出すスタイルいいですね！ブレストの機会はありそうですので、やってみます。\\n意見箱も現状アンケートに近いものでフリーテキストは最後にあるだけの状態で活用ができていないような気もしています。意見箱以外に追加しそうですが、そのタイミングで目的についてのヒアリングができるよう働きかけたいと思います。\\n\\nわかりやすい具体例までありがたいです♪全てなるほどなあ！となりましたが、個人的には特に\\n&gt;年齢に合わせて文字サイズの調節機能を促したり、\\nこの辺がFAQ改善などにも使えそうで…ありがたくいただいていきます♪\\n\\n社内で共有して活かしていきます！ありがとうございました！', 'こうやって、分析系の実務に携われてる話が聞けて嬉しいです！！\\n\\n続報お待ちしてまーす♪')\n",
      "('maimai',)\n",
      "()\n",
      "()\n",
      "('追加質問です。\\n実際にクライアント様は何ができなくて困っていましたか？\\n\\n・お客様の声を集めてテキストマイングしたはいいけどどう活用したらいいかわからない。上に言われたからとりあえず集めて活用しろと言われた→目的がわからない→活用の仕方もわからない→仮説を立てられないレベルの相談ってありましたか？\\n何をしたらいいかわからないクライアント向けに、この業種ならこういう目的が多い、どの目的にしますか、この目的を達成するためには…こういう仮説を用意しましょうというサポートツール的なものがあってもいいなあと思いまして…',)\n",
      "()\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Riita Satsuki', '西岡健一', 'Satoru Mikami')\n",
      "('クラウド', 'BQ', 'GCP', '機械学習', 'AWS', 'ML', 'Docker', 'kaggle', 'データサイエンティスト', '転職', '統計', '統計検定')\n",
      "('データ分析基盤構築とアプリ系のクラウドエンジニアは個人的にはかなり親和性があるのかなと考えていて、データ構築基盤行うところからクラウドエンジニアには向かいやすいのかなと考えていましたが、これについて意見頂けると嬉しいです:man-bowing:',)\n",
      "('親和性は間違いなくあると思いますー！！', 'データ分析基盤構築の仕事をやってると、クラウドエンジニアに転身しやすいかとかって観点で大丈夫です？', 'みどりさん返信ありがとうございます、はいその観点で大丈夫です！', '確実に親和性あると思います！！\\n大丈夫です！！', 'ありがとうございます、それは自信になります！\\n親和性としては他の例で例えるとどれくらいですか？（例えばこの間のrubyとphpみたいなかんじで）', 'Webの基盤も、分析の基盤もクラウドを用いますが、使うGCP内のサービスが少し違う(一部同じ)という感じです。\\nどちらか転身するときは当然キャッチアップが必要ですが、\\nなにか始めるときにはつきものなので、大差ないと言っていいんじゃないですか？\\n\\nそのたとえで言うならば、\\nフロント(js)とサーバー(ruby, goとか)くらいの違いって感じですかね。\\n\\n多くのWeb系の企業では、サーバーやってるインフラエンジニアと分析基盤やってるインフラエンジニアって同じ人であることが多いので、そこまでの違いはないのかもしれないです。\\n(フロントとサーバーは同じ人がやっているということないですよね。)\\n\\nちなみに分析基盤ってデータの収集基盤ですか？(fluentd, stackdriver, redashとか )\\nそれとも分析の運用基盤ですか？(継続的再学習、ランタイム環境の均一化、autoMLとか)', 'ちょっと立て込んでて返信遅くなっちゃいました:man-bowing:\\nなるほど！どっちやるにしてももう片方の知識が少しは必要って感じですね、、、\\n正直自分は両方できるようになりたいので、最初にキャッチアップするのはどっちでもいいかなってイメージです！', '<@UKT5BQD3P>\\n返信遅くなりました。。。\\n\\nRiitaさんの意見で概ね問題ないかと思います。\\n\\n使っているサービスが違うので、結構な比率で学びなおさなきゃいけなくなるのは間違いないです。\\n\\nできる限りデータ分析で使われるようなサービスを抑えれる環境が良いですね！\\n\\nWebサービスに寄ったサービスに関しての学習をどこまでに抑えるかが結構難しいかもしれませんねー！\\n\\n（パッとWebサービスで使うけど機械学習周りだとあまり使わないサービスの例が浮かばなかったので、代表的なもの抑えておいて問題ないかと！）', '<@UJRAL005U> 体調良くなったみたいで何よりです！2人から意見を貰えたので信憑性が深まりそうです、やっぱりwebのインフラ周りの知識も多少必要なんですね、頑張ってインターン探します、、、', 'Web系で大丈夫であれば、いくつか紹介はできるかもしれませんー！', 'それはインフラ系っていうことですか？\\n今wantedlyで数打ちまくってるんで、ダメそうならお世話になるかもしれません:man-bowing:', '<@UKT5BQD3P>\\n詳細なポジションに関しては、状況に寄たっり、応相談って感じだと思うけど、インフラも触るWebエンジニア的な所かなー。。。\\n\\nお金が直接関わって来るところなので、インターンでGCPのコンソールから触らせて貰える環境って、なかなか難しいイメージあるんすよね。', 'うーんなるほど:joy:\\nやっぱり機械学習エンジニアやデータサイエンティストはたくさん求人があるんですけど、データ基盤系でGCPもってなると限られてくるんですよね、、、', '優秀なエンジニアがいる小規模チームでインフラ部分を教えて貰うか、タスク切り出せる余裕のある技術力の高い大企業かって感じですかね。。。', '大企業だと長期厳しそうなんで、とりあえず前者で当たってみます！', '個人的に、はやとさんの性格とそしては、行動量とアクションの速さみたいな所が取り柄だと思ってるのですが、\\n\\nそれって慎重さみたいな部分とはある程度トレードオフだと思ってて、インフラ系名前の通り基盤になる所なので、任せる人は超絶ビビりなくらいの人が良いなーと思うんですよねw\\n\\nなので、面接とかの時に気質的に大丈夫かな？と思ったりする部分がある気がしますｗ\\n\\n採用基準とかは、実際に採用担当している、\\n\\n<@UKY4VFB5E> さん、<@ULQ3D7T2Q> さんなどの意見が参考になるのではないでしょうか？？\\n\\nインフラをインターンに任せてるイメージが持てないのですが、どうなのでしょう？？', 'いや確かに、それ言われるとなんとも言えないです、、、\\n将来的にも保守運用のインフラエンジニアよりも、ガンガンサイクルを機械学習エンジニアかデータサイエンス系で回していくか0から基盤をゴリゴリ作る方がいいのかもしれませんね笑笑', 'ぼくは大企業で新規事業を企画書から立案した時は、インフラ自分で組みました。\\n要求レベルは高いのですが、いい刺激になりました。(kubernetesをterraformで)\\nあと、機械学習のMLopsとかbigquery導入とかはベンチャーで何度かやったことあります！\\n学生でもインターンでも、やりたいことを上長にちゃんと伝えればできる時が来ます！！', 'え、企画から全部やるって優秀すぎでは、、、背伸びして引き受けるって感じですね笑笑', '<@UNFAV5EDB>\\n前提として、どの程度インフラ知識あったのでしょう？\\u3000「任せたらやり切ってくれる」という信頼を作る所が結構重要かなーと思ってますー。', '<@UKT5BQD3P>\\n前回の相談で回答した通り、私としてはインフラは個人で学ぶぐらいでいいと思うんですよね。それよりも自分の強みを磨いたほうが良いかと思います。\\n\\nよほどの人員不足ではない限り、学びたいぐらいな人にはインフラを任せるイメージは湧かないですね。\\n\\nあまり最適解を求めすぎると部分最適になってしまいますよ。これから先はどう変わるかわからないので今自分が思うベストな方向を突き進むのがいいと思います。', '<@UJRAL005U> \\n割と最低限のDockerfileくらいはかけるよって感じでした。\\nフォローかなり手厚かったのと、\\n全てコードかしていたのでレビューができるってことが大きいと思います。', '<@UNFAV5EDB>\\n・やり切る熱意\\n・フォロー体制\\n・インフラに関するコードがレビューできる環境\\n\\nなどの要因がありそうですね。\\n\\n<@ULQ3D7T2Q>\\nそうですよね。学びたいインターンに任せるイメージは持てないですよね。。。\\n\\n<@UKT5BQD3P>\\n結論から言うと、「インターンで学ぶ」というマインドセットを捨てる所が一番大事な気がしますｗ\\n\\n企業もある程度の学習は許容しますが、インフラなどの重要な部分はなかなか任せられないので、どう突破するかの戦略は重要だと思いますよー！\\n\\nその戦略に時間かけるのであれば、何か得意領域を伸ばして教えられるレベルまで持っていくのが結果としては早い気もしますねー。勝又さんが「わらしべ長者戦略」って言ってるやつですね。\\n\\nデータサイエンスの知識で実践レベルまで持って行ければ、その技術で技術力の高いチームに入りつつインフラの実装などを強い人に学ぶことができるので、結果として習得も早いと思いますー。\\n\\nWebの実装、データサイエンスから徐々に隣接領域のインフラに攻めて行くのが良いんじゃないかなーと。\\n\\nもしくは、GCPのクラウド系の資格を取っちゃうとかすればある程度は実力示せるので良いかなとは思います。データサイエンスだったら、「kaggleでメダルを取っている」、「統計検定2級持ってる」みたいな感じの指標があると良いかと。', '<@UKT5BQD3P>\\n「どこまでのレベル感で学習するか？」というゴール設定は一度やった方がいいかもしれませんねー。\\u3000就活を見据えた時に、「色々やってるけど、全部学生としては優秀レベルで即戦力ではない」という所を目指すのか、「ある特定の技術に関しては、実務レベルに達していて、メンバーの持っていないスキルを持っている」みたいな所を目指すのか。\\n\\n就活で有利なのは多分後者だとは思いますが、就活の選択肢を視野広く持てるのは前者だと思いますー。', 'Riita Satsuki さんは恵まれているなと思いましたが、目利き力もあるなと思います。\\n\\nAWS的なキャリアでいうと\\n・ソリューションアーキテクト\\n・DevOps\\n・SysOpe\\nと３つに分かれるくらい専門分野が違います。\\n\\nアプリ作成社向けはソリューションアーキテクト、データ分析基盤の構築系はDevOps？、運用保守的はSysOpeという感じだと思っています。進みたい方向で専門力を上げていけばよいのではかなと思います。\\n\\n基盤構築系はベタランしか怖くて担当割り当てられない（基盤がだめならその上で動くサービスやビジネスが全部だめになる）ので普通の頭ならアサインしないでしょう。（新人でもやりきる人たまにいるけど、仕事めっちゃデキる人なので、転職オファーで別のとこにいき、残った基盤の後始末たるや・・）\\n\\nエンジニア業務未経験者は、ソリューションアーキテクトのアソシエイト試験で知識つけて、相手と共通の会話できる知識は持ってますよアピールが良いと思います。\\n一緒に働くひとからしたらとりあえず話は通じるので。\\n\\nもちろん、入りたい会社がAWSの資格を評価できるくらい、クラウド化を推進している会社が前提です。まあ、GCPでも同じです。資格取得がいいという話ではなく、わざわざ資格も細かく別れているということは、専門性が違うよというのを頭に入れて戦略的に学ぶといいと思いますよ。', '<@ULQ3D7T2Q> \\n西岡さんありがとうございます、部分最適になるっていうのすごい響きます、、、いろいろなものをやるにしてもあくまでも目的は自分が新卒で何をやりたいかを決めるためっていうことに限定した方が良さそうですね。もうちょっといろいろ整理してみます。', '<@UJRAL005U> \\nたしかにすごいその考え方は的を得てるなと感じます、、、就活終えるまでは器用貧乏でも終わってからは後者にならないとなとは思います。', '<@UKY4VFB5E> \\n三上さんありがとうございます、Devopsしか知りませんでした、、、構築と運用で別々にキャリアがあるんですね\\n確かにベテランの方が慣れてるんでミスも少なそうで基盤構築には適してるのかもですね、その観点は無かったです:thinking_face:', '（それにしてもさつきさん（名前間違ってたらすみません笑）強すぎではって感じです:joy:', '<@UKY4VFB5E>\\n流石マネージャーという感じの意見で、めちゃくちゃ参考になりますね！！\\n\\n新人でかつ、腰を据えてやってくれるインフラエンジニアとかはSSRレベルに希少って感じですかねｗ', '基盤も任せられる最強の新卒インフラエンジニアは、ISUCONの決勝までくるような学生チームですね。さらに優勝までした学生チームは各社で取り合いｗ', '<@UJRAL005U> さん\\nが仰っている通りでその3つが揃っていたからだと思います。\\n社風なのか、大手なので余裕があるからなのか、やったことないことをインターン生にやらせる教育文化はかなりありますね。\\n開発効率を犠牲にしても、挑戦する機会をくれたって感じです。\\n\\n逆に、ベンチャーの方は、テクノロジー強いひとがほぼいなくて、ぼくがマネジメント側になっているので勝手に作りました。')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<!channel> \\n<@UMTMKBB1Q> さんの質問ですが、結構ありがちなパターンだと重思いますので、各々自分だったらどうするか回答してみてくださいー！！\\n\\n日曜日辺りに回答を投稿しようかなーと思います！！',)\n",
      "()\n",
      "('coron-wq',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'yuji.imuta', 'Sadayoshi Tada', 'asuki.u')\n",
      "('クラウド', '設計', '書籍', 'Linux', 'SQL', 'AWS', 'API', 'GCP', '教科書')\n",
      "('質問です。\\n\\nデータベースの設計やインフラ構築について学びたいのですが、実務観点からおすすめの本またはサイトがあれば教えて欲しいです。ちなみにレベル別でいただけるとなお助かります。',)\n",
      "('データ分析のインフラ・DB\\nアプリケーションのインフラ・DB\\n\\nだと、どちらを想定していますでしょうかー？', 'なるはど、そこもわかれてくるんですね。できれば両方知りたいですが、どちらかといえばアプリの方でお願いします。', '横からになってしまうのですが、データ分析のインフラについて知りたいです！', 'アプリのインフラ周りはちょっと把握できていないですが、一旦以下辺りをザっと眺めて、学ぶポイントを決めて行けばいいかと思いますー！\\n\\n■SQL初級\\n鉄板書籍\\n<https://www.amazon.co.jp/dp/4797376279/>\\n\\n■SQL上級\\nこちらも鉄板\\n<https://www.amazon.co.jp/dp/4839961263/>\\n\\n■データマネジメント中級\\nデータマネジメント系のお話です。データを以下に経営に活かすかという話なので、かなり経営戦略っぽい感じですね。\\n<https://www.amazon.co.jp/dp/4502276618/>\\n\\n■データマネジメント超上級\\n多分ちゃんと勉強しても3年くらいかかるｗ\\n<https://www.amazon.co.jp/dp/4296100491/>\\n\\n■インフラ\\n結構すぐ古くなっちゃうので、各種クラウドベンダーのチュートリアル見た方が良さそう？\\n\\n例えば、トレジャーデータとかは結構まとまってたりしますねー！\\n<https://support.treasuredata.com/hc/en-us/articles/360001480667-Architecture-Overview>\\n\\nGCPは、以下の質問起点で結構ディスカッションされていますー！\\n\\n<https://data-learning-guild.slack.com/archives/CJCNV9LG2/p1573132522281100>', '<@UNKM5GP8W> <@UMG0947NY>', 'ありがとうございます！！ベンダーのチュートリアル いいですね！！参考にさせていただきます！！', '<@UPSFL6VAP>\\nアプリのインフラ周りは多田さんが結構詳しい感じがするのですが、いかがでしょう？\\n\\nおススメなどあったりしますか？', '上級でおすすめしてくださってる本は今、現場に置いてますが、この本は本当に魔術書です！！便利すぎですよね', '<@UNKM5GP8W>\\nあと、教材ではないですが、インフラ系の話を調べると結構developers ioがヒットするので、おススメですー！\\n\\n<https://dev.classmethod.jp/>', '<@UMG0947NY>\\nちなみに、著者の田宮さん次回の仕事の説明書勉強会に来ていただく予定ですー！（体調治ればですがｗ）', '確認が遅くなりました。。 :bow: 村上さんのコメントにないものをいくつか紹介できればと思います\\nアプリのインフラでってことですが、インフラといえばサーバーとネットワークは大きくさらって、かつ最近はクラウド使うのが当たり前になっているのでクラウド利用前提の本を紹介できればと思います\\nアプリよりのインフラでさらに踏み込むとミドルウェアの理解も必要だと思うのですが、具体的な要件もなさそうかつ細かくなってしまうので今回は割愛させてもらいます :bow:\\n\\n```\\n◾️インフラ設計のセオリー --要件定義から運用・保守まで全展開\\n最近出たものですが、インフラ設計から運用までさらうのに良いと思います\\n<https://www.amazon.co.jp/dp/4865941886/>\\n\\n◾️イラスト図解式 この一冊で全部わかるサーバーの基本   \\nそこまで分厚くないサーバー周りの技術をさらえてオススメです\\n<https://www.amazon.co.jp/dp/4797386665/>\\n\\n◾️スラスラわかるネットワーク&amp;TCP/IPのきほん 第2版   \\nネットワークのイメージって掴みにくいのですが、図解されていて良書です\\n <https://www.amazon.co.jp/dp/4797396075/r>\\n\\n◾️絵で見てわかるクラウドインフラとAPIの仕組み\\nクラウドインフラのことを知るための書籍ですね\\n<https://www.amazon.co.jp/dp/4798141615>\\n\\n◾️クラウドネイティブ・アーキテクチャ 可用性と費用対効果を極める次世代設計の原則\\nまだ読めてないですが、良書の予感がしているのがこちら\\nクラウドの設計をしていくためのエッセンスを学べると思います\\n<https://www.amazon.co.jp/dp/4295007757>\\n```\\n\\nざっくりとなりますが、書籍の紹介でした :books: 何か参考になれば嬉しいです :smile:', '<http://Devlopers.io|Devlopers.io> はAWSのみでなくインフラの書籍のことも書評で紹介されていたりするので僕も良いと思います！\\nRSS登録がお勧めです :+1:', '<@UPSFL6VAP>\\nおぉー！！流石ですね！\\u3000やっぱり、餅は餅屋ですね！！\\n\\nめちゃくちゃ参考になります。\\n\\nそっか、TCP/IPとかからやんなきゃなんですね！確かに通信の基礎ですもんねー。', '自分は、\\n\\n「とりあえずそう決められててみんなその標準に従っている」\\n\\nという、ネットワーク周りの仕様、プロトコルを覚えなきゃいけないので、結構苦手ですｗ', 'あ、インフラエンジニアになって最初にLinuxのこと勉強しろって言われて読んだの入れてなかったです :bow:\\nLPI-JAPANが出している教科書なのでこちらはみといて損はないです(無償です)\\n<https://lpi.or.jp/news/press/page/20180327_01/>', 'インフラの勉強をはじめるとっかかりとしてなら Linuxのコマンドを打って なんかやってみて、やれることを増やしていくなかで、疑問とか 出てきてまた調べる とか やっていっても、後で使える技術は 培えそうです。 \\n\\n例えば 自分で遊ぶ用のマインクラフト とか テラリア のサーバーを自分で立てて 遊んでみる とかでも ゲームの好きな人は 結構 インフラの勉強なるかもですね(˘ω˘)\\n\\n少しできると、インフラ系の技術文献の読解が捗るかもしれませんね(˘ω˘)', 'Linuxコマンドは趣味みたいな感じでいろいろ調べてます！\\n\\nサーバーを立てるってゆうのがよくわからないですよね、、勉強ですね', 'サーバーをたてる というのは サーバーを構築する と捉えるとよいと思います。\\n\\nマインクラフト サーバー 構築  などで調べると いろいろ出てくると思います。\\n\\nこことか \\n\\n<https://jyn.jp/first-minecraftserver_on_linux/>\\n\\n手順の説明が丁寧な方かなと思いましたが、情報が古かったり OSなどのバージョン違いで エラーが出て ブログ記事の手順の通りにいかない可能性もありますので、流れだけしか参考にならないかもしれません。\\n\\n「  サーバーを構築する 」\\n\\nの一例として挙げました\\\\(´ω` )')\n",
      "('maimai',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'asuki.u')\n",
      "('AI', 'データサイエンティスト')\n",
      "('テキスト文章の要約でおすすめのサービスありますか？実際に使った方の感想がありますと嬉しいです。もしくは作成された方などはいらっしゃいますか。',)\n",
      "('特徴語抽出などではなく、文章要約ですか？？\\n\\n結構難しい領域ですね。。。', 'コールセンター業務でテキスト化→要約などのサービスを探すとあるのですが、どうやっているのかなというのと実際要約具合がどれほどのものか気になるのですよ。\\n議事録などでも利用できそうなのですが…\\n要約となるとデータサイエンティスト領域とはまた違う質問でしたかね:sweat_smile:', 'そこの業界関連のお話で、 たしか 人手 で タイピングしてるって聞いたことあります:thinking_face:\\n\\n間違ってたらすみません。\\n\\n確か コールセンター 業界だった気が、、、:thinking_face:\\n\\n音声認識 -&gt; 文字列化 の システム導入なら、AI化 である程度実現されてるかもしれませんね。\\n', 'コールセンター系で結構いい事例だなーと思ったのが、\\n\\n音声認識&amp;曖昧検索ですね\\n\\n大量りあるFAQやマニュアルの中から、やりとりに合わせた内容を検索して画面に表示する的な。', '要約ってどんなレベルのアウトプットイメージでしょ？\\n\\nbertって新しいアルゴリズムが出てから自然言語結構アップデートされてるっぽいので、bertをサービスに入れてるもののサービスレベル知りたいですねー！', '思い出しました。確か ベルシステム24さん\\nこれは 多言語対応 x 人材不足解消 っていうところから タイピング だったのでした。\\n\\n<https://www.nikkei.com/article/DGXMZO35968720R01C18A0XXA000/>', 'ただ、これは、、、さきほどの無知な自分が とても恥ずかしいですね。。\\n要約サービスはたとえば こちらとかでしょうか。\\n\\n<https://ai-products.net/product/voice-recognition-ai-quicksummary/>\\n\\n なるほど、分野にやって要約するパターンをある程度制御して、要約するサービスもあるんですね、、\\n\\n半自動といいますか、どのくらい精度があるのか、 気になりますね。というか \" 精度 \"という 私の言葉自体がナンセンスな気もしてきましたが、、', '情報色々ありがとうございます！！\\nAISmilyさんいつもめっちゃ参考にしてます！\\n今貼ってくれたサービスdemoがあったので見てみたら要約レベルも選択できました。親切…\\n<https://www.ai2-jp.com/package02/trial/>\\nただ話し言葉となると会話の構成などもぐちゃぐちゃだろうからどんな要約になるのかとか、オペレーターとユーザーの対話ともなるとどうなるのか…\\nいっそオペレーターの発言のみ利用して質問の意図確認するチャットボットのように「●●についての質問ですね？」と質問がトリガーであったりキーワードとして登録されてそこから要約されるような仕組みとかできるのかな…まったくわからんですが', 'コールセンターって離職率高いイメージがあったので教育するところがあるとは…でも座学の時間って結構とられるから企業からするとこれいいですね', '&gt;いっそオペレーターの発言のみ利用して質問の意図確認するチャットボットのように「●●についての質問ですね？」と質問がトリガーであったりキーワードとして登録されてそこから要約されるような仕組みとかできるのかな…まったくわからんですが\\n\\n電話越しの声は音声認識もしづらいので、おっしゃる通りオペレーターの復唱のみで検索してるって話聞いたことありますー！', 'おーそうなんですね！マイクの精度とかもあることを考えるとオペレーターの復唱がやはりよさそうですね', 'マイクの精度＋電話だとノイズが入ったり、音声が削られた上で送られたりというのがあるっぽいですね！')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('入門', 'レコメンド', '入門書', 'SQL', 'ネットワーク分析', '初心者', '教科書', '書籍')\n",
      "('グラフ理論を勉強したいのですが、なにかいい入門書ありませんか？？',)\n",
      "('ネットワーク科学: ひと・もの・ことの関係性をデータから解き明かす新しいアプローチ <https://www.amazon.co.jp/dp/4320124472/ref=cm_sw_r_cp_api_i_CGrZDbAPWBA2A>', '高いけど、これがめちゃくちゃ纏まってて、オススメです！', '以前slackに貼ってらっしゃったやつですね！ただレベルたかそうな印象があって・・・', 'グラフ理論とは！！！くらいの入門書から始めようかと思ったんです！', '教科書として書かれているので、大学の基礎数学レベルが出来てれば分かるようになってるんですよねー！\\n\\n1章が「グラフのユースケース」、2章が「グラフ理論とは？」という感じなので、金額的に大丈夫であれば、入門者にもオススメですね！', '入門としては、この辺の代表的な中心性指標を覚えておけばいいのかなーと思います。\\n\\n\\n<https://www.ajimatics.com/entry/2018/01/30/133238>', '<@UMG0947NY> \\n用途としてはどういった感じでしょう？？', '例えばECサイトとか売れたアイテムとかのひも付きとかを分析したいんですよね！\\nサイトの遷移とか、アソシエーション分析？？のようなことを勉強したくて！！', '<https://www.slideshare.net/MitsunoriSato/tokyor32-network-analysis-24442516>', 'こんなイメージです！', 'アソシエーションだったら、グラフ理論じゃなくて、レコメンド勉強した方が良いかもです！\\n\\nECの遷移なら、ファネル分析とか代表的なものがあるので、アクセス解析文脈で選定した方が良さそうですね！', 'それなら実践に近い書籍もたくさんありますし！！', '田宮さんのSQL本にもアソシエーションルールの出し方書いてませんでしだっけ？', '大体カバーしてる気がするので、田宮さん本見てみて、不足してる部分を教えて頂くのが良いかと思いました！', 'レコメンドのあとで、どのような動きとかにつながったりすのか、分析する方法調べていたら、グラフがでてきたので、興味もってこれ使った分析できそうかと思いました！', '田宮さんの本から興味スタートです！！', 'アクセス解析のグラフは、実際データ食わせてみると超グチャグチャになるので、仮説ベースで検証した方が失敗は少ないですねw', '今、関わってる業務が広告系なので広告間のつながりを分析したいとも思ったのです！', 'とりあえずgephiとかにデータ作って食わせてみると、イメージ掴めるかもですねー！', 'あとは、neo4jにサンドボックスとかあるので、それでも良いかも', '<https://neo4j.com/sandbox-v2/>', 'この辺', '初心者質問なのですがネットワーク分析とグラフ理論はイコールかと思ったのですが、違うのでしょうか？・・・', 'イコールですねー！', 'ネットワーク科学の一部にグラフ理論がある感じですかね', 'ありがとうございます！！\\nネットワーク科学って本買ってみました！今求めたものとクリティカルではないかもしれませんが、勉強したいので買ってみました！', 'おぉー！いいですねー！！\\n\\nネットワーク分野は多分これから伸びる分野だと思うので、基礎力付けて行きましょう！！', '個人的には、ROIめちゃ高い技術投資分野なんじゃないかなぁと思ってます！', 'なるほど！！本に負けないように頑張ります笑！！グラフ系のNNも出てきてるので、基礎力つけておきたいとは思ってたので！！')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('Satoru Mikami', 'asuki.u', 'Sadayoshi Tada', 'Riita Satsuki')\n",
      "('AWS', 'jupyter', 'pandas', 'Python', 'Redshift', 'SQL', 'クラウド', 'データエンジニア', 'データサイエンティスト')\n",
      "('今後法人データ等を使ってコンペを開催するような取り組みもして行きたいなーと思っているのですが、ある程度のセキュリティ担保として、\\n\\n・notebook環境で分析できる\\n・ただし、データのファイルダウンロードは禁止\\n\\nみたいな環境作れないか検討しているのですが、何かおススメの構成などあったりしませんかね？\\u3000ネットワーク周りとかセキュリティ周りの話になるので土地勘なく、\\n\\n<@UKY4VFB5E> さん、 <@UPSFL6VAP> さん、 <@UPF4T5DE1> さんなど、何か知見お持ちでしたらお伺いしたいです。',)\n",
      "('aws上にjupyternotebookサーバーを構築してS3ストレージをIAMで管理する\\n', 'jupyterって、ファイルダウンロードできませんでしたっけ？', 'なんかAWSのソリューションアーキテクトの試験問題になってるw', '割と実務でありがちな問題ですね。公開じゃなかったとしても、リモートワークとかで類似の条件はありそうですし。', 'Pythonからストリームで取り込むのは？', 'Rのデータセットでよくやるやつ', 'ちょっとイメージ沸いていないですが、どんな感じでしょう？', 'S3にアクセス制限つきのバケットを用意してデータアップロード\\n\\nJupterNotebookでpandasのHTTPS経由でCSVダウンロードしてデータフレームに変換', 'あー、なるほど、jupter上ではファイル残さないって感じです？', 'そうです。まあメモリにはのっかるけど', 'ディスクへの書き込み権限を付けなければ、writeとかでファイルに書き出せないって算段ですかね？', 'そうですね。S3のアクセス設定でいろいろ細かくできます', '特定のユーザーに制限することも可能です', 'なるほど！ありがとうございます！！', 'ちなみに試した事はないので多分できるはずって感じ', '検討してみますー！\\u3000何か分かったら続報お送りしますねー！', '一応 参考までに教えて欲しいのですが、質問冒頭にあった要件の部分で 分からない点がありました。\\n\\nファイルのダウンロード禁止 という 「 ファイル 」とは もう少し具体的にいうと どの部分のことでしょうか？\\n\\n例えば ジュピターの画面が見えてる以上 プログラムのソースは 見えてる状態なので、 プログラムソースの閲覧(ダウンロード)は OK として、その下の階層にある モデルファイルとかをダウンロードを禁止する。 特定のディレクトリ階層のダウンロードを禁止する とかいう ことでしょうか？', '・学習元データ（生ログ）\\n・加工済みデータ\\n・学習済みデータ\\n\\n辺りを指していまして、プログラムや画面キャプチャなどはやむなしかなと。', '了解しましたー\\nありがとうございます:woman-bowing:', '最低ラインとしては、GU Iからの削除でも良いかなと思いますが、通信的に遮断できるとベストですー！', '自分もこの環境欲しいなと思った。', 'やっぱ、結構ニーズあるんてすねー！\\n\\nリモートワークとかですか？？', '基準としては、\\n\\n「悪意を持ってデータを持ち出そうとしないと持ち出せない」\\n\\nって感じですね。', '画面で見えてる以上は全データにアクセス可能ではあるので。', 'なるほどです！\\n上記 AWSのIAM は 使い方に慣れてないので、データラーニングギルドのユーザーさん ってところで、具体的なやり方がよく分かりませんが、それなら、IAMの 性質上 アクセス制限によって 要件を満たしそうですね:+1: 納得しましたーありがとうございます:blush:', 'google colabもあるけど、やはりプライベートでさくっと環境構築して、データサイエンティストにお願いして分析してもらいたいときがあります', '分かる人がやったら秒で終わったりしますからねw', 'もしこの環境サクッと作れたら、データ分析特化クラウドソーシングサービスとかで打ち出せますかねー？？', 'cloud formationとdocker辺りか使えば、パッケージで準備できそうな気がしますが、どうなんでしょ？', '・学習元データ（生ログ）\\n・加工済みデータ\\n・学習済みデータ\\n\\nのデータ量が大きければ大きいほど、s3からのダウンロード料金がなかなか量みそうな気が、、、\\n\\nもしかしたら アップロード料金 は 大したことないのかな？ \\n\\nAWS 内部の処理 だから S3の アップロード ダウンロード 料金って そんなに クリティカルじゃなかったりします？', 'どうなんでしょう。。。\\n\\nちなみに、データが大きすぎる場合は、Redshiftのリードオンリー条件でSQLが叩けるようにしてあげれば良いのかなーと思ったりしますー！', 'クライアントはjupyterに寄せて、持ち出せないようにするのが最優先課題なので。。。', '了解しましたー:memo:\\n詳細 すみませんでした:woman-bowing:', 'いえいえー！ありがとうございましたー！！', '1件 参考になりそうな記事が、あんまり 参考にならなそうだったので 棄却しました:woman-bowing:', '完全に出遅れました。。 :bow:\\n実務経験がなく恐縮ですが、、、S3にあげちゃうと取り出すときにダウンロードすることになるかなと思います :thinking_face:\\nなので、EFSにマウントするのはどうかなと思い書き込ませてもらいます(参考記事は↓です) EFSであればダウンロード部分がなく学習のトレーニングをスピードアップできるぞ！とAWSの記事でも紹介されていました\\n<https://aws.amazon.com/jp/blogs/news/mount-an-efs-file-system-to-an-amazon-sagemaker-notebook-with-lifecycle-configurations/>\\n<https://aws.amazon.com/jp/blogs/news/speed-up-training-on-amazon-sagemaker-using-amazon-efs-or-amazon-fsx-for-lustre-file-systems/>', '&gt;もしかしたら アップロード料金 は 大したことないのかな？\\n&gt;AWS 内部の処理 だから S3の アップロード ダウンロード 料金って そんなに クリティカルじゃなかったりします？\\nS3の料金体系としてアップロードは料金かからず、ダウンロードはかかるはずです\\n```\\n・インターネットから Amazon S3 へのデータ転送受信 (イン) : 0.00USD/GB\\n・Amazon S3 からインターネットへのデータ転送（アウト : 0.114USD/GB\\n```', 'さすが AWSエンジニアさんです\\\\(´ω` )/ 追い求めいた明確な答えでした。\\nAWSはサービスが多すぎて検索しづらく、、回答ありがとうございます:blush:', 'EFSでも良いと思いますー', 'これデータエンジニア向けの最初の課題として面白いな。環境構築、セキュリティ、ネットワーク、ストレージ、データ転送、料金体系の知識がある程度わかってないと解けない。バランスがいい', '確かにざっくり要件でAWSならこう提案するっていろんな要素考える必要あるから勉強になるし、アウトプットするために整理して言語化する必要あるしネタとしていい気がしますね！', '今さらかもしれないんですが、ちょっと調べたので書いておきます。\\n<https://cloud.google.com/storage/docs/gcs-fuse?hl=ja>\\nGCSのバケットをディレクトリシステムとしてマウントできます。\\n仕様の詳細は\\n<https://github.com/GoogleCloudPlatform/gcsfuse/>\\nに載ってます！！\\n\\nあまりパフォーマンスは良くないんですが、\\nGKEのClusterにjupyterを置いたとしたら、\\nそこから直接GCSをマウント出来ます！\\nあくまでもマウントなのでCluster内部までファイルが来ないので、ダウンロードを阻止すること自体が可能です。\\n<https://www.google.co.jp/amp/s/cstoku.dev/posts/2016/k8s-gcsfuse/>\\nこの方がおおよそ同じことやっています。\\n\\nまた、jupyterのフロント自体は、\\ncontainer内部のjsを直接編集できるので、\\nボタン消しておけば解決だと思います。')\n",
      "('coron-wq',)\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "('質問です\\n\\niphoneのアプリの通信先を特定したいです。というのはアプリが外部apiにアクセス？またはデータベース接続する際にその対象先の情報を得たいです。具体的な例を挙げると\\n\\n<https://apps.apple.com/jp/app/box-loca/id1466961267?l=en>\\n\\nこれは動画視聴アプリですが動画を見ようと選択するとロードに入り、複数の動画データを読み込み、ユーザーに選択させて視聴させます。この際、どこに通信して動画を表示させているのか気になります。\\n\\nもう一つ、例を出すと、フリーのmusicアプリを使用するときに裏側でどこに接続して音楽を引っ張ってきているのか知りたいです。\\n\\nまた、今のはあくまで具体例なのでその他のアプリでも同様に通信先をパケットキャプチャ？したいんですけどどうすればいいかわかりますか？',)\n",
      "('Charles Proxyってアプリ(1000円くらい)を使うと\\ncurrentsessionとかHTTPのメソッドやステータスコード取れます。', '<@UNFAV5EDB> \\n\\nありがとうございます。そちらを参考にフリーを探すと\\n<https://link.medium.com/lCz1BvzhG1>\\n見つけられました。非常に感謝です')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coron-wq',)\n",
      "('ﾋﾛﾘｰ',)\n",
      "('クラウド',)\n",
      "('本当に困っています。調べるとprivateのvarはいじってはいけないらしいんですけど流石に50GB超えててめちゃめちゃ困ってます。だれか助けてください',)\n",
      "('これで外付けhdd的にデータをクラウドへ移動させるのはどうでしょう？\\n<https://vegepples.net/2016/11/15/drive/#HDD-3>', 'んー、そもそも58という数字がおかしいと思っているんですけど普通なんですか？', '一昔前のmacbook airなら64GBモデルあったから\\nシステム領域除いたらそのくらいなのでは', 'どういうことですか？本体の容量は256です。privateが58を占めてます', 'ん〜\\u3000確かにおかしいですねぇ\\u3000力になれず恐縮です')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('機械学習', 'マーケティング', 'AI')\n",
      "('<https://www.amazon.co.jp/AI%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%83%9E%E3%83%BC%E3%82%B1%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0-%E8%87%AA%E5%8B%95%E5%8C%96%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92-%E7%B5%8C%E6%B8%88%E3%83%A2%E3%83%87%E3%83%AB%E3%80%81%E3%83%99%E3%82%B9%E3%83%88%E3%83%97%E3%83%A9%E3%82%AF%E3%83%86%E3%82%A3%E3%82%B9%E3%80%81%E3%82%A2%E3%83%BC%E3%82%AD%E3%83%86%E3%82%AF%E3%83%81%E3%83%A3-impress-gear/dp/429500474X>\\n\\n\\n\\nビジネス面での勉強をしたいのですが、なにかおすすめのコンテンツ、本などありますでしょうか。\\n現在はこの本を用いて勉強しています。事例等が知りたいです',)\n",
      "('ビジネスってかなり幅広いので悩むのですが、どういう系でしょ？', '質問が雑でしたね・・すいません\\n今、広告業界にいるのですが、なにを勉強していいのかくらい迷ってます・・・\\n・データをどう生かすのか\\n・機械学習を生かすのか\\n・データ*行動分析\\nなどが知りたいです。。。', '<https://www.amazon.co.jp/dp/4297101084/>', 'これとかですかねー？', 'ありがとうございます！！\\nこういうのです！！！', '<https://www.amazon.co.jp/dp/4798157791/>', '事例だとこの辺？', '<https://www.amazon.co.jp/dp/4844368885/>', 'これは、営業さん向けっぽい内容なので、大体もう知ってるかもですね。', '<https://www.amazon.co.jp/dp/4873118255/>', 'あとは、機械学習を活かすという意味ではこの辺？', '<https://www.amazon.co.jp/dp/4822237729/>\\n\\nExcelしか使わないやつだけど、データ分析を活用プロセスを演習形式で学べるやつ。', '大体この辺ですかねー？？', '<https://www.amazon.co.jp/dp/4478039631/>\\n\\nあと、マーケティング系だとこの辺ですかねー？？', 'オライリーのは気になってました！\\n営業と話してて、自分の手持ちの少なさに危機感を感じてたので、すごい助かりました！！ありがとうございます！！')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "('jupyter',)\n",
      "('あと、jupyterlabからDocumentsにアクセスできない笑',)\n",
      "()\n",
      "('asuki.u',)\n",
      "()\n",
      "()\n",
      "('macos 環境 興味あるので調べてみたら、似たようなことで困ってる方は 幾人か いるようですね、、、\\n\\n<https://discussionsjapan.apple.com/thread/110198584>\\n\\nたしかに 仰る通り その中のディレクトリの中で、osに関わる部分のため、弄らない方がいい ディレクトリもあるようですが、 そのような 肥大化 に悪影響をきたす アプリケーションが macosにインストールされている可能性があるようです。\\n\\n悪影響を及ぼすアプリケーションに心当たりがある場合は、そのアプリを削除する といった 改善方法があるみたいですね:sweat_drops:\\n\\nたとえば 悪意がないフリーアプリでも 実装ミス で起こるうることなのかなと 少し思いました。\\n\\n特定のアプリをいれた時期から macの調子がめちゃ悪くなった、、、  とか わかりやすい何かヒントがあるといいですね:sweat_drops:',)\n",
      "()\n",
      "('asuki.u',)\n",
      "()\n",
      "()\n",
      "('また、場合によっては、シンプルに 「  Safe Boot する 」ことで改善した例もあるようです。\\n\\nos 起動時に shift キー とのことです。\\n\\nやってみて改善しなかったらすみません:sweat_drops:',)\n",
      "()\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('maimai', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('クラウド',)\n",
      "('現状の代替えとしての価格設定が一つのポイントかと思います。\\nAdbobeは20万ぐらいのパッケージを年間6万にしました。\\n実際には5年以上更新されない商品形態になっていたCSを定額にしてMacと組んで過去を駆逐した仕様は見事だと思いました。',)\n",
      "('<@UJRAL005U> わかりづらくすみません、・のついている質問のいずれか応えやすいものについてお答えいただけますと助かります', '<@UL2TY2ERL> CS6動かなくなるの何気に痛手ですよね…たまにしか使わない層だとCCいいなあと思うのですが…Adobeさんはうまいことやってますね', '提供形態はクラウドのサービスを想定しています？\\n\\n・ユーザー単位課金\\n・松竹梅のプラン課金\\n・オプション\\n\\nみたいなのが一般的なのかなーという感じはしますね。', 'クラウド想定です！\\nあー容量や機能で松竹梅などですね。\\n松竹梅という単語が出てこなかったので助かりました。ありがとうございます。', 'キーワードとしてはフリーミアムとかですかねー！', '価格戦略としては、プロモーション費用どれだけ考慮入れるかは結構大事かと！\\n\\nそのためにはLTV見積算出ですね！', 'あとは、キャッシュポイントをどこにするかってのもポイントかなーと。\\n\\nサービス自体は安いけど、導入、活用コンサルで稼ぐって方法もありですし。', 'フリーミアム！！！よく見るやつです！名前全くしらなかったので助かります。\\nプロモーション費用とあとマンパワー補充する際の費用も抑えておけと助言きました！')\n",
      "('tomo.h',)\n",
      "('maimai',)\n",
      "('自然言語処理',)\n",
      "('ゆるーく聞きたい感じなのですが、日本語の自然言語処理の\\nデータ収集〜データ分析(分類問題)まで一気通貫で体験できるようなネタを考えていて、データセットのネタを探しています。\\nそこで以下の条件に合致するデータセットを探していたりします。\\n\\n・何らかのラベル付けがある(アノテーションが手間でない)\\n・名寄せ問題などにあまり悩まされない\\n・そこまでデータ取得に手間がかからない(スクレイピングが必要なくらいはOK)\\n・許可等あれば商用利用に耐えられる(こちらは必須ではないです)\\n\\nあたりの条件のデータセットを探していたりするのですが、知っているものあったりします？\\n私が知っているものだと\\n<http://kokkai.ndl.go.jp/api.html>\\n<https://www.rondhuit.com/download.html>\\n\\n国会の議事録なんかは私がそこそこ練習で使った経験があるのですが。。\\n他にこんなの知ってるよ的なものがあれば、上げてもらえるとありがたいです。',)\n",
      "('該当するかわかりませんがこちらはどうでしょうか\\n<http://www.db.info.gifu-u.ac.jp/data/Data_5d832973308d57446583ed9f>\\n商用目的OK、感情ラベル付与', 'ありがとうございます！早速確認してみます！')\n",
      "('asuki.u',)\n",
      "('coron-wq',)\n",
      "()\n",
      "('それに 該当するかちょっと自信ないですが、これとか もしかしたら、、と思いました。\\n\\n<http://linkdata.org/view/rdf1s2274i>\\n\\n札幌証券取引所単独上場銘柄 です。\\n\\n\\nこちらは オープンデータ の共有サイトになります。\\n\\n<http://linkdata.org/work?sort=date>\\n\\n\\n\\n\\n\\n\\n\\n',)\n",
      "('このサイトすごいですね。教えていただき非常に感謝してます',)\n",
      "('asuki.u',)\n",
      "('tomo.h',)\n",
      "()\n",
      "('おそれいります:sweat_drops:\\n\\n北海道の株より、こういう 日本語の解説 説明が 付与されてる方が 、よりご所望の形に近いかもと思いました。\\n\\n京都が出てくる本のデータ\\n\\n<http://linkdata.org/view/rdf1s1294i>\\n\\n',)\n",
      "('ありがとうございます！助かります！',)\n",
      "('coron-wq',)\n",
      "('ﾋﾛﾘｰ',)\n",
      "()\n",
      "('webassemblyについてどう思いますか？\\n\\n<https://en.wikipedia.org/wiki/WebAssembly>',)\n",
      "('プロトコルは詳しくはわからないけど、chorome devバージョンで\\n有効にすると、読み込み爆速になりますよ', '爆速！いいですねえ、導入不可避')\n",
      "('Riita Satsuki',)\n",
      "()\n",
      "()\n",
      "(\"```blob_download = bucket.get_blob('xgb_reservation_model.pickle')\\nloaded_model = pickle.load(blob_download.download_as_string())\\n\\ny_pred_proba = loaded_model.predict_proba(X_test)```\",)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "('Fukushima-M1-gameAI-DynamicPricing', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "()\n",
      "(\"これで2行目、`file must have 'read' and 'readline' attributes`\\nって言われるんですけど、どういうことでしょうか..？\",)\n",
      "('pickleのことよく分かってませんが、get_blobの引数には、ファイルのパス名を渡してあげないと、Noneが返ってくるような気がします。\\nblob_download変数の中にNoneが入っていて起こってるエラーかもしれません。', '確かに、`blob_download`の中身が怪しそうですね。。。\\n\\nオブジェクトの中身って想定している内容になっていますでしょうか？')\n",
      "('Katsuya Nagano',)\n",
      "('はやと-休学中の文系学生', 'tomo.h')\n",
      "('統計',)\n",
      "('notebookでの関数のデバッグってみなさんどうしてますか？\\nnotebookじゃない場合は例えばVSコードのデバッグ機能使えば各処理でなにが起きてるかみれるのですが。。。\\n\\n関数の中身をコピペ→引数に入れる部分を実際のオブジェクトに置き換える&amp;インデントを元に戻す\\n→各処理毎に出力して確認、ってのがとても面倒・・・',)\n",
      "('自分は完全にprintですね〜\\nあたりつけてここかなってとこでprintしてます、慣れただけっていうのもあるかもですがあんまり不便は感じてないです。たしかにデバック出来たら便利ですね、、、', 'メインは都度printとassertですね。。\\n現場のきちゃないデータだとちょっとずつデータ見ながら作っていく方がしっくりくるので。。。\\n\\n物によっては部分的にテストコート用のセルを作って気になる変数をprintしたり、関数の実行結果を確認すようなセルを作っておき、該当箇所のロジック変えたら、テストコード用のセル実行して目視確認をするくらいです。\\n前に論文記載のオレオレ確率関数とかオレオレ統計モデルを実装した時は、テスト用セルをたくさん準備して、各変数が想定通りかとか、積分して1になるかとか結構実装したことありましたがw')\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('あるいは、関数の中にいったんprint入れて結果を吐く、というやり方くらいしか思い浮かばないっす',)\n",
      "()\n",
      "('れごん-島根のﾌﾘｰﾗﾝｽ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('`embed` だ!!!\\n<https://currypurin.qrunch.io/entries/AY4wdA08CE6GdoHT>',)\n",
      "('notebookでやると、ターミナル表示されるんですねー！',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('名前出てこなかったけど、それですね！\\n\\npythonも、rstudioみたいにオブジェクト一覧出てくれれば良いのにって思うことはありますね。',)\n",
      "()\n",
      "('はやと-休学中の文系学生',)\n",
      "()\n",
      "()\n",
      "('え、そんなのあるんですね:flushed:\\n今度早速使ってみます',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('rubyで言う所の、binding.pry的なやつですよね？',)\n",
      "()\n",
      "('れごん-島根のﾌﾘｰﾗﾝｽ',)\n",
      "()\n",
      "()\n",
      "('そうですね。けど、embedはnextとかstepまでは使えないので、確認とかするだけ用ですね。',)\n",
      "()\n",
      "('Riita Satsuki',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('Python',)\n",
      "('`from IPython.core.debugger import Pdb; Pdb().set_trace()`\\nでbinding.pry的な感じになりますよ！！',)\n",
      "('おおー！便利そう！',)\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('おぉ、色々な知見が・・・っ！！\\nみなさん、ありがとうございます！それぞれ試して自分が使いやすいやつ見つけてみます:blush:',)\n",
      "()\n",
      "('Mana',)\n",
      "('藤沼淳一', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'Katsuya Nagano')\n",
      "('BI', 'Python', 'Tableau', '可視化', 'PowerBI', 'クラスタ分析', '機械学習', '初心者', '統計')\n",
      "('超初心者質問で恐縮なのですが:pensive:\\n人への統計＆機械学習の説明を分かりやすく行うために、グラフを動的に表示させる手段（できれば時間経過、スライドバーなどで変化）を探しています\\n\\n例えば、Albertさんのサイトのk-means法デモツール\\u3000のようなものです\\n<https://www.albert2005.co.jp/knowledge/data_mining/cluster/non-hierarchical_clustering>\\n\\n↓ここらへんに当たるのが良いかなと思っていますが、皆様おススメのものはございますでしょうか？？\\nGeoGebra\\n<https://www.geogebra.org/>\\n\\nPython: matplotlib で動的にグラフを生成する\\n<https://blog.amedama.jp/entry/2018/07/13/001155>',)\n",
      "('Google Data Studioは微妙でしょうか？', '自分元ALBERTですが、この表示は結構ガチガチでコード書いてたような気がします。', 'BI使えるなら、BIツールで行けそうな気がしますね！！', 'ちなみに、その記事のクラスタ分析①、②のサンプルデータセット作成と分析は自分がやりました。\\n\\nもう5年前とかなので、めちゃ懐かしいですｗ', '<@UQ8NVHJFJ>\\ntableauで雑に作るとこんな感じですが、イメージ合ってます？', 'plotly_expressオススメです。\\n細かい調整は難しいですが、ちゃっとアニメーションにできます。\\n<https://plot.ly/python/plotly-express/>\\n<https://i.gyazo.com/7f699a81b17de119bf240a11688d3f3f.mp4>', 'アニメーションの可視化に関して勉強会とかしたいっすね。\\n\\nプレゼントとかの時にヌルヌル動くと分かりやすい。', 'Tableauで始めるデータサイエンスという本を買ってみた', 'アニメーションではなく、手動でスライドバーの方ですが、RだとshinyってやつでBIみたいにパラメータを動的にできたような。使ったことないのでなんともですが、Pythonも似たやつあるみたいです\\n\\n<https://qiita.com/stkdev/items/c52aa3ea4899f6e6e8bc>', 'こういうビジュアライズいいなぁって思ったりします。\\n\\n<https://youtu.be/nLP2tyFD-zc>', '確かに、Shiny結構ヌルヌル動いた気がしますね。', '昔、Dashとplotly_express使って自家用車のデータを可視化して遊んだことがあります。Dashで作った物は簡単にHerokuにあげられます。\\n<https://obdmapbox.herokuapp.com/>', 'わあー:exclamation:皆さん色々教えて下さってありがとうございます、めっちゃ反応がすごい...\\n自分がさらに調べて、PythonのTkinter、RのScatterPlotというのが有ることも分かりました:star-struck:', 'あ、あと弊事業部はMicrosoft 推しなのでPowerBIも有りました\\n', 'GoogleDataStudio、Tableau、plotly_express、Rのshiny、PythonでShinyぽいやつ、Dash、とあと自分が挙げた手段と、試して比較してみます\\u3000ちょっとずつ...', '<@UJRAL005U> 中の人のコメントとか強すぎます笑\\nガチガチでコードと...:exploding_head:\\n\\n図示頂いたTableauの画面だと、スライダーで変数の中身決め→式(集計？)に変数入れて計算→結果動的にグラフが動く:chart_with_upwards_trend:ということですよね？\\n式にルート、二乗等も普通に仕込めるのでしょうか？', '日時とか集計範囲変えるとか楽\\u3000且つ\\u3000100万行ぐらい余裕で処理できる\\n公表では1億', '速度大事ですね。。。結構量いけるものなんですね:heart_eyes:')\n",
      "('Fukushima-M1-gameAI-DynamicPricing',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('統計', '機械学習', '書籍')\n",
      "('ビジネスにおける需要予測について、素朴な疑問があります。\\n需要予測の妥当性とか信頼性ってどうやって評価しているのでしょうか？\\n思いつくのは、需要予測導入前と後でどのくらい変わったのかの差分を取って、評価する。といった感じですが、これってビジネス的にはいいんでしょうか？\\nもしくは、実績データなどがない場合はどうやって評価するのでしょうか(そんな場面がそもそもあるのでしょうか)？\\nかなりざっくりとした質問になってしまいましたが、実際にビジネスで需要予測ってどうやって使うのかなぁと不思議に思ったので、質問させて頂きました。',)\n",
      "('&gt; 需要予測の妥当性とか信頼性ってどうやって評価しているのでしょうか？\\n需要予測の予実は、どれだけ売れたか測れば計測できるのでは？\\n\\n広告予算だったり、金額だったり、ある程度パラメータをチューニングした結果を想定していますか？', 'ちょっと僕の考えがまとまってなくて申し訳ないのですが…。\\nええっと、予実を測ってそれに統計的な解析をかけるのはありなのかなぁという疑問です。\\nパラメータについてはまったく考えてないです。', '①バックテストで、既存データ内で検証\\n②実際の運用に乗せてみて判断\\n\\nみたいなステップを踏むことが多いように感じます。上記のテスト過程を経て使えそうとなったら、実際の意思決定に活用するという感じですね。', 'なるほど。\\nありがとうございます！\\n単純に予測精度で提示する感じですかね。', '人がやる予測精度と機械学習による予測精度を比べて、バックテストでokだったら導入って感じでしょうか。', 'そうっすねー！\\u3000上記資料のような感じで、結構目的によって変わる所はあるかもしれませんねー。', 'なるほど。\\n素朴な疑問にありがとうございました！', 'かなり曖昧な感じですが、「肌感に合うとか」、「大きく外さない」、「上振れ（下振れ）は多少許容できる」、みたいなビジネス要件と擦り合わせながら導入して行くことになりますねー！', 'ちなみに、上記は来週の発表資料の中身ですｗ', 'なるほど。\\nデータサイエンスでドメイン知識が重要なのは、そういったビジネス要件と擦り合わせがあるからですかね。', '貴重な資料ありがとうございますw', 'ですねー！\\n\\n実際に何が重要なのかとか、予測する人は何を基準にどういう考え方で数字を作っているかとかを読み取って、運用まで落とし込むのってめちゃくちゃ大変です！', '過去になかった需要をシミュレーションする系だと統計的な推測値だと不十分だったりすることもありますしね。', 'ファジーな部分を理論に落としこむのは、かなり大変そうですね。\\n毎回状況は変わりますし。マニュアルやレシピとかなさそう。', 'そうなんすよねー。需要予測難しいっすｗ', 'そういった統計的な推測値が取れない場合、どうやって説得するんですか？', 'コンサルっぽく推定値を出すか、統計値を使えるようにモデルを変えるか。方法は色々ありますねー！\\n\\nマーケットシェアだったり、競合のデータだったりは売ってる会社があったりするので、そういう所からデータを仕入れて、マーケットシェアから逆引きするとか、どこの商品の代替になるのかっていう、類似商品からのシェアの獲得だったりみたいな考え方をしたりもします。', 'なるほど。\\n実戦的なやり方がいろいろあるんですね。\\nすごいなぁ。', '専門でやっている人が居る会社とかだとドメイン知識が強すぎるので、鉛筆なめロジックになかなか勝てないんすよねｗ', 'その人辞めちゃったら終わるってやつですねw', '\\u202a<https://www.amazon.co.jp/dp/4041041422/\\u202c>', '極めた人間にはなかなか勝てないんですね。', 'ここら辺は結構オススメっすねー！', '期待値に基づいた思考を実戦的に使うことを考えてたので、かなりタイムリーです！', '読んでみます！', 'バイブル的な書籍ですねー！')\n",
      "('Satoru Mikami',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('機械学習',)\n",
      "('これから別件でNDAを結ぶ会社があるのですが、「機密情報を基礎とする応用技術の開発を行わないという」文ありデータ分析の受託の場合、わりと応用技術が多いのでどうしているか答えられる範囲で知りたいです。\\n\\nまた、受け取ったNDAをチェックするサービスっていいのあります？',)\n",
      "('自分はまだまだ法務とか抱えられないので、以下のサービスを使うことが多いですね。\\n\\n<https://www.shares.ai/mypage>', 'この辺のガイドラインに契約周りの話って載ってないんですかね？\\n\\n\\n<https://www.meti.go.jp/press/2018/06/20180615001/20180615001.html>', '18ページ辺りに書いてありそうな気もしますね。\\n\\n<https://www.meti.go.jp/press/2018/06/20180615001/20180615001-2.pdf>', '一度渡しちゃったら流出や再利用の危険はあるので、実態としては、\\n\\n人や会社の信頼度を見て提供するデータのレベルを切り分けてるって感じはありますね。', '法解釈も難しいし、判例もまだまだ少ないしで、法と契約でしっかりブロックし切れるかは今の段階では怪しい所結構ありますね。', '<https://tech.nikkeibp.co.jp/it/article/Watcher/20090827/336138/>', '<https://topcourt-law.com/ai-iot/learned-model-copyright>', '法律、契約上は禁止してても、\\n\\n「そのデータ使って学習したモデルか？」\\n\\nという所の検証は困難を極めるので、実態として訴訟は難しいんじゃないかなと思います。。。', '「いやいや、それ共有しちゃダメでしょ」ってやつ共有する人とかも結構いたりするので、\\n\\n契約では最低限縛った上で、人、会社のコンプラ遵守度合だったりを考慮するのが良いですかね。\\n\\n若干本筋とはズレますが。', '大事なのは\\n\\n・秘密管理性\\n・有用性\\n・非公知性\\n\\nそれぞれ当てはまるかってことはわかりました', '論文でパブリックになっている機械学習のアルゴリズムの組み合わせは該当しなさそう', '学習済みモデルは該当しそう', 'ここら辺の本とか結構ケース載ってますね。\\n\\n機械学習のモデルに関してというより、データ提供ビジネス主体って感じですけど。', 'この辺難しすぎて、なかなか手が出せて無いですねー。。。')\n",
      "('Shunnosuke',)\n",
      "('はやと-休学中の文系学生',)\n",
      "()\n",
      "('random forests と extremly random forestsの違いどなたかわかりますでしょうか？\\n調べたら、extremely random forests はRandom Forestと同じように複数用意してBaggingするのだが、それぞれの木を学習する際に、Bootstrapサンプリングはせずに訓練データ全てを用いる。と書いてあったのですが、Boostrapサンプリングしないで訓練データを全て用いてBaggingする？というのは、データの行は全て用いるが、列をランダムに選択することでBaggingするということでしょうか？？:sweat_smile:\\n参考URL:<https://yoshoku.hatenablog.com/entry/2019/05/02/005231>',)\n",
      "('ランダムフォレストは決定木で切る時に一番いい感じに分かれるところで切りますが、extremeはもう完全に適当に切るっていう感じですね', '<http://kazoo04.hatenablog.com/entry/2013/12/04/175402>', 'こんな感じです〜\\n（baggingのところはあんまりわからないです、ごめんなさい笑）', 'ありがとうございます!\\nデータの量があまりないときにextremeが選択肢として出てくるって感じですかね。。\\n量が多ければrandom forestでオッケーで')\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "('ｹﾛﾏﾂ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "()\n",
      "('みなさん、プレゼンの練習てどのようにしていますでしょうか？\\n（もしくはしなくてOK？）\\nジョブズは8時間ホテルに籠もって練習したそうですが。。\\n\\n会社の研修で、オライリー本の内容を1hr×4回に渡ってプレゼンすることになりました。\\n資料作成に関しては、ほぼ終わったのですが、話し方の練習を工夫できないかと思いまして。。\\n今やっている方法としては、\\n\\n１、アドリブで話してみる\\n２、話した言葉を紙に起こす\\n３、喋りにくい箇所、分かりいく箇所を修正する\\n４、１から３をループ\\n\\nこれらをビデオ撮影して見るです。',)\n",
      "('中田敦彦さんが、知り合い3人に、一人ずつ計3回練習としてプレゼンしてみるのがよいとおっしゃってました。\\n', 'ありがとうございます！知人に忌憚ない意見をもらうのが一番ですね。正直に「分からん！」と言ってくれそうですし。\\n分からないのはプレゼンテーターの責任なので、何が分からないのかヒアリングしとくには重要ですね', '自分も明後日のプレゼン練習しなきゃです。。。', 'あっちゃんのプレゼン半端ないっすよねw')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('流れは良いかと思います！\\n\\n動画撮影すると気付くこと多いですよね！',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('ありがとうございます。\\n自分の姿を見るのはシュールな気分になるので嫌ですが、修行と思ってやっていますw\\nニヤけてるなとか、単調やなーとか気付きますね。',)\n",
      "()\n",
      "('sota_sakuma',)\n",
      "('maimai',)\n",
      "()\n",
      "('<https://event.shoeisha.jp/eva/training/>\\n\\nこんなの受けます！',)\n",
      "('これいいですね！私に足りてなさすぎるものを間違いなく学べるやつ',)\n",
      "('sota_sakuma',)\n",
      "()\n",
      "()\n",
      "('広島の展示会でたまたま話聞いたんですが、さすがの一言！\\n1日目google の人が話して、この方が２日目話したんですが、観客が3倍くらいでしたね！',)\n",
      "()\n",
      "('sota_sakuma',)\n",
      "()\n",
      "()\n",
      "('日本でエバンジェリストって職種の先駆け的な人みたいですね！',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('初めて聞く職業です！海外では一般的なんですかね？プレゼンについて面白いこと聞けそうですね〜',)\n",
      "()\n",
      "('藤沼淳一',)\n",
      "()\n",
      "()\n",
      "('うちの勉強会では「まぁカウンター」なるものを使っています。\\n\\n単にカウンター(数取器)なんですが、「まぁ」「あの」「えーと」など言いがちな言い回しをカウントして、プレゼン終了後に「まぁ：●回」「えーと：▲回」などと数値でFBします。',)\n",
      "()\n",
      "('藤沼淳一',)\n",
      "()\n",
      "()\n",
      "('あとは、FBの時間を30秒(+最大10秒)と決めて「褒める内容は最少に。ダメなところを指摘しましょう。」とルール付けています。',)\n",
      "()\n",
      "('藤沼淳一',)\n",
      "()\n",
      "()\n",
      "('あとは内容によりますがライブ投票などの双方向性をもたせたものを途中で入れると「飽き」を防げて良いな−と思います。（数回しか使ったことありませんが。）',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('まぁカウンター、凄いですねｗ\\n\\n確かに口癖はつい出ちゃうので、そういう指標があれば改善しようと思うきがします！',)\n",
      "()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('藤沼淳一',)\n",
      "()\n",
      "()\n",
      "('自分では「“えーと“って3回くらい言っちゃったあなぁ」と思っていたところに「藤沼さん、今回は10回言ってました」とか指摘されるんで、より「気をつけよう」という意識が働きますｗ',)\n",
      "()\n",
      "('Yan',)\n",
      "()\n",
      "()\n",
      "('まぁカウンターのネーミング面白いですね。英語のプレゼンだとAH COUNTERって聞くので英語起因のネーミングだったりするんですかね。',)\n",
      "()\n",
      "('藤沼淳一',)\n",
      "()\n",
      "()\n",
      "('そこに気づかれるとは。笑\\nそうです、半分くらいが外国人スタッフなので。',)\n",
      "()\n",
      "('Yan',)\n",
      "()\n",
      "()\n",
      "('ローカライズ素敵です。',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "()\n",
      "('口癖は意識しないと治りませんね。そう意味でもビデオ撮影で目の当たりにするのは良いですね',)\n",
      "()\n",
      "('こ ろ ん',)\n",
      "()\n",
      "()\n",
      "('経済学に詳しい方おられますか？\\n政府の国債発行について伺いたいです。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@UQSRC415Y> \\n質問が短かすぎて、適切な回答がし辛い所あるから、以下のような内容を気をつけると良いかも！\\n\\nその聞き方だと、もし求めてる質問を知ってる人がいても、\\n\\n「そんな詳しくないから。。。」\\n\\nってなっちゃいそうです。\\n\\n<https://aws.amazon.com/jp/premiumsupport/tech-support-guidelines/>',)\n",
      "()\n",
      "('こ ろ ん',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'Yan', '吉村政彦ｰ産業ｽﾊﾟｲ', 'yuji.imuta')\n",
      "('設計',)\n",
      "('なるほど、言われてみればそうですね。\\n再度質問します。\\n\\n政府の国債発行の結果、むしろ国民の預金が増えることはわかりました。これは政府の国債に対して銀行が日銀預金で払うから？です。そこで疑問なんですがなぜ国民預金でなく日銀預金なんですか？\\n\\n素人なのでそもそもの理解が間違ってるかもしれません。教えていただきたいです',)\n",
      "('この辺とか比較的分かりやすいっすかね？\\n\\n<http://www.trend-review.net/blog/2012/04/002253.html>', '日銀預金がお金を擦る\\n↓\\n各銀行に貸し付ける\\n↓\\n銀行も色んな人に貸し付ける\\n\\nというフローで、流通額がどんどん増えていく仕組みという理解です。\\n\\nこの辺自分もちゃんと理解してないんで、間違ってるかもですが。', '拝見しましたが僕の望んでる回答はなさそうですね。\\n\\n記事内に以下の図がありましたが国債に対して端的に金とあるので、、、', 'この図で再度質問を簡単にすると、図中の金がなぜ国民預金ではなく日銀預金かなのです。', '預金って、出先、入り先だから、四角の中の話だと思うのですが、全部の「金」が日銀預金に当たる認識です？', 'すいません、全部じゃないです。\\n僕の理解だと\\n\\n政府、銀行、の間の金です。', '「なぜ」というのは、「制度設計上、なんでそんな仕組みになっているのか？」、ということです？\\n\\n銀行が日銀に預けたお金が日銀預金なので、銀行の預けている日銀預金が増えて、それをまた貸し付けるので国民預金も増えるって感じなのではと思います。', '国民預金という言葉僕間違ってますね、言いたかったのは銀行預金です。つまり国民の預金です。\\n\\n仕組み？といえばそうです。なぜ日銀預金を使う仕組みになっているかです。', '個人的な認識としては、日銀が絡むことで、「発行した通貨を世の中に流通量させる」という目的があるからかなと認識してます。', '<@UMG0947NY> \\n経済学科出身とのことですが、この辺詳しかったりしますかね？？\\n\\nトピックは、国債発行の仕組みと、制度設計的な話だと思います。', '典型的な用語整理が怪しい問題なので定義についてまとめながら考えるといいですね。', '銀行預金＝国民の預金が怪しい', '直感的には発行紙幣量が思考のポイントでインフレすれば単純に国民の預金額上がるんじゃないんかと', '&gt; 政府の国債発行の結果、むしろ国民の預金が増えることはわかりました。これは政府の国債に対して銀行が日銀預金で払うから？です。そこで疑問なんですがなぜ国民預金でなく日銀預金なんですか？\\n&gt; \\n&gt; 素人なのでそもそもの理解が間違ってるかもしれません。教えていただきたいで\\n国民の預金\\u3000と\\u3000国民預金\\u3000は同じ？\\n→銀行預金？\\n銀行預金です。つまり国民の預金\\nここの銀行とは中央銀行なのか（市中）銀行なのかどちらになりますでしょうか？\\n（解説の図が適当すぎる）\\nおそらく、図に「金→国民」がないからわかりにくいというのが問題な気がします。\\n\\n金が増えれば、政府と企業から金→国民となります。\\n\\n画像ではなくて元ソース貼ってくれるとイメージしやすいです。', 'とりあえず、データ分析全然関係なくてワロタ。\\n\\n>政府の国債発行の結果、むしろ国民の預金が増えることはわかりました。これは政府の国債に対して銀行が日銀預金で払うから？です。そこで疑問なんですがなぜ国民預金でなく日銀預金なんですか？\\n\\n諸々エスパーしつつ質問に対して回答を試みると...\\n\\nまず政府が国債を発行して銀行が購入する際に政府が得られるのは現金ではない。\\n代わりに銀行が保有している日銀当座預金が政府の日銀当座預金に振り替えられる。\\nそうすると政府はその日銀当座預金を担保に財政支出時に政府小切手を発行し、めでたく財政出動。\\n\\nそのあとは企業は小切手を銀行に持ち込んで...略。\\n\\n続けていくと銀行との間に国民預金が出てきますが、\\n質問に対する回答としては”国民預金は政府と直接接点が無いから”じゃないかと。\\n\\n別に専門ではないので適当な部分もあるかも。', '前半の預金が増えるパートを意識的に流して後半の質問部分にフォーカスして回答したら謎回答になってますね。校正する気力が無いので自分の回答もエスパーして意図を汲んでいただければ。お役に立ってれば幸い。', '直接な接点がないのはそうですね、しかしどうしてもふに落ちません。。勉強しなおします。みなさんすいません、ありがとうございます。', '<@UL2TY2ERL> <@UMC518ER0> \\nフォローありがとうございます！！\\n\\n<@UQSRC415Y> \\n・質問対象に対する解像度\\n・自分の疑問に対する解像度\\n\\nを上げていくと、より求めてる回答や、専門的な知識を持ってる人の回答を引き出せるんじゃないかなぁと思います！\\n\\n色んな質問あると面白いので、質問は今後もどんどんしちゃってくださいー！', '<@UQSRC415Y>  さん\\nこの漫画、オススメ(*^_^*）\\n\\nキミのお金はどこに消えるのか <https://www.amazon.co.jp/dp/4041071100/ref=cm_sw_r_cp_api_i_wq75DbMT60MNF>', '昔中国嫁愛読してたんですけど、この本は作者がどこまでわかってて書いてるのか判断しづらくて読んでて不安になるんすよね...。', 'その作者は正直嫌いだけど、この本に限って言えば、ちゃんと経済の専門家が付いて監修してる感がちゃんとあったので可。\\n\\nコイツに好き勝手書かせると駄目(笑', 'なるほど、専門家がいると多少読む気になれますね\\n\\n本関連で言うとランダルレイ先生のmmt理論は読んだ方いますか？', '監修の意見なのか、彼の意見なのかよくわからんのが、自分が耐えがたいポイントかも。', '日本語の先生（ATOKの人）の奴は「何言ってんだテメェ？」だったけど、こっちはマトモ(笑', 'なるほど。最初の方で脱落したので、また読んでみよっと。', '<@UJRAL005U>\\u3000ギルド代表\\u3000筋トレで学ぶデータ分析\\n最近slack 全然見れてなくて、すごい反応が遅くなりました。。そして、経済学出身ですが、お力にはなれませんでした。。今更ですが、申し訳ないです。。')\n",
      "('こ ろ ん',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '吉村政彦ｰ産業ｽﾊﾟｲ')\n",
      "()\n",
      "('債券について質問です。\\n\\n債券にレバレッジをかけるという行為がわかりません。債券はそもそも利息がリターンになりますよね。レバレッジをかけると何がリターンで何がリスクなんですか？投資額のレバレッジ倍で計算した利息であってますか？そうなるとリスクってなんや、、ってなってよくわかりません。簡単に説明していただけると助かります。\\n\\n\\n<https://financial-field.com/assets/2019/04/09/entry-41362>',)\n",
      "('言葉があやふやなので用語()で自分の認識を書いて戴けると専門用語かできます。', '前回みたいに\\u3000銀行でも中央銀行と市中銀行で意味が全く違います', 'たとえばどこですか？債券なら日本か海外か、みたいな話ですか？特に指定はないです', 'とりあえずwikiで債権調べても◯◯債権で10個以上あります。', '会計学もそうなんですけど\\u3000手形で同じことがおきます', '質問の核はあくまで債券のレバレッジに対するリスクリターンについてであり、それを踏まえるとどの債券であろうが同じ議論になると思うのですが、\\n\\n仮にリターンは大きいですか？リスクはどのくらいですか？という問であればそれはおっしゃる通りで焦点を絞るかまたは相対的な議論になると思いますが。今回は必要ないのではと思います', 'もし、レバレッジ対象の債券によってそのかけ方自体が変化または、リスク、リターンが異なるのであれば私の質問の仕方がわるいです、すいません', '100円をそのまま使う\\n\\n1%増・・・1円利益\\n1%減・・・1円損失\\n\\n100円を担保に1万円で取引\\n\\n1%増・・・100円利益\\n1%減・・・100円損失\\n\\nという話ではないですか？\\n\\n上記はリスクもリターンも100倍になるという話だと思います。', '単にそれでいいのでしょうか？どうもふに落ちないのですが、、ありがとうございます', '<@UQSRC415Y>\\n株をやってらっしゃるとの事ですが、先物と、先物オプションって解りますか？', '先物はやってないのでわからないです。', '債権と云うのは、インカムゲインが基本ですが、若干の値動きもある為、株のように安く買って高く売ればキャピタルゲインが得られます。\\n\\nしかし値動きが僅かなので、基本的にキャピタルゲインは望めず、自ずとインカムゲイン目当てで大量保有するのに適しています。\\n\\nまた株と違って期日が来れば満額手に入る為、安心感があります。\\n\\n一方、債権にレバレッジを掛けた商品とは、そもそも「債権では無い」ので、それそのものに価値は無いです。対象債権の値動きに指数を掛けて「キャピタルゲインを目的として売買するもの」と考えてもらってOKです。そういう意味で、先物と先物オプションの関係に似ています。\\n\\n値動きの根拠は対象債権なので、債権にレバレッジを掛けた商品を幾ら売買しても「債権そのものの価格に影響は無い」点に注意して下さい。また同時に「実態が無い商品」なので、対象債権が上がると思っても「売りを引き受けてくれる人と玉数」が伴わないと、売買が成立しません。\\n\\nまたこの手のオプション系金融商品は値動きが大き過ぎる＆証拠金取引の為、現物株の様に「暴落時に売らなければ損失も確定しない」と云う類のものではなく、レバレッジが効いた状態での値動きが証拠金を超えるようであれば追い証を要求されたり、若しくはその前に強制売却されるので、良く分からない＆余程のお金持ちでも触らないのが無難です。', 'なるほど、先物に近いものなのですね、どうりでわからないわけです。\\n\\nもう少し基本的なところを勉強したほうがいいかもしれません、いい機会になりました。ありがとうございます。')\n",
      "('こ ろ ん',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'maimai', '吉村政彦ｰ産業ｽﾊﾟｲ', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('教科書',)\n",
      "('プロトコル勉強中なのです\\n\\nリトルエディアンなど\\n:star:0x80 as 7bit variable integer\\n以外の部分は理解しているつもりです。\\n逆に:star:の部分がわからないです。\\n\\nこれがなんのためにあるか理解できません。\\n\\n8bitの穴埋めなのかな？と思いましたがそうであれば0x80 0x00ではなく0000でいいと思いました。\\n\\nどなたか説明お願いします。',)\n",
      "('ちなみにこれってieeeと関係ありますか？', '質問する前に、コンテクスト揃えた方が良さそうですね。\\n\\n以下の記事などが参考になると思います！\\n\\n<https://www.trivector.co.jp/contents/?p=2493>\\n\\nころんさんの質問って、トピック外の質問かつ、はいコンテクストすぎて、回答難しいんですよねw', '&gt; 「コンテクスト」とは、「文脈や背景」と訳されますが、つまり言外の部分＝「文化、慣習、知識、価値観」などのことを指します。\\n\\n難しい、、ですね、、少し追記します', '言わなくてもわかる～！伝わる～って文化ですね:slightly_smiling_face:', '通信プロトコルの場合、送信側と受信側でエンディアンが異なっている場合があるので、それに備えてそうなってたンじゃないかな・・・うろ覚えだけど(笑', '文脈的にそれはないと思います！', '<@UQSRC415Y>\\n先日から、恐らく皆さん困るような質問が多いので、質問の仕方に関して、少し丁寧に解説させて頂きますね。\\n\\n多分頂いた質問だけだと、他の方からすると、\\n\\n・どういう経緯でプロトコルを勉強しているのか分からない\\n\\n・何故リトルエンディアンの話になっているのか分からない\\n\\n・何のプロトコルの話をしているのか分からない（プロトコルって言っても色々ある）\\n\\n・どう考えた結果として、何故つまっているのか分からない\\n\\n・周辺知識として、何をどこまで理解しているか分からない\\n\\n簡単に言うと、「リトルエンディアン」、「プロトコル」というキーワード以外はほとんど何も分からない。という状況なんですよね。。。\\n\\n詳しい人が答えるとしても、どこまで専門的な用語を使って良いかも分からない。という状況かと思います。\\n\\nなので、この状態で質問に答えたとしても、求めている回答を返せる人は皆無だと思います。\\n\\n先日Yanさんが使ってたワードが正にそれに当たるのですが\\u3000、「エスパーしないと何を疑問に思っているか分からない」というような状況です。\\n\\nで、どういう風に質問を整理するかというと、基本的には以下のようなプロセスが必要となります。\\n\\n１．何が分かっていないか整理する\\n\\n２．自分がどこまで理解しているか整理する\\n\\n３．質問の想定対象者を決める\\n\\n４．その質問想定対象者に自分の状況を正しく伝えるためにはどうすれば良いかを考える（思考やその考えに至った背景を共有する）\\n\\n数学科だと思うので、数学の問題に置き換えて話すと、位置の関数から速度を求める際に、\\n\\n・位置情報を微分したら速度になるという情報を知っている\\n\\n・微分のやり方を知っている\\n\\n・具体的に計算できる\\n\\nみたいなステップを踏んで、どこまで理解しているかを整理するかと思います。それと同じような感じで、「ここまでは分かっているけど、ここからが分からない」という感じの説明をしてあげる必要があります。\\n\\nその際に、\\n\\n「この教科書のここを読んで微分のやり方は理解できたけど、練習問題が解けない。この式変形が分からない。」\\n\\nというような質問をした方が理解しやすいですよね。\\n\\n上記の１．の段階で躓いてしまうこともあるかと思うので、その際はその旨がうまく伝わるように質問してあげないといけないです。\\n\\n質問する技術が無いと、質問する側もされる側も不毛に時間を使うだけになってしまうので、質問する際は、\\n\\n・何が分かっていないか？\\n・自分がどこまで理解しているか？\\n・どうやればその状況、理解を再現できるのか？\\n\\nが含まれるようにしてください。\\n\\nまた、「正しく質問するために内容を整理する」というプロセスを踏むと、その過程で解決することも多いと思います。\\n\\n自分はサービス提供しているのである程度は答えますが、他の方に関しては完全に善意で答えて頂くことになるので、善意に甘えるのではなく、きちんと質問整理してくださいね。\\n\\n他人の善意に甘えるのは良くないですし、善意で答えてくれるひとのために、質問をきちんと整理するというのは、最低限の礼節だと思います。\\n\\nきちんと相手のことを思って質問できる人と一緒にプロジェクトをしたいですし、非常に重要なスキルなので、意識して取り組んでみて頂けると嬉しいです。', '写真の回転のさせ方はベクトルどう処理すればいいのか？\\n考えるところから思考の整理をしてみると良いですよ。無駄な思考時間取らせると欲しい情報が出てこなくなります。\\n\\n思考のプロセスを考えると難しいことがわかるようになます。')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('クラスタリング', 'kaggle', 'データサイエンティスト')\n",
      "('類似ユーザー抽出関連のタスクこなしたことある方いらっしゃいますか??\\nlook a like model のようなものです・・',)\n",
      "('ユーザークラスタリングと、クラスタ振り分けであればよくやりますが、イメージ近いですかね？', '近いかもしれません！\\nユーザー同士の類似度を算出したいのですが、説明変数なににするかや、これってルールベースで区切った方が、良いものなのか気になっています。。。。', '分類に関してはk-meansなどで分類して、運用に関してはルールべーすでやるみたいなアプローチはしますね。', '「ユーザーを分割するにはどうすればいいか？」というのは、色々と試行錯誤しながら納得感がある分類にして行くのですが、\\n\\nMAツールとか配信ツールで使う際は各特徴量のif文で書けた方が便利なので、そういう切り分けが多いかもです。', 'もしくは、RFMみたいな感じでドメイン知識フル活用して最初から軸は決めちゃうとかですかねー。\\n\\nある程度基礎分析は必要になるとは思いますが。', '軸決めに悩んでたりしまして、、\\nRFMは完全に頭の中から抜けてました\\nマーケ寄りのタスク今やってるのですが、ドメイン知識不足すぎてしんどいです・・笑', 'ステップとしては、RFMとかの基本的なところやり切った後にクラスタリングとかのイメージなので、まずはRFMとかをしっかりやってあげると良いかもしれませんねー！！', 'なるほど。。。\\nなにをベクトルとして扱うかったことで悩ませてて、、、、', 'そこは業務領域によって違うので、まずは基礎分析ありきって感じではありますね。\\n\\n・目的変数に関連がありそうな指標\\n・サービスに対するユーザーの特徴が良く表れている指標\\n\\nを探すことになるのですが、そこが分析の肝でもあるので、一概に何の指標が良いとは言い切れないんですよね。\\n\\nECだったらRFMですし、サブスクリプションやゲームみたいなサービスなら、アクティブな期間、継続期間とかが当たるかもしれません。', 'そうですよね・・・\\n難しいですが、この仕事の楽しさってこういうところなんだなあって実感しましたw', 'モデリングは一瞬なので、なんだかんだこういう試行錯誤がデータサイエンティストの主な仕事なのかなぁと思いますｗ', '実務でkaggle のようなスコアをギリギリまで最大化することはないので、\\nモデルのところは他の人にお願いしちゃいますね。。分析とかの方が楽しいですw', 'そうなんですよねーｗ\\u3000ユースケースを整理したり、運用に乗せる所、効果があったか検証する所などが骨折れますねｗ', 'いまちょうど運用を考えるところで、これ実行時間とか現実的なのか?・・・ってところで頭悩ませてます・・・\\n効果測定も考えなきゃいけなくて、初のPJ１人でこれはしんどいなーって日々思ってますw', 'ただ楽しいので不満はないですが・・・w', '効果測定はコントロールグループとかを作って、RCT的にやるのが一番シンプルでねー。\\n\\n該当クラスタ、それ以外のクラスタに該当クラスタ向けの施策を打ってみて、反応率を比較する。みたいな感じです。', '&gt; 初のPJ１人でこれはしんどいなーって日々思ってますw\\nこれはめちゃくちゃしんどそうですねｗ\\u3000先生がいるといいんですけどねー！', '効果測定も結構なやんでまして,今やりたいと感じてるのが、upliftmodeling  ってやつと因果推論の勉強して使ってみたいなあ・・って感じです', '先生が欲しいです・・・・', '因果推論は確かにありですね！\\n\\nただ、実験できないときにデータからなんとか頑張る手法だったりもするので、\\n\\n・実験的に施策打って効果を検証\\n\\n・因果推論して、その結果を現場に共有\\n\\nで、どちらが良いか比較が必要ですねー。この辺は、現場のリテラシーにもよりますw', 'なるほど！！！\\n現場は完全自分まかせなので、結果さえ出せばOKなところがあるので、自由すぎて逆に難しいですw', 'それなら、やりたい方でやっちゃいましょうw\\n\\nグロースハック的なキャリア伸ばしたければ小刻みに施策検証をスピーディに回した方が良いですし、\\n\\n確実に成果出したいなら因果推論ベースが良いかなと！\\n\\n「とりあえずやってみる」が許される現場であれべ、グロースハック的なアプローチの方が上手く行くかなぁという印象ですね。', 'なるほど！！\\n工数の見積もりとかもやったことがないので、おそるおそるでやってる感じです・・・・\\nグロースハック的なアプローチで行ってみようかと思います！！！')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '吉村政彦ｰ産業ｽﾊﾟｲ', 'Katsuya Nagano', 'shimizu', 'ﾋﾛﾘｰ', 'Yan', '鈴木裕太', 'asuki.u')\n",
      "()\n",
      "('口直し\\niPhone SEの次に買うべきスマホがわからない。\\nサイズ的には8しかないのかな？',)\n",
      "('SE→10にしましたが、デカい画面は快適ですよー！', '手がちっちゃいのでサイズ感で迷っています。11までジャンプしようかな・・。', 'ただ、手のフィット感はないですねw', '両手で持ってちょうど良い感じではありますね', '電車の中つらいんですよね〜。', '他の方のご意見有れば', 'リング付けたりする人もいますがそれでも画面上部のタッチとかは厳しいっすね', 'iPhone7→iPhone11に変更・・・デカい(つД`)', 'iPhone8ですが、ゲームもしないし音楽もスマホではあまり聞かないし、カメラも稀にしか使わないので脱iPhoneしてミドルクラスのAndroid機種でいいのではと思ってますが使ったことないOS(Android)でUIとか覚えるのめんどくせぇなぁってのが現在です。', 'SE→iPhone11\\nでかいと感じましたが、\\n• バッテリーの持ちが段違い\\n• Apple Payが便利\\nという利点がでかいと思います', 'なるほど、やはりサイズを考えて結局8かな～。\\n\\nSEゲーム動かないのとバッテリーが辛い。', '私の場合、安心感の点から、ケース内蔵型バッテリーを使ってるので、iPhone7もiPhone11も重くて分厚いです(笑\\n\\nでも、予備のモバイルバッテリーを持ち歩かなくとも良くなった（ケーブルを良く忘れるw）のはオススメポイントです。\\n\\nただ、まだiPhone11用のQiにも対応したバッテリー内蔵型ケースは純正の1.5万位する不格好なヤツしか無いので、サードパーティー製待ちです(*^_^*）', 'リングつけるのおすすめですよー！', '11。手がデカい族。\\n\\n極端に小さくなければ手のサイズより持ち方への慣れの要素の方が大きいんじゃないですかね。握るというよりは4指に乗せる感じで打つので自分の手のサイズだともう少しデカくてもいけます。', '8か11のアンケート', 'と言いつつ待てるならUSB-Cモデルを待ちたい。iPadの充電時間との差がすごい。', '果たしてusb cモデルは発売するのでしょうか。。。非接触充電オンリー説も出てますが(更に時間差がヤバそう', '11  パソコンより高いイメージw', '実はスタンダードの11だけなら意外とコスパいい\\n11 proと望遠カメラついてる以外はCPU性能変わらないし', '同様に考えて素11にしましたが、apple党が唱えるコスパの薄っぺらさと言ったら...。', 'ブランド価値込みでのコスパって言ってますからねw', '我々信者は薄々現実に気付きつつもお布施を定期的に納め続け...。\\nスイッチングコストの概念を学ぶ素敵な教材ですよね。', '<@UMC518ER0> 極端に手が小さいんです・・・', '試しに、安くて同じサイズ感のAndroid使ってみたら', '5.5inch持っていますがでかいw', '自分は 片手で気軽に使えるSEが大好きなので、SE2が出るまでまだ待つことにしました:joy:\\n\\nそのため、この前 アップルストア銀座にいって バッテリー交換してきました。およそ 6000円 でした。', '1年前にバッテリー交換しましたw', 'なるほど！それなら やっぱり バッテリー弱いですねw\\n\\nあと今月 30日に 理想的なシンプルな形で iPad miniが 発売されると 昨日知ったので、中途半端な画面サイズは捨てて、それを買って、 iPhone SE と 新しい iPad mini の使い分け 作戦で いくつもりです\\\\(´ω` )\\nアップルペンシルが使える iPad miniが楽しみです:relaxed:')\n",
      "('Riita Satsuki',)\n",
      "('Yuta Kita',)\n",
      "('pandas', 'Python', 'Docker', 'Git', 'Linux')\n",
      "(\"`ImportError: pandas-gbq requires google-cloud-bigquery: cannot import name 'collections_abc'`\\n\\nこのエラーpandas-gbqで出るっぽいんですけど、\\ncollections_abcってなんだかわかるかたいらっしゃいますか\",)\n",
      "('<@UQXUSE316>\\n<https://github.com/pydata/pandas-gbq/issues/304>\\nこれですね！！！\\n助かります！！\\nありがとうございます！！\\nまだ解決はしてないですが汗', '全然違いましたね笑', 'いや、同じですよ！！！！', 'え？そうなんですか笑\\nとりあえず、良かったです', 'なんかGoogle側のバグっぽい感じですよね\\nsixのバージョンとか依存関係ごちょごちょすると治りそうですが、\\n時間経てばきっと誰かが直してくれると思うので待ちます', 'そうですね\\nsixの特定のバージョンしか動作しなさそうです', 'こういうのって待ってれば大丈夫ですよね？？', 'sixのバージョン指定して環境作りに行ったほうがいいですか？', '他の依存関係壊れたりしたらめんどくさいなぁという思いが', '確かに…\\n依存関係が面倒だから待ったほうが安全かもしれないですね\\nGoogle Cloud Pythonの1.23.1で対応予定みたいですね\\n<https://github.com/googleapis/google-cloud-python/pull/9981>', '今は1.23.0ですかね', 'Pythonのバージョンですか？\\nGoogle Cloud  Pythonってなんですか。。。', 'あ、パッケージ名はgoogle-cloud-bigqueryですね（Google Cloud PythonはGitHubのリポジトリ名ですね）\\npandas-gbqが依存しているパッケージです\\n↓の25行目です\\n<https://github.com/pydata/pandas-gbq/blob/master/setup.py>', 'これ本番混ぜられてるんですかね。\\npip --upgradeしたらいけるってことですかね。', '```RUN pip3 install --upgrade pip\\nRUN pip3 install --upgrade setuptools```', '最新リリースされてるのでいけるかもしれないですね', 'おお！！やってみます！\\nありがとうございます！', '最悪はsixのバージョンを下げればいけるのかな\\nsix &gt;=1.13.0,&lt; 2.0.0dev\\n<https://github.com/googleapis/google-cloud-python/pull/9979/commits/f8ec989957f5d806295d5fe482a5df027b7dcba8>', '```RUN pip3 install --upgrade pip\\nRUN pip3 install --upgrade setuptools```', 'したけどだめでした….', 'まじっすか…', 'sixのバージョンってどこで指定するんですか？', '`pip install six==1.13.0`', '↑のコマンドで特定のバージョンのインストールですね', '今の状態ってpipに依存関係を任せてると、依存関係修正されてだめになっちゃうって話ではないですか？', '別に1.13.0がだめなわけじゃないからいいんですかね', 'sixのバージョンは確認しました？\\n現在のバージョンの確認コマンドは↓ですが、2.0.0devとかになってたり？\\n（Linux環境での確認方法です）\\n`pip freeze | grep six`', '`six==1.11.0`', 'ってなってます！！！\\nこれがだめっぽいですね', '`pip install six==1.13.0`\\nでできました！！\\nありがとうございます！！！', 'おお、おめでとうございます！', 'ありがとうございます〜:bowtie:\\ngithubでissueを探して解読するやり方も学べたので勉強になりました:man-bowing::man-bowing:', 'お疲れさまでした！', 'もしかしたら普通にupgradeでいけたかもしれないですね…\\nより正確にするにはこっちのコマンドのほうが良さげです\\n依存関係も確認するはずなので\\n`pip3 install --upgrade google-cloud-bigquery`', 'pip3 install google-cloud-bigquery\\nってやってるんですけど、\\nこれでも同様に依存関係確認しますよね？', 'そうですね\\n依存関係見るはずですね', 'じゃあ、多分だめそうです。', 'GitHub見る感じだとなんかcloseしてておいって感じですよね…笑', '確かにそうですね笑\\nちょっとコマンド打ってみたんですが\\npip3 install google-cloud-bigquery==1.23.0  → 1.23.0でインストール\\npip3 install google-cloud-bigquery → 1.23.0のまま\\npip3 install --upgrade google-cloud-bigquery  → 1.23.1になる', '上から順に打ったんですけど、「--upgrade」のオプションが無いとバージョンが上がりませんね', 'pip3 uninstall google-cloud-bigquery\\npip3 install google-cloud-bigquery\\nってやっても1.23.0になるってことですか？\\nその時ってpip3 checkに引っかかってるんですかね？', 'そのコマンドだと1.23.1になりますね\\nuninstallコマンドを実行せずにinstallコマンドを実行した場合は1.23.0のままになってしまうようです', '僕は毎回Dockerfileビルドしてたんで\\n依存関係確認していたような気がしていたんですけどね…', 'DockerのBuildのキャッシュが残っていたりしたのが原因ですかね…', '```Step #0: Collecting google-cloud-bigquery&gt;=1.11.1\\nStep #0: Downloading <https://files.pythonhosted.org/packages/b5/6c/b3ae29876dbbd63ca8fdf284fdf07ef025c06feacb18710e9571f6641246/google_cloud_bigquery-1.23.1->```\\nCloud runでキャッシュオフにしてるのでそもそもキャッシュないんですよね。\\nなんですけど、だいぶバージョン違うのインストールしてましたね', 'なるほど…なんなんだろうか…\\nまたわかったら教えてください！', \"`Step #0: ERROR: google-cloud-bigquery 1.23.1 has requirement six&lt;2.0.0dev,&gt;=1.13.0, but you'll have six 1.11.0 which is incompatible.`\", 'なんかこんなエラー吐いてましたね', 'いや、直せよっていう()', 'こーゆーのって先ほどおっしゃってたみたいに、マジックナンバーでバージョン指定してあげるのが一般的なんですか？\\n基本 pipにいつも丸投げしてるんですけど', 'いえ、全く一般的じゃないはずですよ笑\\n最終手段かと思います', 'incompatible\\nってわかってるなら修正して欲しいですよね…', '確かに()', 'もしかしたら他のパッケージでsixのバージョンが低くないといけないのがあったのかもしれない…', 'つまりそれって何かがやばいってことじゃないですか….', 'バージョン管理って大変ですね', 'それだとやばい…', '大変ですね…', 'とりあえずお疲れさまでした！\\n今日はこのへんで…\\npip3 checkしたらどうなるかが気になりますが…')\n",
      "('shimizu',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Katsuya Nagano')\n",
      "('教科書',)\n",
      "('「データ分析結果を見せる作法」が載っている本を探しているのですが、どなたかご存知でしょうか？',)\n",
      "('データビジュアライゼーションの教科書 <https://www.amazon.co.jp/dp/4798053481/ref=cm_sw_r_cp_api_i_9Sb.Db1G0Y265|https://www.amazon.co.jp/dp/4798053481/ref=cm_sw_r_cp_api_i_9Sb.Db1G0Y265>', 'ありがとうございます！読んでみます！', 'この辺とかも良いですね\\n\\nグラフをつくる前に読む本 一瞬で伝わる表現はどのように生まれたのか <https://www.amazon.co.jp/dp/4774192198/ref=cm_sw_r_cp_api_i_Acc.DbF135RE9|https://www.amazon.co.jp/dp/4774192198/ref=cm_sw_r_cp_api_i_Acc.DbF135RE9>', 'いい感じに見せるという意味でなら、Google流資料作成術という本が、まさにそれですね。\\n邦題がクソですが、原題はStorytelling with Dataです。データにストーリーを語らせることを主眼としたスライド作成本です。Google関係ねぇ。\\n<https://www.amazon.co.jp/dp/4534054726/ref=cm_sw_r_tw_dp_U_x_Zwd.DbTD78XX4>', '良さそうな本なのにタイトル詐欺？（笑）\\nありがとうございます！', 'Amazonレビューでも結構邦題叩かれてますｗ')\n",
      "('shimizu',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '鈴木裕太')\n",
      "('可視化', '機械学習')\n",
      "('↑に因んでですが、\\n実際にコンサル系の業務をされている方は会社上層部やお客様にデータを使ってお話するときって\\n業務経験に頼るしかないのでしょうか？\\nそれとも、何か虎の巻のようなものがあるのでしょうか？\\nだいぶ想像に頼った質問で恐縮ですがよろしくお願いいたします:man-bowing:',)\n",
      "('きちんとした可視化結果と考察があれば、大体話はスムーズに行くイメージですね。\\n\\n機械学習のモデルを使った説明とかなら、変数重要度の読み解き方や注意点を概要で説明してから共有するなどのアプローチを取ったりします。', 'なるほど〜。\\nまず「可視化結果」と「考察」に注意してやってみたいと思います！:man-bowing:', '上手く行かない事例としては、分析官の中で落とし込みができていなくて、「つまりどういうこと？」みたいな質問に答えられないシーンが多きがしますー！', 'ということは、砕いた言葉や言い換えで分かってもらうというスキルも大事になってくるんですね？', 'そうですね。本質的なポイントはずらさずにクライアントの理解しやすい言葉に置き換えて話すのは大事ですね。\\n\\nユーザー分析だったら、「XXというページでの離脱率が上がり、OOというサイトでの離脱率が下がりました。」という説明だとポイントが伝わりづらく、「この期間ではこういう属性のユーザーが多く来ていて、こういうものに興味があるユーザーなので、OOには興味がありそうだけど、XXには興味がなさそうかもしれない。」みたいな、何が何故起こるか、付加情報まで含めて伝えることが重要ですね！', 'あと、施策提案の時は、フェルミ推定的な過程は結構重要だったりするかもしれません。', '&gt; 「XXというページでの離脱率が上がり、OOというサイトでの離脱率が下がりました。」という説明だとポイントが伝わりづらく、「この期間ではこういう属性のユーザーが多く来ていて、こういうものに興味があるユーザーなので、OOには興味がありそうだけど、XXには興味がなさそうかもしれない。」\\nこれって、つまり自分なりの解釈を入れるって認識で合ってます？', 'ですね。解釈を入れつつ、解釈と集計結果は切り分けて伝えられるようにしています。\\n\\nアナリストは分析結果だけを渡せば良いと話もありますが、個人的には、こちらで解釈までした方が良いと考えていますね。', 'その解釈に至ったプロセスをきちんと説明できれば、クライアントが当たり前に捉えているドメイン知識を引き出せたりするので。', '&gt; アナリストは分析結果だけを渡せば良いと話もありますが、個人的には、こちらで解釈までした方が良いと考えていますね。\\nこちらの考え方とても共感できるので、私もこの姿勢でやってみたいと思います！\\nなるほど、解釈を話して「〜と思うんですが実際のところどうですか？」っていう展開もできるんですね！', 'ですね。基本的に、外様で入っている場合は、お客さんの方がビジネスについて深く理解しているというスタンスで、データとビジネス実態の整合性を取って行くみたいな感じになるかと思います。\\n\\n変な分析結果が出たりしたときに当たりつけて貰えたりしますしね。逆に、そういった質問でクライアントも把握していないようなことから情報共有の問題が発見出来たり、新しい知見が生まれたりしますね！', ':いいですね:')\n",
      "('seiyakitazume',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('ベイズ', '機械学習', '時系列', '転移学習', '統計')\n",
      "('【コンバージョンから60日間(もしくは30日間)しかデータがない中でのECのLTV予測について】\\nキタヅメと申します。\\n自社サービスとして、送客した顧客の質によって変わるASPシステムを構築したいと考えております。\\nそのため、予測LTVの値によって、報酬を変えるASPシステムは作れないか考えていました。\\nコンバージョン後、あまり時間をかけすぎると、アフィリエイターさんに報酬を払えないので時間がない中で、予測LTVを求めたいのですが、検索するとやはり初回購入からたっぷり時間が経ったデータを使ってLTV予測をしています。\\n\\n例えば、こちらの記事ではRFMスコアを使ってLTVを予測しているようです。\\n<https://towardsdatascience.com/data-driven-growth-with-python-part-3-customer-lifetime-value-prediction-6017802f2e0f>\\n\\n初回購入から90日間で時系列も考慮したLTV予測についてはこちらの記事がありました。こちらは60日間でも出来そうですが、精度はそんなに高くないんだろうなぁと予想しています。\\n<https://ameblo.jp/cyberanalyst/entry-11819955628.html?frm=theme>\\n\\nこれからLTVに予測に関する論文も読んでいこうと思うのですが、コンバージョンから60日間のデータだけを使ったLTV予測という状況が特殊なので、参考になる論文あるかなぁと思ってます。\\n\\nみなさんのオススメの情報があったら、是非、教えてください！！何卒、宜しくお願い致します。',)\n",
      "('<@UMFGQHD46>\\n60日で推定しようと思うとなかなかシンプルな機械学習だと難しそうなので、一般的な購買モデルを仮定してあげて、推定値を出してあげるなどの必要がありそうですねー！\\n\\n■STEP1 サービスのモデル推定\\n\\n・全ユーザーのうち再購入する人の割合確率\\n・再購入する時間に関する分布\\n・購入毎にどのくらいの金額を使用しそうかの利用金額確率分布\\n\\nといった所をある程度解析してあげて、確率分布を出す。\\n\\n■STEP2汎用モデルの作成\\n他のECサイトなどでも使えるRFMのようなモデルから、ユーザー単位に予測値を算出するための数式をモデル化する。\\n\\n■STEP3\\nSTEP2で作成したモデルを使用して、個別ユーザーに対するLTV予測を実施する。\\n\\nみたいな感じですかね？STEP2→STEP3などは、転移学習でも行けそうな感じはします。\\n\\nシンプルにやるなら、Stanとかを使用してベイズ統計モデリングとかって感じですかね？\\n\\n複数のサービスのLTVを他サイトのモデルに使用できるような許諾が必要になって来ると思うので、なかなか大変そうですね。。。', 'ご返信ありがとうございます！！\\nRFM使いたいのですが、リーセンシー・フリークエンシーが60日間だとバラけないけど良いのかなぁと思ってました！\\nただ、60日でも数値出してしまって、使ってしまうのアリかもしれないですね！\\nありがとうございます:blush:', '何か伝わってない気がしますねｗ\\n\\nどんな感じのモデル構築を考えていますでしょうか？', 'すみません汗\\n\\nモデル構築自体、まだ定まってないですー。\\n\\nMediumの記事でもLTV予測にRFMスコアを使っていて、これは使いたいと思ったのですが、購入から60日間のデータでRFMで分けてしまって良いのかなぁと思っていました！')\n",
      "('ｸﾛ',)\n",
      "('はやと-休学中の文系学生',)\n",
      "('統計', '統計検定')\n",
      "('恥ずかしながら統計の知識が高校までで止まってしまっていて、統計検定二級を目指そうかなと考えています。\\nおよそどれくらいの時間がかかるのかと、良い教材があれば教えていただきたいです..',)\n",
      "('自分は6月に取ったんですけど、熊田さんがおっしゃるように統計webと、あとは過去問集を買ってひたすら解きました〜\\nあとは辞書代わりに統計検定2級の公式本を使いました', '高校までちゃんとやってるなら参考までに自分は同じところから100時間弱かかりました')\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('統計',)\n",
      "('統計理解していなくても合格はできるので、詰め込めば1ヶ月でいけます！\\n内容もちゃんと理解してだと、ある程度腰を落ち着けて学習しないといけないんで、2ヶ月から3ヶ月はみた方が良いかと',)\n",
      "()\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "('ｸﾛ',)\n",
      "('統計',)\n",
      "('統計の時間は二級対策としては、スタンダードかと\\n\\n<https://bellcurve.jp/statistics/course/|https://bellcurve.jp/statistics/course/>',)\n",
      "('ありがとうございます！やってみます',)\n",
      "('熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者',)\n",
      "()\n",
      "('書籍',)\n",
      "('書籍だと、個人的には以下がオススメです、\\n二級よりも広い範囲を浅く広くって感じですが、全体像を掴むのに良いかと\\n\\n<https://www.amazon.co.jp/%E5%85%A5%E9%96%80-%E7%B5%B1%E8%A8%88%E5%AD%A6-%E2%88%92%E6%A4%9C%E5%AE%9A%E3%81%8B%E3%82%89%E5%A4%9A%E5%A4%89%E9%87%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E5%AE%9F%E9%A8%93%E8%A8%88%E7%94%BB%E6%B3%95%E3%81%BE%E3%81%A7%E2%88%92-%E6%A0%97%E5%8E%9F-%E4%BC%B8%E4%B8%80/dp/4274068552|https://www.amazon.co.jp/%E5%85%A5%E9%96%80-%E7%B5%B1%E8%A8%88%E5%AD%A6-%E2%88%92%E6%A4%9C%E5%AE%9A%E3%81%8B%E3%82%89%E5%A4%9A%E5%A4%89%E9%87%8F%E8%A7%A3%E6%9E%90%E3%83%BB%E5%AE%9F%E9%A8%93%E8%A8%88%E7%94%BB%E6%B3%95%E3%81%BE%E3%81%A7%E2%88%92-%E6%A0%97%E5%8E%9F-%E4%BC%B8%E4%B8%80/dp/4274068552>',)\n",
      "()\n",
      "('K.FUKUHARA',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('機械学習',)\n",
      "('お疲れさまです。自分はデータサイエンスも機械学習も初級者なんですけど、このギルドのおすすめの利用法はありますか？\\n今はcourseraのmachinelearningコースの修了を目指しています。',)\n",
      "('今皆さんで執筆しているAdvent Calendarに活用方法書いてる方結構いらっしゃったので、参考になるかもです！\\n\\n<https://qiita.com/advent-calendar/2019/data-learning-guild|https://qiita.com/advent-calendar/2019/data-learning-guild>',)\n",
      "('K.FUKUHARA',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'れごん-島根のﾌﾘｰﾗﾝｽ', 'はやと-休学中の文系学生', 'Katsuya Nagano')\n",
      "('kaggle', 'BQ')\n",
      "('1年と半年くらいのうちにkaggleのコンペで上位10％くらいを狙えるようになりたいです。（難しいレベルだとは思いますが…）',)\n",
      "('<@UKT5BQD3P> <@UL0NZCCMT> \\nこれは、kaggle expertにアドバイス頂きたい所ですね。\\n\\n個人的には割とちょうど良いレベル感なのかなぁと思いますー！', '上位10%はゴールドメダル圏内なので、ソロで取るのであれば何か他の人が見つけていない手法や特徴量を作れるようになる必要がありますね。\\n\\nコンペに使える時間があり、カーネルやディスカッションの情報を統合できれば、銀メダルは狙えて、銀メダル圏の人達とチームマージしたら金メダル圏(Top10%)は狙える数字だと思います。', 'あれ、Top10%って銅メダルじゃないですか？？', '人数によって変わりますね。\\n<https://www.kaggle.com/progression|https://www.kaggle.com/progression>\\n\\n100チーム以内であれば10%が金メダル圏内で、1000チーム超えれば10%は銅メダル圏内でした。\\n\\nであれば、テーブルデータはkaggle本読んで、画像系であれば、最新論文手法読めれば狙えるレベルだと思います', 'ありがとうございます。一月後くらいにkaggle本を参照しながらテーブルデータ系のコンペに挑戦してみようと思います。', '上位10%なら全然いけると思います、もう勉強始めて数ヶ月経ってるみたいなんで、早ければ3ヶ月くらいで狙えるところかなと！', 'やってみることはkaggle本でいいと思います〜', '今回初コンペなので何者でもないですが、このあたりのやり方は参考になりました。\\n<https://drumato.hatenablog.com/entry/2018/12/05/070000>\\n\\n<https://twitter.com/maxwell_110/status/994872828460720128>\\n\\nれごんさんのやつ\\n<https://qiita.com/regonn/items/c7d681c20b0a93d8c1c2>\\n\\nあとは書いているように、ひたすら人のコード読んで理解しつつ、色々試したり、誰かに（主にギルドで）質問したりを繰り返すことで力がついてきているなー、と思いました。\\n試行回数増やすのが一番大事そうです。', 'すごく丁寧にありがとうございます。ぜひ参考にさせてください。')\n",
      "('尾銭泰徳 ozeni.yasunori',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('API', '機械学習', 'ML', '統計')\n",
      "('統計学の時間ブックマークしました！\\nまたどなたかgcpのnatural language API使った事あるかたおられますか？\\n機械学習の勉強の一歩として動かしてみたのですが、想定した動きにならず、使い方が間違っているかも、と疑問になり、相談させていただきたいです。\\n\\n◆やりたかった事\\n名刺を画像をvision API でテキスト化→tatural language APIで構造化して\\n[会社名][氏名][住所][連絡先]をラベリング→データベース化\\n\\n◆できた事\\nテキスト化はvisionAPIが非常に優秀で名刺に記載の情報は全てテキスト化されて出てきた。\\n\\n◆できなかった事\\ntatural language APIにテキスト化されたデータを投げてみても上手く構造化されず、ほとんどが会社名とかではなく、その他データ扱いに。。\\n\\n補足としてもうちょっと詳細な内容はqiitaに載せています。\\n<https://qiita.com/ozeni/items/16b36f65e32c9e06832e>',)\n",
      "('この記事を見るとすんなり上手くいってるんですよね。。。\\n<https://qiita.com/Hironsan/items/166515acec35658986b2>', '投げるテキストに問題あるのか、APIの設定に問題あるのか切り分けるのに、\\n\\n&gt; キントーン株式会社\\n&gt; 東京本社第一営業部\\n&gt; 蔡瑁 図太郎\\n&gt; 23-4567\\n&gt; 東京都日本橋天竺町1-2-3\\n&gt; Tel: 00-1234-5678\\n&gt; E-mail: <mailto:saibo.zutaro@kintoon.co.jp|saibo.zutaro@kintoon.co.jp>\\n&gt; \\nここれをそのまま投げて同じ結果が返って来るか試してみたらいかがでしょう？', '会社名を「株式会社」の所で認識してるとしたら、「名刺良品」は認識難しそうな気がしますね。。。', '試してきました！確かに上手くいきました。。。（初歩的検証ですみません！）qiitaの記事にはできませんでしたが、自分の過去の名刺とか色々突っ込んでどれも上手くいかなかったので、データよりロジックが悪いと思い込んでしまってました。。。', '上手く行くサンプルで試してたりするので、そういう罠ありますねw', 'PERSONも、日本人名だと分類制度悪いとかあるかもですねー。。。', '「XX郎」とかも「郎」の所を学習してるんじゃないかなぁとw', '確かに。。データがダイレクトにテスト結果に影響与えるパターンを身を持って知りました。。。\\n唯一、住所はほとんどのデータでラベリングが上手くできたので、属性ごとに学習の成熟度合いが違いそうです。', 'sansanさんとか大手が人力でパンチしている現状からそのままサービス転用はまだまだかもですねー。\\nただvision APIの精度の高さは圧巻でした。', '住所は47都道府県から大体推定できそうですからねー！！', 'あと、話は若干変わりますが、こんな感じで、学習元データがアメリカナイズされてたりするものもありますw\\n\\n<https://qiita.com/tetsuroito/items/e0944dfefd806e51364a|https://qiita.com/tetsuroito/items/e0944dfefd806e51364a>', '自分が陥ったパターンとクリソツ！\\n強力な技術ゆえに間違った時の振ればはもすごい。。MLOps超大事！')\n",
      "('はやと-休学中の文系学生',)\n",
      "('Yuta Kita', 'sota_sakuma', '吉村政彦ｰ産業ｽﾊﾟｲ', 'asuki.u', 'Riita Satsuki', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('GPU', 'クラウド', 'AWS', 'BQ', 'GCP', 'Azure', '機械学習', '初心者')\n",
      "('deep learning用にGPUをGCP上で使う環境を作ろうかなって思ってて今のところこの記事を参考にしようと思ってるんですけど、この通りにやると1,462.99/月（ドル）ってなっててやばそうなんですけど、何か他にいい記事とかこれ使うといいよみたいなのってあったりしますか？（できればクラウドインフラだけで解決する方がありがたいです）\\n\\n<https://qiita.com/taka_baya/items/f7b3c37152d24bff3517>',)\n",
      "('Google Colaboratoryとかどうです？\\n<https://qiita.com/mafunity_/items/464d70915c1815e9a628>', '返信ありがとうございます！\\nGooglecolabは使いやすいかもですがあまり学習スピード早くならないんで、とりあえず今回はなしで考えてます:man-bowing:', 'クラウドのGPU付きのVMは、基本的に回す時だけ立ち上げて使い終わったら落とす感じで運用するしかなさそうです。', '<@UKT5BQD3P>\\n私がDLGに連れてきた<@UPF4T5DE1>さんに相談してみて下さい。\\nきっと良いアドバイスを貰えると思います(*^_^*)', '<@UN0HCK74M>\\n\\n私のは クラウドではないので、役に立たないかもですね:sweat_drops:\\n\\n上記2つの回答を支持しますー(˘ω˘)', '<@UPF4T5DE1> 費用が問題なのであれば、ローカルで構築というのも選択肢に上るかな？とも思った(^_^；\\n（現に私が今それを検討してるのでｗ）', 'GPU をKubernetesを使ってプロビジョニングしたプリエンプティブル VM なら常時稼働でもほとんどお金かからないです。\\nStackdriver Monitoring を使って、オペレーションログは確認できるので、クラスターが揮発すること自体はあんま問題ないです。\\n\\n分析環境のリソースをGPUにするのはymlに\\n`resource: gpu`\\nって書くだけなので一瞬です！\\n', '<@UKT3G90U8> <@UN0HCK74M> \\n<@UPF4T5DE1>返信ありがとうございます！毎回落としてればそんな費用かからないですよね（震え声）', '<@UNFAV5EDB> \\n聞いたことない単語がたくさんある（震え声）\\nそんなやり方あるんですね！ちなみにそれってどこかに記事とかでまとまってたりしますか？', 'プロビジョニングとか調べてもあまり出てこなくて', '<@UKT5BQD3P> \\nプリエンティブルVM \\n簡単に言うと程優先度でリソースを使用する分\\n料金が安くなるサービスとの認識でいいと思います。\\n最大で24hで自動的に落ちる&amp;空きが無くなったら勝手に落ちる可能性がある\\nあたりを許容できるかかと思います。\\n名前は違いますが、AWS、Azureにも似たようなサービスがあると思います。\\n', 'AWSでいうスポットインスタンスか', '<@UKT3G90U8>\\nなるほど、ありがとうございます！GCPで全部完結するんですね、優先つけてくれるのは他使わないんでありがたいです', '<https://tech.zeals.co.jp/entry/2019/01/08/094054#GPU%E3%81%AE%E5%89%B2%E3%82%8A%E5%BD%93%E3%81%A6>\\n結局プリエンティブルVM試してみたんですけどうまくいかなかったので、初心者でもとっつきやすそうなこっちを参考におとなしくdocker立ててやってみようかなと思います〜!\\n<https://qiita.com/lain21/items/a33a39d465cd08b662f1>', '<@UN0HCK74M> \\n\\n一応 弊社の社長に ゲーム用グラフィックボードを挿して使うGPU対応QNAP ですが、見積もり含めて確認したのですが、最近 弊社のQNAP 関連事業で 日本の法人のお客様が増えつつあり、個人で個別対応が難しくなってきてしまいました。\\n\\nもう少し 早くに出会えていれば、、といったところです。うちからだと サポートさせて頂くことになると思うので、個人様だとそのサポート費用分が割高になってしまうかと思います。\\nQNAPは初期設定だけハードルが高いので、サポートがないと使えないかと思います、、、\\n\\n機械学習において GPUでトライアンドエラーをたくさんしたい企業様 であれば、見積もり出せそうです。\\n\\n良い回答ができずすみません:sweat_drops:', '<@UPF4T5DE1>\\n気にして貰って感謝・感謝です(*^_^*)\\n\\n大丈夫です！バイタリティだけはあるので、自力で何とかします(-_☆)ｷﾗﾘ\\n環境構築もまた経験値なのです(*^_^*)')\n",
      "('sasaki',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa', 'ﾋﾛﾘｰ', 'Katsuya Nagano', 'yuji.imuta', 'すずきしげお')\n",
      "('マーケティング', 'データサイエンティスト', '統計', '転職', '設計', 'DX', '教科書', 'AR', 'kaggle', 'Python', 'Tableau', 'データアーキテクト', 'データクレンジング', 'デジタルマーケティング', '機械学習', '強化学習')\n",
      "('初めて質問させて頂きます。スレッド違いでしたら申し訳ございません。\\n漠然とした質問で申し訳ありませんが、データサイエンティストのキャリアについて、もう少し深掘りしてお聞きしたく質問させて頂いた次第です\\n\\n自分はキャリアとしてマーケターとデータサイエンティストの掛け合わせのような人材をイメージしており、商品の需要予測を行いながらマーケティング施策を決定したり、消費者のアンケート結果を分析することで新商品を開発したり、商品流通の最適化を行ったり、といったものを想像しています。\\n\\nその一方で、自分の状況としては、データサイエンスを学び始めたのが今年の8月からで、数学、統計学の基礎、GBDTなどのモデルを使ったkaggle経験（理論は全然理解していないです…）程度で実力は乏しく、その一方で就職のタイミングが近づいているという状況です。\\n\\nそこで、お聞きしたいのは、このような現状で、上記のようなキャリアイメージを描く場合、どのようなキャリアステップを踏むのが良いか、ということです。\\n\\n自身としては下記の3つのルートを考えています。\\n\\n①マーケターとして就職、働きながら同時にデータ分析スキルを学び、実践していく\\n→最終的にマーケターになるのであれば一番近道であり、現実的な道筋かと考えています。その一方で、懸念点として、どこまで独学で実務レベルのデータ分析スキルを学べるか、という不安があります。ただツールを使うだけでなく、理論まで理解していないと、高いレベルに行けないのでないかという漠然としたイメージがあります。\\n\\n自分は文系学部の3年で、線形代数、微分積分学については、理系大学1,2年生範囲までは把握しているものの、データサイエンスの世界で理系大学院生と戦う場合、自身の基礎力に不安があります。マーケターとして就職した場合、基礎力をしっかりと大学で学ばないままになってしまい、長期的にみて不利な選択なるのではないかとも考えています。\\n\\nそのため、①を選択するに当たって、\\n・そもそも大学院レベルの数学、統計学がないとデータサイエンティストとしては不十分か\\n・大学院レベルの数学、統計学が必要として、独学で、また働きながら学ぶことはどれくらい難しいか\\n\\nが疑問点であります。\\n\\n②大学院に進学し、統計を学んだのちに企業に就職する（or企業に就職したのち大学院に戻る）\\n→①の懸念点である大学院レベルの数学、統計学の習得を克服するものですが、\\n・家庭の事情によりあまり大学院に進学できそうにない\\n・マーケター×データサイエンティストにとって、データサイエンティストに要求される3つのスキルのうちビジネス力の比重が重いのではと考えると、アカデミックな世界に残る重要性が低いのではないか\\n\\nといった考えから、余程のことがない限りはこの選択はないかと考えていますが、データサイエンティストとしては、研究、技術開発の方向性を目指す場合は大学院進学は必須なのでしょうか。①と合わせて、大学院に進学することのメリットについて教えて頂ければ幸いでございます。\\n\\n③新卒で経験が浅くても入れそうなデータ分析系の会社に就職→データサイエンティスト枠で転職\\n→データ分析系企業で経験を積んだのち、事業会社にデータサイエンティスト枠で転職し、マーケティング施策を行っていく、というイメージです。①と②の間をいく形で、学びながら実務ができる道に進み、経験を積んだのちに転職するというものです。\\nこの場合、懸念点として、\\n・転職してデータサイエンティストになることの難しさが分からない\\n・上記に関連して、データサイエンティスト枠で事業化会社に転職するステップが分からない\\n\\n上記の2つがあります。この点についてももしどなたか教えていただけると有り難いです。\\n\\n以上、大変長くなってしまい申し訳ありません。皆様が書かれているアドベントカレンダーと被る部分もあるかと思いますが、お教え頂ければ有り難いです...',)\n",
      "('元マーケターポジションからデータサイエンティスト→データアーキテクト方面寄りのキャリアを歩んでいるのですが、おそらくCrossさせるキャリアは社会人歴5年目以降に力を発揮するのでまずは1つの軸を作るのが良いのかと思います。\\nデータサイエンティストキャリアについてはかなり学生のうちでは競合かつ、経験者優遇なところがあるのでまずは、インターンするのがいいかと思います。', '<@UL2TY2ERL> \\nエムスリーという最強の職場でインターンしてるそうですw', '<@URPSGF5SP> \\nありがとうございます！！\\n\\n明日中には回答できるようにしますね！！', '有難うございます！\\u3000お忙しい中恐縮です:man-bowing:', 'そりゃ、最強ですな。\\n何を悩んでいるのかわからないぞ。\\nしいて言えば、別のところに就職した時にいかに恵まれていたのかわかるぐらいだと思います。', 'エムスリーでインターンと言っても色々あり、自分のやってることは大したことがないので…想像されているレベルとは違うかと思います…', '師匠にあたる人は皆さんめっちゃ強いので、上手いこと吸収すると良さそう。', '③新卒で経験が浅くても入れそうなデータ分析系の会社に就職→データサイエンティスト枠で転職\\nこれを選ぶと苦しむので辞めたほうがいいことだけは行っておきます。\\nそれなりのデータに対する理解のある会社でないとまず、社内政治で苦しみます。且つ新卒で社内政治を乗り切るのはスキルとしては難しすぎる。\\nまぁ、今いるところがプロ野球選手ばっかりなので技術はあまり気にしないほうが無難です。\\n一度幅を広げてみるもありかと思います。', '確かに、周りが強すぎるので相対的に出来てない感を感じてる可能性はありそうですね。', '\\n初めまして。\\n極論、未来のことはわからないので自分で考える以上の事は無いのですが、まぁそれでは元も子もないので、私なりの見解をシェアしたいと思います。\\n\\nまず、ご相談の文章を読んだ所感ですが、\\n1.将来の職種、業務内容についてかなり具体的にイメージできている\\n2.自分なりに学習を行なっている\\n3.自身の置かれている状況を客観的に捉えようとしている\\n4.以上を踏まえて戦略的に考える事が出来ている。\\nことが読み取ることが出来ます。\\nこれは、感覚的には1%未満のかなり優秀な方でいらっしゃると言うのが第一印象です。\\nその上で、最初のご質問である、「データサイエンティストとして十分か」という問いですが、\\nまず、何を持って十分とするか、客観的に観測可能な方法で定義する必要がありますね。\\n(曲がりにもデータサイエンティストを目指しているわけなので)\\nそれが出来れば自ずとどのようにリサーチすればいいかも見えてくるでしょう。\\n\\nなお、これは補足ですが、海外で働きたいなら最低限mstrは取った方がいいですね。またアメリカではデータサイエンティストというとほぼPhDというのが現地の認知のようです。\\n\\n次に独学で知識を獲得できるか、と言うことですが、\\nノーベル物理学賞のファインマンの有名な逸話があります。\\n彼がMIT時代に雲形定規を手にとって「雲形定規は、どのように回転させようと、それぞれの曲線の最も低い点で、接線が水平になるようにつくられている」ことを「発見」した（もちろんこれはイタズラで、発見したかのように言っただけ）。それを聞いた周りのMITの学生が雲形定規を手にとって接線が水平であるという事実を確認した。みんなこの｢発見｣に大興奮だった。\\n「どんな曲線であっても、極小点（最低点）の導関数（接線）はゼロ（水平である）ということを知っているはずなんだよ。事実から関連を捉え類推することができないんだ。つまり、知っていることだって、実は知らないんだよ。」と言う話があります。\\n\\nつまり、MITの学生であっても数理の世界の話が現実空間と全く結びついてないと言うことなんですね。\\n\\nこれを自分でできるなら独学でもいいでしょう。ただし、自信がないなら適切な指導を受ける必要があるでしょうね。\\n基本的には、企業内で社内外のクライアントに説明する必要がある分析者は大抵この能力が求められるので、指導は受けられるかもしれません。もちろん大学にもそのような方は多くいらっしゃいます。\\n\\n最後にキャリアステップについてです。\\nまず、新米のデータ分析者はコンサルティング的に複数の案件をくるくる回すよりも、単一のドメインで、同一のデータで(つまり事業会社で)分析を行うことを、個人的にはお勧めします。(賛否あると思います)\\n理由は、データ分析はデータに対する仮説が重要ですが、それはその仕事の事がわからないと筋の良い仮説が立たないからです。\\nまた、分析した結果、意思決定の結果を最後まで当事者として見届ける事ができることも、キャリア初期の経験としては非常に重要だと私は考えています。\\n\\nなお、転職や就職については、市況が大きく変わらなければ難しくはありません。\\nどの会社もデータ分析者を求めています。\\nエージェントを使うもよし、リファーラルを使うもよしです。ただ人に話せる成果にこだわりましょう。それが入場券になります。\\n\\nまた、言及されていらっしゃいませんが、私が重要だと思っている論点について触れておくと、データ分析の能力を鍛えるのと同時に、組織人として、ビジネスマンとしての基礎体力は非常に重要です。\\nわかりやすい教科書は先日村上さんもご紹介されていた、田端氏著書の\\n新しい社会人の教科書です。\\nデータ分析は詰まる所人を動かしてナンボな訳ですが、マーケティングは特に予算が大きくなりがちなこともあり、社会人としての基本動作が出来ないと即詰みます。\\n\\n長々と書きましたが、基本的には自分が熱中できる事をとことん突き詰めつつ、学んだことを世に発信していれば、だいたい思い通りに行くと思いますよ。', 'だらっとになりますが、追加で書きますとデータドリブンなことをやりたい営業組織やマーケティング組織なんかも文系就職という視点は面白いかもしれませんね。\\nカスタマーサクセスチームのデータ支援をはじめましたが、データドリブンな意思決定に興味持っている会社も増えてきています。（実は意外とできている会社がない）', 'これになってると僕も思うなぁ\\nハングリー精神はいい事だけれどもね\\n&gt; 周りが強すぎるので相対的に出来てない感を感じてる', 'エムスリーでインターンしていてその働き方がしっくりくるのなら事業会社のデータチームに入るのがいいと思う\\nゲーム系は新卒の門戸が広いから来て欲しいなぁ〜', '&gt; 新卒で経験が浅くても入れそうなデータ分析系の会社に就職\\nこういう会社はデータサイエンスを謳いつつ、IBMワトソンだったりTableauなどのツールぽちぽち系オンリーでプログラム書かないことが多いので注意です。\\nエンジニアでいうところ、「文系未経験歓迎！」と書いているところは大体中小SIerというのと同じような理屈です。要は「未経験でも問題ない仕事」。\\nそれらツール自体は悪いものではないですが、文章拝見させてもらった感じだとそっち系は希望と違う氣がするので書き込ませてもらいました。\\n\\nそれと、質問の意図からは逸れますが、皆さん書いているように（別部署かもしれませんが）インターン先に強い人多いので今勉強していることを聞きに行くのが就職までのスキル強化で一番いいかと。学生は特権階級なので、普通は初見でもみなさん優しく教えてくれるので学生のうちにその特権は積極的に使っていきましょう。実務での使い方や注意点など聞けるはずなので。', '<@URPSGF5SP>\\nまず、マーケターの定義からですが、広義のマーケターと狭義のマーケターの話があるかなと思います。\\n\\n広義のマーケターとしては、市場調査、商品設計、流通方法、プライシング、プロモーション等をひっくるめてサービス設計するような役割ですね。\\n\\n狭義のマーケターとしてはWebマーケティング、Webプロモーションを主軸に置いたマーケターです。\\n\\n恐らく広義のマーケターの話をしていると思われるので、そちらに関してのお話をさせて頂きますね。\\n\\n個人的に、大きな選択肢としては、\\n\\n１．事業会社に所属して、マーケティング担当としてキャリアを積む\\n\\n２．自社で保有しているデータを基にマーケティングのサポートをするような会社に所属する\\n\\nという大きな2種類のパターンがあるのかなと思います。\\n\\n----------------------------------------\\n１．事業会社に所属して、マーケティング担当としてキャリアを積む\\n----------------------------------------\\n１に関しては、広義のマーケターが必要とされるような会社で、かつ色々と教えてくれる上司がいるとなると、大企業に所属することになると思うのですが、その場合にマーケティングの部署に所属できるかどうかがキーになって来そうです。\\n\\n希望を出して配属先に賭けるような方向性を目指すと運に賭ける所が大きくなってしまうので、入社の時点で「マーケティング職」というポジションで入れる会社がないかリサーチするのが重要かと思います。\\n\\nまた、所謂DXと言われるデータ活用の推進がどこまで具体的に現場に落ちているかもキーポイントかもしれません。\\n\\n大企業の中でも、データ活用が上手く行っている会社と上手く行っていない会社に明暗が分かれて来ているように思いますので、具体的にどんなデータ活用の施策が現場で行われているのかなどを面接で確認してみても良いかもしれませんね。\\n\\n----------------------------------------\\n２．自社で保有しているデータを基にマーケティングのサポートをするような会社に所属する\\n----------------------------------------\\n例えば、<@UPR6BE9S6> さんの所属しているTvision Insightなどは、テレビの視聴に関するデータを持っていたりして、その視聴データを基にクライアントに提案するようなことをします。（間違ってたら補足頂けると助かります。）\\n\\n他にも、アンケートリサーチであればマクロミルなどは大御所ですし、最近だとダイナミックプライシング系のスタートアップも多く出て来ているので、そこら辺の領域も結構ハマりそうかもですね。\\n\\nダイナミックプライシングをする上で需要予測のモデルは必須になって来るので、最低限、需要予測\\u3000×\\u3000プライシングという部分はカバーできるかと思います。\\n\\nそういった、「データ\\u3000×\\u3000マーケティング」の取り組みをしている会社のデータサイエンス部署に所属することを目指せば、目指している方向に行けつつ、リスクや運に頼ることも少ないのかなと思います。\\n\\n頂いていた中の②に関しては、自分が学部卒なのですが、大学院レベルの知識が欲しくなることはあります。やはり、何かしらの専門を持たれている方は強いですね。\\n\\n一方で、大学院を出ていたからと言って、現実問題に対して筋の良いモデルを適用できるかというと、別問題だったりします。\\n\\n数学的には正しくても、問題を適切に捉えられていないパターンなどは見られますので、大学院に進学すれば安心という訳でもないですね。\\n\\nデータサイエンスの仕事をする以上、半分くらいの方がMr.は取られているので、そこは覚悟した上で飛び出すのが良いかと思います。\\n\\n③に関しては、データサイエンス全般の知識が欲しいのであればありだとは思います。ただ、受託中心などとなると何の仕事にアサインされるか分からないので、マーケティング専業でやっているような会社があればそういった所を探すのが良いのではと思います。\\n\\nその場合、SESだと一人で現場に出ることも多くなってしまうと思うので、基本的には受託メインの会社を選ぶのが良いのかと思います。\\n\\nザっとお答えさせて頂きましたが、何かもっと聞きたい事などあれば、何でも聞いてください^_^', '<@URPSGF5SP> \\n根本的な所として、何故マーケターが良いと思ったのかは気になります。', 'マーケター以外の選択肢も探れたらと思ってます！', '<@UL2TY2ERL>\\n増田様\\n\\n丁寧にご回答くださり誠に有難うございます:man-bowing:\\n\\nマーケターポジションからデータ分析よりのキャリアを歩まれているのですね！\\u3000自分の目指す方向ととても近いと思われるので参考になります！\\n確かに、まずマーケターorデータサイエンティストのどちらかに軸を置いてから、そこで結果を出して、徐々に両方を掛け合わせるキャリアを目指した方が現実的ですかね\\n\\n一応エムスリーでインターンをしているのですが、あまり内部のことを話すわけにもいかないので曖昧に述べますが、エンジニア、データサイエンティストの方と殆ど関わりがない、将来的にも無さそうな部署なので、可能性は低いですが、データサイエンスの知識を生かせる部署に異動願いを出す、または辞めるという選択も考えているくらいな状況です。一緒に働いている方は間違いなく優秀なのですが、やりたい、学びたいこととは少しずれているので、増田様が仰られている通り、学生の特権を生かしてどこかしらで分析経験を積みたいと考えています。\\n\\n③に関しては、データに対する理解のある、受託分析の企業のイメージです！（言葉足らずで申し訳ございません）あまり名前を出すのはアレかもしれませんが、AL○○,ブレ○○,ヴァ○○などです（募集要項、説明会などからの情報によると、経験が浅くても一応応募はして良さそうな感じだったので、入れそう、という書き方にさせて頂きました）\\n上記の会社であれば、優秀なデータサイエンティストの方が多い印象を受けましたし、新卒研修制度も充実していると感じたので、先ほどの、マーケターorデータサイエンティスト、どちらに軸を絞るかで、データサイエンティストに軸を絞るなら、そもそも内定貰えるかどうか分かりませんが、良い選択肢なのかなと考えていました。こちらに絞りすぎて、マーケティング職に転職するのが難しいのかどうかによって、③の選択肢を取るかどうか変わってくるかなという印象でした。\\n新卒で社内政治を乗り切ってデータドリブンな組織づくりをしていくのは想像だけでも大変そうなので、その選択肢は取らないようにしようと思います。忠告いただき有難うございます！\\n\\n色々焦って進路について幅を狭めてしまっている感もあるので、もう少し視野を広げてみようと思います、こんな長文の質問に回答くださり、本当に有難うございました！', '<@URPSGF5SP> \\n頑張ってください！！\\n\\nAL○○は多分自分の古巣なので、聞きたいことあれば聞いてください！', '3は分析の専門会社すぎるぞ。\\n話している会社のレベル感が高すぎてどこ行っても問題ないような気がするw\\nマーケティングの会社=P&amp;G 想定ぐらいで怖いぞw', 'マーケティング学びたいという方向だと、③の中だと、選べるのであればヴァ○○が比較的良い気がしますねー！\\n\\nWebの行動ログ持ってる所ですよね？\\n\\nであれば、行動ログ抑えてればそれを元にマーケティングの提案につなげる事が多そうです。\\n\\n他2社は総合的に強い人沢山いるのですが、全方面から分析を取り扱うので、例えば製造業だったり、その他データ活用だったりでマーケティングから離れたポジションでアサインされる可能性は結構あるかなと思います。', 'サンプル数が少ないのでかなりバイアスはかかってますが、マーケティングの部署でも、データから仮説を立てないで、感性でやってるようなところに、データサイエンスの知見があると神のように扱われて、やりたいようにやれるようになれるパターンがあります。ただ、壁にぶち当たった時に頼れる人間が社内にいないっていうデメリットはありますが、、、', '<@UREUHGVAQ>\\nHiroyuki.Tachikawa 様\\n\\nこんな長文の質問に丁寧にお答えくださいまして誠に有難うございます。\\nデータサイエンティストの数学、統計学の知識として、何を持って十分とするか、という点は\\n正直定義するのが難しいなと感じています。というのも、1.将来の職種、業務内容についてかなり具体的にイメージできている、と仰って頂いたのですが、あくまで自分の想像の範囲で、データサイエンティストがマーケティングに関わるのなら、こんな業務をするんじゃないかなというものでしかなく、（主にPython実戦データ分析100本ノックの例にあるようなものです）やりたいことのイメージが固まっている一方で、データサイエンスの知識を身に着けることにより何ができるのか、というイメージがないため、「何を持って十分とするか」は、「どこまで知識があればこれくらいの仕事ができる、という肌感覚を持った上で、自分はここまでやりたいからここまで学ぶ」という順序で考えないと分からないかなと思っています...\\nそのため、ぜひこのギルドや、今のインターン先を生かして、上記の肌感覚を持つ、という部分を早急に身につけて目指すべき方向性を定めようと思います。\\n\\nやはり海外で働くなら大学院に行く必要がありそうですね... 今の所は強く希望しているわけではないですが、今後キャリアを積む中で視野に入れることになる場合、大学院に通い直すなどしてみます。\\n\\n独学で知識を獲得できるか、という点につきまして、そのようなエピソードがあることは知りませんでした！MITの学生でも数理の話が現実空間に結びついていないという話はとても興味深いです。そもそも数理の世界の話をあまり理解していない自分にとっては、結び付けられるかどうか以前の問題な気もするので、より大学院に行った方が良い気もしてきました...今大学院に行けないのですが社会人から大学院に通い直す方向も考えてみます。\\n\\n\\nキャリアステップに関して、事業会社で分析を行った方が良い理由大変納得いたしました。\\nまだ経験が浅いですが、分析におけるドメイン知識の重要性を感じます...\\n\\nビジネスマンとしての基礎体力の重要性はあまり意識していませんでした。早速本は買ったので読んでみようと思います\\n\\n改めてご回答いただき有難うございます。お話をお聞きすると、まずはデータサイエンティストの業務理解を深め、その上で自分がどこまでやりたいか見定め、自分のやりたいことと一致する事業会社の就職を目指し、その上でデータ分析の専門性を深めていく、というのが良いかなと感じました。大変参考になりました有難うございます！', '<@ULKPET3UK>\\nヒロリー様\\nご回答いただき有難うございます！\\nデータ分析スキルは相対的にでなく、間違いなく絶対的に低いのでこのコミュニティ生かして頑張っていきたいです\\u3000多分自分はtoCの方が好きなので、事業会社のデータチームで入れるところがあれば入りたいと考えていますね…\\xa0自分はリアル脱出ゲームの制作をサークルやらインターンでしていたこともあって、ゲーム会社は結構視野に入れています！\\u3000もし宜しければお話お聞かせください:man-bowing:', '<@UPR6BE9S6>\\nKatsuya Nagano様\\nご回答いただき有難うございます！\\n\\n未経験歓迎にはそれなりに理由がありますよね… 自分としては、もっと複雑な仕事をするか、完全にビジネス寄りで働くか、を希望しているので、甘い言葉に誘惑されないようにします笑\\n\\nインターン先に強い方々が同じフロアには存在するはずなので、学生の特権を生かして色々聞きに行こうと思います。せっかくの機会なので生かそうと思います', '<@UJRAL005U>\\n村上様\\n\\n入会してすぐ長文の質問を送りつけてしまい申し訳ございません:sweat_drops:\\n丁寧にご回答くださり有難うございます:man-bowing:\\n\\nまず、何故マーケターが良いのか、という点ですが、やはり森岡毅さんの本を読んで、マーケターの仕事が魅力的だなと感じたことが大きいです。個人的には、誰にどんな価値を届けるのか、ということを考える仕事をしたいので、商品開発から、そのプロモーションまで一貫して携われるマーケターという職に純粋に憧れがあります。\\nその上で、何故マーケターとしてではなく、データサイエンティストも視野に入れているかというと、そもそもマーケターになることを意識する以前からデータサイエンスに興味があったこと、データサイエンスとマーケティングの相乗効果が大きいことがあります。\\n\\nデータサイエンスに興味があったのは、自分がリアル脱出ゲームを制作して人に届ける、ということをしていて、どうやったら人は喜ぶのか、体験として良いものと感じるのか、など人の心理を考えるようになり、それを読み解く武器として、感情を定量的に分析する手段としてのデータサイエンスに興味を持ちました。\\n\\n1.事業会社に所属してマーケティング担当としてキャリアを積む\\nある程度新卒研修制度が充実しているところとなると、やはり大企業のマーケティング部署がいいかなと考えています。入社時点でマーケポジで入れるところを探そうと思っています（もしどこが良い、などあれば教えて頂ければ幸いです:man-bowing: 言われてしまっていますが、今の所P＆G、USJなどは視野に入れています）\\n\\n2.自社で保有しているデータを基にマーケティングのサポートをするような会社に所属する\\n\\nTvision Insight話題になっているので存じ上げております！\\u3000自社で保有するデータがある方が、一貫して関われるので良いですね。視線推定技術なども活用するのでしょうか\\n\\n大学院レベルの数学、統計学について、改めてお聞きしたのですが、大学院レベルの知識、というのは、数学、統計学についてでしょうか？\\u3000それとも他分野の専門的知識でしょうか？\\n数学、統計学である場合、大学院で学ぶことは独学だと無理なものなのでしょうか…？\\n研究としての仮説検証の作法などは、確かに大学院で専門的に学んだ方が良いかと思いますが、単純に内容だけであれば、独学、または企業に就職したのち、院を出られた先輩方に適宜聞きながら習得できるかと楽観的に考えていたのですが、大学院で学ぶことそれ自体の意味について教えていただけないでしょうか…？\\n\\nその一方で大学院で学べばデータサイエンスをうまく活用できるではない、ということ承知いたしました。とはいっても多くの方が修士までは行かれているので、学部就職は大変だな…と\\n感じております。\\n\\n受託分析会社ですと、村上様はAL○○におられたのですね！\\u3000マーケティングに関わりたい、という思いがあるのですが、その一方で、売上予測だけでなく、画像データを用いた分析や、強化学習も優先度は相対的に低いですが学びたい気持ちもあるため、ぜひ中のお話お聞かせいただければと存じます:man-bowing:\\n\\nこの度はお教えいただきまして誠に有難うございます:man-bowing:', '<@UMG0947NY>\\nyuji imuta様\\nご回答いただきまして誠に有難うございます:man-bowing:\\n\\nインターンをしていても、マーケティング部署でもデータサイエンスの知識がある人ばかりか、というとそうでもない印象を自分も持っているので、データサイエンス力をつけてマーケティング部署に入って活躍したいな、とも考えています。確かに頼れる人が社内にいないと、そこで詰まってしまいそうですが...', '<@URPSGF5SP>\\n&gt; 大学院レベルの数学、統計学について、改めてお聞きしたのですが、大学院レベルの知識、というのは、数学、統計学についてでしょうか？\\u3000それとも他分野の専門的知識でしょうか？\\nこれは３つありますね。\\n\\n１．数学、統計知識\\n２．専門領域に関する知識\\n３．研究、リサーチに関する方法論\\n\\n１．に関しては良い教材もあるので、独学で大丈夫かなーと思います。\\n\\n２．に関しては、西内さんのTweetが良かったのでシェアしますね！\\n\\n<https://twitter.com/philomyu/status/1210097423214792704?s=20>\\n\\n「知識として知っている」から「やってみて壁にぶち当たる」というステップに移って効率的に学ぶには、その専門分野の先を行く、研究室の先輩や教授にサポートしてもらうのが良いかと思います。\\n\\n３．に関しても、研究論文のお作法だった李、進め方は指導教員の下でやった方が圧倒的に効率的なため、大学院の方が時間効率が良いような気がします。\\n\\nA社みたいなアカデミックな会社に入れれば、３．の所はしっかりと教えて貰えたりしますし、特定領域に強みを持っている会社であれば２．はカバーできるのかなとは思いますね。', 'A社に関しては自分の居たころのメンバーが社長含めほぼ誰もいない感じですが、社内での勉強会を開催していたり、新卒を取って育てていたりと、教育に関する力は結構入れている印象がありますね。\\n\\n各領域の専門性の高い方が結構多くいるイメージです。\\n\\nA社自体が100人～200人程度抱える大企業になってしまっているというのと、業務が多岐に渡るので、「データ分析全般の知識を付ける」というのが目標なら良いのかと思いますー！', 'あと、最近はSESもやっているようで（今もやってるかは不明）、状況によってはSESで常駐になる可能性はありますね。\\n\\nただ、SES的な感じになったとしても、きちんと帰社日を設けてフィードバックしたり、定期的に現場を変えるなど、SESで入れっぱなしにはならないようには色々工夫しているような印象は見られますね。\\n\\n（断片的な情報なので、結構状況変わっている可能性はあります。）', '村上様\\nご回答いただき有難うございます！\\n\\n1については独学でも可能とのこととても心強いです！このギルドも生かして身につけていこうと思います:man-bowing:\\n\\n2については、専門分野の先を行く方のサポートですね。データサイエンティストについてはこのコミュニティで学びつつ、マーケティングについてはマーケターポジションで入れる会社などに属して上司に教わるのが良さそうでしょうか…？\\u3000新卒で募集しているところに応募してみます\\n\\n3.やはりこの点については大学院の研究室に属することに強みがありますね… A社であれば\\nこの点もカバーできそうとのこと有難うございます:man-bowing:\\n\\nまたA社に関する様々な情報を教えてくださり誠に有難うございます。大変参考になります…!\\n\\nみなさま真摯にお答えいただき本当に有難うございました…! 就活で悩んでいたのですがここで相談できて本当に良かったです..!有難うございました:man-bowing:\\n\\nみなさまの意見を聞くところ、基本的に最善なのは、海外で働くことや研究の流儀を学ぶ上でもまず大学院進学→事業会社のデータ分析部署という流れが一番良いかと感じました。\\n\\n自分の場合はすぐに大学院が難しそうなので、自分が何をやりたいのか今一度考えた上で、\\nマーケター×データサイエンティストの掛け合わせの人材になりたいなら、\\n事業会社のデータ分析部署or事業会社のマーケティング担当でキャリアを積むor自社で保有しているデータを基にマーケティングサポートを行う会社に行き、\\nデータ分析全般に関わりたいのなら、ここにA社などデータ分析全般を扱う会社への就職をチャレンジする、という方針で行きたいと思います。\\n\\nそのために必要となる数学、統計学はこのギルドも生かしながら学んでいき、社会人基礎力やドメイン知識については働きながら身につけていこうと思います。\\n\\nだいぶ進路についての道筋が見えました。重ねてになりますが皆さん貴重なお時間を使って回答くださり誠に有難うございました。今後とも宜しくお願い致します。', '弊社(TVISION)、TV業界以外でも知名度あったことに驚きです。よければ、どういう文脈？で聞いたか教えていただけると助かりますw\\n\\nP&amp;Gは存じ上げてるようにマーケティング強いことで有名なので、OBも有名です。なので、P&amp;G出身の人がどこにいってるかとか調べてみるとそこも候補に入りそうですね。コカコーラも確か強かった気がしますし、P&amp;G出身の人多かった気がします。\\n\\n「P&amp;Gマフィア」でググるとP&amp;Gのマーケター情報色々出てくるのでおすすめです。', 'いつのまにかスレッドがめっちゃ盛り上がっている！\\n<@URPSGF5SP> 大学院いいと思いますよ。\\nいずれの選択肢でも sasaki さんは非常に優秀なので、どんな生き方でもきっと自分の希望は叶えられるはず！これからが本当に楽しみです。勝手ながらめっちゃ期待してますw\\n頑張ってください！', '<@UPR6BE9S6>\\n確かTwitterで拝見した覚えがあります…！\\nP＆G出身の方の企業も良いですね、調べてみます有難うございます…！', '<@UREUHGVAQ>\\n皆さんお答えいただいて本当に有り難いです…\\nそんなに期待されるほど優秀でないですが…\\u3000ここまで皆さんにアドバイスいただいたのでしっかり生かして頑張ります:man-bowing:', '森岡さんの本を読んでマーケティング × データサイエンスのキャリアを目指しているのであれば、同じ方向性を目指している<@UPBV44H6H> さんの意見もお伺いしたい所ですね！\\n\\nお時間ある時で大丈夫ですので、マーケティング×データサイエンスのキャリアを目指す上で、どんな選択肢がありそうかご意見頂けると嬉しいです！（お忙しい中話振ってすみません）', '私の観測範囲での事例を投げておきます。\\n私は理工系で機械学習の研究をしていて、新卒でマーケティングリサーチをやっている調査会社に入りました。なので私自身は最初からデータサイエンティストとして扱われました。(ちょうどDSという言葉が流行り出した頃でした)\\nただ、その会社のほとんどの人は、調査の企画設計という仕事に従事していて、統計に必ずしも詳しくはありません。全く統計を知らない人も実は多いです。イン〇〇ジ社やマ〇〇ミル社も全員が全員、統計に詳しい人ではないです。\\nそんな会社でも自分の先輩後輩で、調査企画設計の仕事を経て、白い通信会社や国内最大手歯磨き粉の会社で、デジタルマーケティング分析やデータ分析の仕事に転職しました。\\n学生時代から統計を自主的に勉強しているだけでも十分な強みになるかと思いますし、入社すれば何人かは専門家がいます。大抵そのタイプの人は教えを請えば喜んで教えてくれると思います。', '<@URRKHGARX>\\nすずきしげお様\\n\\n有難うございます！調査会社でも、クライアントとの質問項目のすり合わせやアンケート画面作成、データクレンジングや納品の際のパワポ資料作成etc…統計の知識を必要としない重要な業務が色々あるから、という感じなのでしょうか\\nどこの会社でも、ある程度DXが進んでいれば専門家の方はいらっしゃって、その方たちの元で積極的に働けば結果としてやりたいことが出来るのは確かにそうかもしれません、あまり視野を狭めすぎずもう少し気楽に就活進めます。有難うございます:man-bowing:')\n",
      "('すずきしげお',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'ﾋﾛﾘｰ', '尾銭泰徳 ozeni.yasunori', 'dbrow', 'Vo-chan', 'Hiroyuki.Tachikawa')\n",
      "('SaaS', 'ダッシュボード', 'BI', '設計')\n",
      "('社内におけるデータ分析教育を企画しなければなりません。講師は私です。コンテンツや進め方などについてのアイディアやアドバイスをください！「自分ならこうやる」など。\\n・いわゆる日本的大企業。消費財メーカー。体育会系ゴリゴリ営業マンが7割、品質追求命の工場の人が3割と言った会社です。\\n・手挙げ式でやる気のある人を全国支店・工場から募集\\n・集合研修、ウェブなど形式は未定\\n・データドリヴンな意思決定を少しでも普及させたいのが目的。',)\n",
      "('全社的にデータ分析を展開するとしたら、自主的にやって貰うという所が最優先かと思いますので、\\n\\n・まずは営業マンか工場の人か、ターゲットを絞る\\n\\n・ターゲットのモチベーション、ニーズを調査（残業減らしたい、成果を出したいなど）\\n\\n・モチベーションと一致して、効果が出やすい分析を選ぶ（営業なら、営業先の属性ごとに優先順位つけるとか、提案商品変えるとか）\\n\\n・まずはどこかチームや部署でテスト的にやって、成果出るように徹底的にサポート\\n\\n・全社展開\\n\\nみたいな感じでしょうか？\\u3000ボトムアップのアプローチの場合、「データ活用した方が得」という状況を作ることと、それを社内で普及させることの二つが重要になって来るのかなと思います！', 'いわゆる、「データサイエンス講座」みたいなのはやらないかなーと思いますね！', 'ありがとうございます。確かにいきなり全員でやろうとしてました。まずは営業ですかね。年末年始に企画の全体像とコンテンツのプロトタイプを作るのでまた相談乗ってください。', 'トップダウンだと結構強引にやってもなんとかなると思うのですが、現場主導で動かすとなると、コンテンツよりインセンティブ設計がポイントになるイメージありますね！\\n\\n是非、プロトタイプできたらまた教えてください！！', '営業にデータを活かすのは結構ウケがいいですね。\\n特にデータを横断で見れるように整備してあげるのがいいです', '営業にデータを活かすのは生産と違って、効果が見えづらいという悩みはあります。生産なら例えば異常検知→生産性改善！みたいな流れがわかりやすいですが、営業だと何がどれだけデータ活用の貢献か切り分けられないというのがいつも考えどころです。結局人間関係が決め手じゃないの？みたいな。', '資料作成やクライアント向けのリッチな情報をまとめる作業の効率化で削減時間が見えやすいかなと。\\n営業マンの内勤時間が多いことが課題に思う組織であれば効果ありますよ', 'それは課題としてあります。今はSaaS(Salesforce的な)の導入、BPR/RPA、ダッシュボードの整備などで解決を図っています。データ分析研修で営業効率化だとどんな切り口になるでしょうか。', 'SaaSの導入が決まっているのであればその使い方をメインにハンズオン的な研修をするのがいいのかなと思います！\\n私はシステムの導入支援など業務で行ったりしたことがあるのですが、営業さんは思っているよりシステムに入力してくれない。。\\n実際に今までの営業データを移行してダッシュボードから課題や見込み顧客を見つけるハンズオンとかいいかもしれません！', 'SaaS導入のハードルは現場にいかに使って貰うかですよねーw', '失礼いたします。社内でデータ分析案件の創出を目的とした社内ワークショップ企画に携わっているのですが、以下のような点は大事だと感じています。\\n１.以下３点をイメージアップし、関係者間で共有\\n-（そもそもの）開催の目的\\n-参加者のAs-Is, To-Be（研修が終わったときにどうなっていて欲しいか）\\n-参加者に研修後、どんなアクションをとって欲しいか\\n2.ターゲット（参加者層）を決める\\n→誰に来てもらうかによって研修内容/発信すべきメッセージが変わってくる。\\n職種、職位（部長クラス/現場マネージャ/担当者）、所属部署によっても変わってくる。\\n⇨1,2が決まれば内容の方向性が決まる。\\n3. アクションを起こした人と業務上の連携、少なくともお悩み相談を受けられる人（可能であれば組織）の存在をアナウンスする\\n→勇気を持ってアクションした人をひとりぼっちにせず、ゴールまで並走支援', 'ありがとうございます。\\n3はslackで社内オンラインコミュニティを作ってフォローしたいなと考えてました。\\nasis-tobeは詰めなきゃですね。データ分析を専門としない人は普通の人はどのくらいになれればいいんだろう', 'データ見ながら改善案をディスカッションできるようになれば大成功な気はしますねー！', '自分も他社企業内の分析支援（主にBI活用ですが）やってて割と響いた点で技術支援以外の部分共有しますね。\\n1.課題に対するゴールデンサークルやツール利用時の5W1Hを明確にする。\\nこれはAsis-tobeと同じような感じですが、もっと具体的な例や実際の社内で抱えてる問題例をコンテンツとして提示してからだと学ぶ人達も身に入りやすいです。\\nゴールデンサークルの参考リンクはこれです。\\n<https://www.kikakulabo.com/topic-gc/|https://www.kikakulabo.com/topic-gc/>\\n意外とニーズを聞いても大雑把にしか把握してなかったりするのでうまくガイドするか考え方を身に着けさせる方向に力を注いだ方が、分析のコアの部分で楽しいし現場の人もテンションあがってくれます。\\n\\n2.少数精鋭で育成してから分散して配置\\n手を上げてくれた人を全国から集める形なので大丈夫だと思いますが、集めるのであれば先の人が述べたようにターゲットを絞る必要はあると思います。\\nできるだけ決定権がある程度ある人か、現場に近い人を集めてサポートしたあとにその人達が身の回りの人をサポートする体制にするとジワジワ浸透していきます。\\n\\n3.既存のやり方で突き通したいおじさん達の説得法を考える。\\n大企業であればあるほど、現場の人が多ければ多いほど必ずぶち当たる問題です。\\n村上さんが言うように「得な状況を作る」はかなり有効です。\\nその上で2で述べたように現場のリーダーなど決定権を持ってる人だとやりやすいです。\\nいない場合は「推進リーダー」みたいに肩書をつけてあげてしまうのも手かと。', 'お、なんか面白そうな話題。社内研修ってある種のアートですよね。\\n以前営業会社の戦略の一環でいろんな営業トレーニングの企画と全国へ赴いて講師もやっていました。新しい考え方を浸透させたいときは、受けてもらいたい人たちとその上司に直接会って（最悪でも電話で）自分が受けてもらいたいと考えているコンテンツを受けたいか、受けたくないならどうしたら受けたいかを聞くのが王道ですね。\\nまた「データドリヴンな意思決定を少しでも普及させたいのが目的」ならば、研修によって成果が上がった社員を作ることでしか果たす事はできないはずなので、研修の内容よりもその後の結果に徹底的にこだわることが重要です。\\nここでもし研修受講者に結果を出させる自信がなければ、研修はやめるべきです。現場の時間を泥棒するだけなので。別の切り口で企画を考えた方がいいですね。\\n私が経験してわかったことは、伝え方や浸透させ方は小手先でしかありません。「うまいやり方なんてないな」って事です。現場にとって全社にとって本当に価値のある事なのか、徹底的に考え抜いて徹底的にこだわる他ないと思います。', '余談ですが、今並行してここでやっている講座で色々検討して、LMSとして以下のツール使うことにしました！\\n\\n<https://www.instructure.com/canvas/|https://www.instructure.com/canvas/>', 'フリーでも十分使えてデータ化できるので、LMSとかはあるとベターかもですね！', 'たしかにこういう仕組みがあるといいですね！', '特に、社内研修とかだとどこまでやったか把握できないという課題感がるみたいで、進捗管理は結構どのツールでも共通でついていましたね。')\n",
      "('ｸﾛ\\u3000京大医学部3年',)\n",
      "('こ ろ ん', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'すずきしげお')\n",
      "('統計', '統計検定', '機械学習')\n",
      "('統計検定準一級の必要性に関して質問です！\\n最近二級の勉強を始めたのですが、思ったより難易度が低そうなので、準一級に挑戦してもいいかな、と考えています。\\nしかし、それほど統計が好きなわけでもないので、2級レベルで十分通用するならば、準一級に突っ込まず、勉強時間を他にあてたいと考えています。\\nみなさんの考えを聞ければ幸いです！',)\n",
      "('<https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test|https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test>\\n\\nこういう検定系は僕的によく使うなあと思いますが実際会社で統計検定のどのセクションを使っているかは僕も気になります。', '試験要領を詳細に見れていないので印象での回答になるのですが、\\n\\n・データサイエンス\\n・ビジネス\\n・エンジニアリング\\n\\nのどこに軸足を置くのかで変わってくるかと思います。\\n\\nモデリングなどのデータサイエンスに主軸を置くなら必須になって来ると思いますが、他の二つに主軸があるなら2級レベルでも事足りることは多い印象ですね。\\n\\nとはいえ、基礎力がないとなかなか応用効かないので、優先度は比較的高い気はします。\\n\\n一旦2級レベルまで取って、その後他2領域をカバーしてから判断するくらいでもいいのかなーと。', 'ありがとうございます！\\n全体像が把握し切れていなかったです。\\n他の分野もカバーしに行きたいですね', 'わたしも準1、1級の試験勉強中です。とりあえず2級はCBTで好きな時に受けれるのでサクッととってしまえば良いかと思います。\\n準1は機械学習も含めた広範囲な分析手法の試験です。そういったことに興味がある場合は受けても良いかと思います')\n",
      "('こ ろ ん',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "('クラウド', 'DataRobot', 'AWS', 'AR', 'AutoML', 'GCP', 'jupyter', 'データサイエンティスト', 'データマイニング', 'レコメンド', '回帰分析', 'ML', '強化学習', '時系列')\n",
      "('現役データサイエンティストの方に質問ですが実務で使っているアルゴリズム？などを教えて欲しいです。\\n\\nというとはたとえば強化学習を広告に使っているのようにブロードな回答でもいいですし、商品のレコメンデーションをk平均方でしているなどの少し詳細なものもかなり勉強になるのでお願いします。',)\n",
      "('主にやったことがある分析などだと、\\n\\n■ データマイニング\\n解釈性が重要なので、\\n\\n・重回帰分析\\n・決定木分析\\n・k-means\\n・主成分分析\\n・共分散構造分析\\n\\nみたいな所を結構使うかもですね。\\n\\n\\n■ レコメンド\\n難しいロジックが効果を出すか微妙な所があるので、\\n\\n1.ただのフィルター\\n2.アソシエーションルール（lift値計算）\\n3.協調フィルタリング\\n\\nみたいな順でやることが多いですかね。3.までやることは結構稀かと。\\n\\n\\n■ 時系列分析\\n需要予測などです。これも簡単なものからやるので、\\n\\n1.ARIMA\\n2.RNN or 状態空間モデル\\n\\n\\n■ モデリング、予測\\nとりあえずxgboost使ってモデル作るか、AutoML的なので複数モデル作って選択する感じですかね。\\n\\nザッと実務で使ったことがあるモデルを挙げてみました！！', '基本方針としては、極力簡単なものから徐々に難しくして行くってアプローチを取ることが多いですね！\\n\\n現場の理解も、自分の理解もその方が追い付きやすいので！', 'めちゃくちゃ参考になりました！ありがとうございます！追加で質問させてください。\\n\\njupyterがメインフィールドですか？\\ndatarobotなどは使いますか？\\ntableauなどのソフトは使いますが？\\n\\n先ほどの回答のようにキーワードいただけるとめちゃくちゃ参考になります', '全部使いますが、メインのサービスや言語はその辺りです。\\n\\n受託メインなので、基本的にはクライアントの状況に合わせて使うツールとかは使い分けます。\\n\\nDataRobotとtableauは商用なのでクライアント依存な所はありますが、tableauは自前でライセンス購入してます。\\n\\nDataRobotとかは高すぎてなかなか使う機会ないですw', 'なるほど、分析環境はdockerで構築するくらいの認識でいいですか？k8sはまだよくわかってないんですよね\\n\\n最終的にはやはりクライアントの状況に合わせてですよね、難しい、、', 'dockerはつい数か月前に初めて使ったレベルなので、エンジニアとかがいれば、案外環境作ってくれたりしますね。\\n\\nあとは、GCP（ノートブック）、AWS（Sage Maker）共にクラウドサービス内にボタン一つで立ち上がるnotebook環境があるので、それを使うのが吉じゃないかなぁと思います。', 'クラウドってそんなに便利なんですか！！衝撃です。ありがとうございます', '最初少し試すだけならクーポンあって無料なので、試してみると良いっすよ！', '自分でかいたnoteですが、ずっと下の方に実際に業務でやったことも書いてあるので参考になれば。\\n<https://note.com/hr_tachikawa/n/n470de597b750#bH7Z8>')\n",
      "('はやと-休学中の文系学生',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'tomo.h', 'Satoshi ｻﾄｼ')\n",
      "('自然言語処理', '書籍', 'Python', '入門', 'BQ', 'レコメンド', '機械学習', '形態素解析', '時系列')\n",
      "('日本語の自然言語処理の技術全体とPythonでのその実装について一冊でいい感じにまとまっているオススメの本を知っている方いませんか？',)\n",
      "('たしか、動画作っているめちゃくちゃ詳しい人がいるはずだから、教えて上げてほしい。', '<@UL2TY2ERL>\\n名前が出てこないって感じですか？？', '<@ULM6FBU11> さん、\\nおやすみ終わりましたか？', 'あ、そっか、そうだった。\\n\\n自然言語の先生ですねw', 'ありがとうございます！自然言語の動画作ってる人がこのギルドにはいるんですね、、、！', '<@UKT5BQD3P>\\nなかなか一冊でまとまっている情報がないのが実情です。\\nしっていたらわたしも教えて欲しいくらいです。\\nQiitaだとわたしの記事も含みますが\\n<https://qiita.com/3000manJPY/items/a0652d488ce3c956613d>\\n<https://qiita.com/tomone_hata/items/67e7f9415dbf5c8ff8ba>\\nUdemyだと\\n<https://www.udemy.com/course/learning-ai/>\\nですかねえ。自然言語処理でも分類をやりたいのか文書生成したいのかなどいくつか答えが違うと思います(ちょっと今日いっぱい取り込み中のため雑な回答ですみません)。\\n\\n書籍だとこのあたりの自然言語処理の箇所を統合すればいい感じになると思います(わたしの講座もこの辺をがんばって統合してみようかなと思ってます)\\n<https://www.amazon.co.jp/dp/4339027510/ref=cm_sw_r_tw_dp_U_x_bsBeEb40Q1>\\n<https://www.amazon.co.jp/dp/4873118360/ref=cm_sw_r_tw_dp_U_x_vtBeEbF0PYJ8A>', '<@ULM6FBU11> \\nありがとうございます！！\\n\\nやっぱり、まとまってる書籍ってなかなか無いんですね・・・', 'これ書籍化しないかな～。\\n<http://www.cl.ecei.tohoku.ac.jp/nlp100/>', '<@UL2TY2ERL>\\nそれを新しい手法とかも含めて売り込むと本気で売れると思いますよー。裏話になりますが、そこまで網羅した内容を講座で作れないです。。実際にはここにいらっしゃる人以外の方のレベル感も考慮しないといけないので。。', '確かに、ここにいる人をターゲットに想定するとレベル高くなりすぎそうですね・・・', 'なるほどですね。\\n機械学習もそろそろ奥深くなってきているのでそろそろ分野決めないと、言語、画像、音声、時系列予測、レコメンド、数値分析（ちょっと違うか）みたいにデータ界隈でも別れて来るのかな～と。', '<@UL2TY2ERL>\\n自分はグラフDBとネットワーク科学辺りにベットしたいと考えてますー！', 'できることの割に注目されてないので、狙い目な気がしてます。', '<@ULM6FBU11> \\nいろいろリンク載せてくださってありがとうございます！講座やってるの強いですね、、、どちらかと言えば分類ですけど文章生成も少し見てみたいかもなみたいな温度感です。', 'とりあえず記事読んでみようと思います〜', 'ちょっと古いですがこの辺が勉強になりました。\\n\\n<https://www.amazon.co.jp/入門-自然言語処理-Steven-Bird/dp/4873114705/ref=sr_1_1?__mk_ja_JP=カタカナ&amp;keywords=入門+自然言語処理&amp;qid=1578282816&amp;sr=8-1>\\n\\nこれは英語版で無償で公開されてもいます。\\n\\n<http://www.datascienceassn.org/sites/default/files/Natural%20Language%20Processing%20with%20Python.pdf>', '<@US85V53MK> さん\\nその本私も気にはなっていたのですが、英語というのが引っかかって中身見ずに排除しちゃったのですよね。。\\n形態素解析とかその辺の話がちゃんと書かれているのかなぁと。。買ってみようかしら。。', '<@US85V53MK> \\nサトシさんありがとうございます〜\\n今回探してるのは日本語ですが、纏まったのが見つからなかったらそれやってみようかなって思います。')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'masso', 'shimizu', 'sota_sakuma', 'kenichi.suzuki', 'たか', 'asuki.u', '熊田\\u3000翔  ﾃﾞｰﾀ分析で差別化したい生産技術者')\n",
      "('IoT', '転職', 'AI', 'クラウド', '機械学習', 'ポートフォリオ', 'AWS', 'kaggle', '画像解析', '設計', 'BI', 'Tableau', 'ビッグデータ', '前処理', '統計', 'API', 'Linux', 'OpenCV', 'SQL', 'DX', '統計検定')\n",
      "('<!here>\\n\\n\\n\\nサトシ<https://data-learning-guild.slack.com/archives/CJP6483K2/p1578200350124200>\\nです。\\n\\n*エンジニアのキャリアに関するご質問です。長文失礼します*:man-bowing::skin-tone-2:\\n\\n*IoTに関わりたいとの希望です。*\\n私は10年ほどWEB業界に在籍していたのですが、IoTに興味がわき（IoTというと範囲が広いのでここで私の興味が湧いたIoT分野は`現実世界から情報を取得する仕組みを作って役に立つ形に変えるための装置や情報の分析、現実世界で物を動かす`ことだと定義させて下さい）、\\n\\n例えばスマカギやスマートマルシェや、またomronやtanitaの体重計、Fitbit、工場センサ、Tileなどの現実の製品とサービスが一体化した製品がとても魅力的で、そのような製品に技術的な面で関わりを持てるような仕事を将来的に持ちたいと常々考えていました。\\n\\n３年ほど悩みましたが、2019年にデータ分析サービスを提供している客先常駐型の企業に転職させていただきました。\\n\\n*しかし現実は理想と乖離していたといいますか、私の見通しが甘すぎました。*\\n当初転職先企業様からは「あるコンビニチェーンの画像センサーから取得した情報を元にデータ分析を行う。最初そこにSQLの抽出業務から参画し、2ヶ月目にはOpenCVを学んでもらって解析開発業務に入ってもらう。2年程度は確実に続く案件だ」と言われていたのですが、その案件は３ヶ月ほどでたち消えとなってしまい、よくある案件ガチャのハズレを引いてしまった形となってしまいました笑:sweat_smile:\\n\\nその失敗から私のキャリア戦略と、企業の選択が間違えていたと思い再度考え直している段階です。:thinking_face:\\n\\n現状indeedなどでIoTと検索しても件数は多くありません（あっても組み込みSIer）\\n\\nそもそもIoTはネットワークエンジニア、データベースエンジニア、画像音声データ分析者（その中でも更に前処理８割、モデリング２割）、組み込みエンジニア、サービス設計者が複合的に絡み合って生まれていると思われるものなのでIoTに関わる。というよりはそのどれかを選ぶべきなのかもしれません…具体的なキャリアパスの正解はないのかなと思います。:sweat_drops:\\n\\n*そこで現状キャリアプランと考えているのが下記のとおりなのですが、時間のある時でもちろん結構ですのでご意見をいただきたく思います。*\\n\\n1. 少ないとは思うがIoTに関われそうな案件があれば迷わずトライする\\n2. 将来的にIoTと親和性が高そうな技術を習得できそうな案件に自分の中で優先順位をつけ参画や独学をする。（画像分析、音声解析、データ分析）\\n3. IoTに関われそうな案件の面接対策のために、ラズパイに実装させた画像解析、センサーから取得したデータの自動分析、IoTデバイスの作成をする。また機械学習（画像・音声）系のkaggleのシルバーを取得する。\\n\\n*上記にプラスして*\\n1. IoTに直接は関われずともIoTに必須であるデータ基盤設計の勉強をしておく。\\n2. IoTに関わりのある人脈を構築する。\\n3. 業界と職種の検索を引き続き行う。\\n\\nここにおられる先輩エンジニアの方々にご教授いただけますと、大変助かります。どうぞよろしくお願いいたします。:man-bowing::skin-tone-2:\\n\\n-------------------------------------------------------------\\n_その他私に関する参考情報（不要かもしれませんが笑）_\\n経歴:10年ほどWEB業界に携わり、１年ほど初歩的なデータ分析,Tableau,AWSのIAM権限まわり業務を経験\\n\\n年齢:35\\n住居:東京\\n\\n保有資格\\n• 統計検定2級\\n• TOEIC720\\n• Java SE8 silver\\n• ウェブデザイナー上級\\n• MOS検定上級',)\n",
      "('<@UPF4T5DE1> <@UMQ7CDJUR> <@UKT3G90U8> <@UQL12TR3M> <@URG8BPJ07> <@URTRU1W48>\\n生産管理、IoT、ヘルスケア領域の方を主に業務としてやられてらっしゃる方にメンションさせて頂きました。\\n\\n現場に近い方や、近いシチュエーションでキャリアを検討している方の意見が参考になると思いますので、上記の方向性に関して、実際に働かれている方々の観点としてアドバイスや所感などをご共有頂けたりしないでしょうか？', '参考程度になればと思うのですが、「IoTに関連する技術のうちの多くを学べる可能性が高い業界」として地図＋自動運転業界を一つ提案します。\\n\\n現在、私自身６年程地図業界に身を置いているのですが、デジタル地図を作成するために必要な計測車両（いわゆるGoogleカーのイメージ）の研究・開発職はそういった技術が集まってできるものです。\\n\\n具体的には、GPS・カメラ・レーザスキャナといった代表的なセンシングデバイスで取得したデータの\\n\\n・読み込み処理\\n・ノイズ除去処理\\n・DBへの保存（データベース設計含む）\\n・地図整備の前処理として点群データや画像データの処理（機械学習も含む）\\n\\nなどが主な技術的な構成要素です。', '付け加えますと、（要素技術の面から言えば）計測車両をつくる≒自動運転車両をつくると考えて差し支えないと思います。', 'ITエンジニアとしてはペーペーですが、以前製造業界にいてIoTに取り組んでいた身なので僭越ながらひとつ意見を…。\\n「IoTに軸を置いたキャリアにしたい」という感じでしょうか？\\nキャリアプランのひとつに、「IoTを武器にしているメーカーに転職」というのはいかがでしょうか？\\n\\n&gt; `現実世界から情報を取得する仕組みを作って役に立つ形に変えるための装置や情報の分析、現実世界で物を動かす`\\nこの部分については`製造業界`がマッチしていると思いました。\\n\\n前職では医療機器メーカーで生産に携わっていたのですが、そのときのテーマとして以下のものがありました。\\n\\n①現場の生産設備の故障タイミングを予測して設備のダウンタイムを削減する\\n②画像解析（機械学習）を使って不純物（髪の毛など）が入った製品を不良判定するシステムを導入し、工数削減する\\n\\nこの2つのテーマは製造業界では結構共通の課題みたいなので、案件としては製造業界の中では多いかもしれません。\\n\\nちなみにですが、そのときに以下の企業さんにお世話になり、どこもIoTに力を入れてました。その企業さんのホームページを見たら何かヒントになるかもしれないので、参考までに…。\\n- オムロン\\n- キーエンス\\n- 三菱電機', '<@US85V53MK> \\n先輩では無いんですが。。製造業向けに、AI、データ分析案件のプリセールス、エンジニアやってます。\\nlotの担当では無いですが、B to Bのメーカーさんに一緒に提案したりする事が有ります。\\n\\n個人的に、検索ワードとしてiotよりも製造業向けのAI、データ分析の方がイメージに近い結果が出ると思います。\\niotで探すとおそらく組み込み系 or iot ツールの案件が多くなってしまうと思います。\\nIot の機器に近い部分(itとotの連携、GW、SDK開発等のデータを送る仕組みなど)をやりたいならば良いかと思いますが、元々web、BIに携っているのでIt側(集まって来たデータをどう活かすか)だと上記のワードで探すのが良いかと思います。\\n\\n案件ガチャについてですが、製造業向けのAI、Iotの分野はPoCからはじめて、実際のシステムに組み込んでいくまでのハードルが高い為、良くある事ぐらいに思うのが良いかと思います。\\n\\n', '上がっている様な商品はオムロンだったり、三菱だったりが製品のメーカーではあるんですが、iotの部分は裏でベンダーが担当しているケースがほとんどだと思います。。\\n希望している様な業務をやっている会社としてはSi系のAI、iot系のチーム or AIベンチャーが多いと思います。\\nただ後者は、web系(基本的にitで完結する業種)が顧客に多い傾向に有ります。', '<@US85V53MK>\\n鈴木健一と申します <https://data-learning-guild.slack.com/archives/CJP6483K2/p1576918004028500>\\n\\n人に意見できるほどIoTに関わるキャリアがあるわけではありませんが、いまの私の体験を書いておきますと、\\n\\n私も長いことWebをやっていましたが、いまはいったんWebから離れてインフラエンジニアとして製造業のお客様向けのデータ分析基盤構築の案件をやっております。Tableauを触ることもあります。製造現場でのIoTでのデータ収集の構築もあります。実際にやるかどうかは別として上がってくるIoT関連のネタとしては、製品の製造過程のセンサー情報、機器のGPS情報、現場の環境情報、従業員のヘルスケア情報などがあります。\\n\\nいまのところ、データを分析するよりも、インフラとしてデータ分析基盤を構築するのが主です。データ分析の方面もやりたいのですが、私もこの先どうしたらいいのかわかっていないです（このコミュニティに参加した理由のひとつです）。\\n\\nとはいえ、いまの案件は将来につながりうるいい案件だと思っております（製造業なのでデータ分析の仕事はあるかも）。この案件をいまやっているのは、自分のやりたいことを強くアピールしていたわけではなく、私の貧弱な人脈からの偶然です。サトシさんの「上記にプラスして」で書かれている通り、人脈は大事だと感じます。\\n\\n保有資格を書かれていますが、私もここ数か月は毎月なにかを取るようにしています。直近では、AWSのビッグデータ、機械学習の2つを取得しました。いまの所属会社は資格取得を強く奨励していて、実務でどの程度役に立つかは別として話のネタにはなり、自分はなにができるのかしたいのかを説明しやすいので、資格取得の勉強は私は重視しています。\\n\\nそれから、勉強したことはQiita等にアウトプットするようにしています。自分のレベル感や、なにを普段やっているのかを示せるので、そこからなにか仕事につながることもひょっとしたらあるかもしれません。', '私は製造業の生産技術にいますが、製造業がIoTに関わるタネが多いとは私も思います。\\nメーカの見極めは必要と思いますが。\\n(企業によってはソフトエンジニアの方があまりいないので、配属ガチャだと人材の取り合いになりそう(^_^;))\\n\\n私が工場の歩留りや稼働率改善のためIoT導入検討時には課題に対し\\n・センサーの原理\\n・どのようなデータになりそうか\\n・そこから何が導けそうか\\nを想像しきってから自信満々に検討していきます。\\n外ればかりですが、自信が無いとすぐ諦めてしまうので。\\nそのあたりの知識や具体的な製品情報と、何事もIoTを使うとどうなるかという大喜利的な訓練は遊びレベルででもやってた方がいいのかなと思います。ラズパイ買うときに秋葉原でIoTコーナ見るのも楽しいと思います。\\n見当違いな意見でしたらごめんなさいー。', '<@US85V53MK>\\n\\n製造業向け IoT関連の仕事をしています。\\n上畑 安須輝です。\\n<https://data-learning-guild.slack.com/archives/CJP6483K2/p1571230132054400?thread_ts=1571230132.054400>\\n\\n他の方が概ね回答しているので、私からは製造業向けIoT関連に特化して申し上げます、参考になれば、、、という感じですが、\\n\\n1,2年前は、製造業以外の案件で、とあるIoTデバイスの応用ビジネス、技術検討をやっていたのですが、仕事で使えそうだったのですが、実際に業務・納品に至ることはなく、、\\n\\n昨年中盤あたりから、製造業向けIoTでお仕事をいただき、検討・実装・納品しています。\\n\\n業界的な市場規模はこちらが参考になるかも。\\n<https://www.google.co.jp/amp/s/iot.aperza.com/2018/10/2195/amp/>\\n\\n現在の サトシさん の仰る \"工場センサ\" に近いかもしれませんが、\\nPLC(プログラマブルロジックコントローラ)関連のIoT化に関わっています。\\nおまけ程度で Raspberry Pi --- BlueToothで使える高精度温湿度計 も使って、構築したDBにデータを蓄積したりしています。\\n\\n最近では、年末 11月 12月 に 納品しました。\\n年末の実装が評価され、複製したシステムも 1月中納品予定です。\\n現在 製造業向け データロガーや、 上記 shimizu さんの例にもありました \"三菱\" さんのFA機器制御用液晶デバイスのマニュアルを読みながら、\\nお客さんからPLCを借りつつ、各機器の連携、動作を確認しながら仕事をしています。\\n\\n製造業さんは、IoT化したい気持ちは強いのですが、\\n日本のPLC周りでガラパゴス化した技術を扱う力を持ちながらIoT化に必要な技術をもっている会社が少ないため、製造業/FA業界のIoT化に苦戦しているように見受けられます。\\n\\n\\n\\n発注側が PLC周りの技術に長けているわけでもなく(PLCを扱う技術よりも、PLCを利用して製造する製品そのものに特化)、\\nかといって IoT をやります といっている会社も、クラウドからの思想、IoT デバイスからの思想で挑んだ時に、\\n躓くのが、実際の工場で多く設置されているPLC周りの 装置の扱い(クラウドにデータをあげる手段を見出しことが難しい)\\nや、PLCを使わないにしても、PLC並みの耐障害性が IoT デバイスに求められることなどから、\\n詳細仕様検討を進めていった時に製造業さんの\"実際に\"やりたいことが、どの会社もやれない\\n\\nというようなことが起きていると思われます。\\n（クラウドにデータをあげたいのに、実際は あげる口がありそうで使えなかったり、使いづらい）\\n\\n事実、弊社もそのままではできず、たまたま、弟の会社の助けになる技術を弊社が持っていたことから、\\nお互い協力しながら、実装を進めることができたという実情があります。\\n\\nつまり *\" データの取得 \"\\u3000と一言でいっても、現実 製造業の現場で使っているものから \" データを取得 \" するところですでに躓いているので データ分析 のところまではいたっていない* と考えられます。\\n(取得・分析したいデータの多くがなかなか取得できない)\\n\\nそこの導線を構築する仕事だけでさえ結構やることがあります。\\n\\n\\nとかく、製造業で多く使われるPLCやPLCで扱われるデータ(アップロードして分析したいデータ)をインターネットのレベルまで引きあげるために\\n壁がいくつもあるので、実際にPLCのデータをクラウドにアップできる導線を製造業の方にとって現実的なコストで作れる会社はなかなかないと思います。\\n(たくさんお金を積めばPLCメーカーがやってくれるかもしれません)\\nPLCは、メーカーごとに独自のプロトコルをメインで実装しており(文化的に)、\\nなおかつ、同じメーカー内でもPLCの型番によってできることが結構変わってきて、\\nたぶんPLCメーカー(大手)的にはカスタム案件扱いになってしまい、めんどくさがられそうです。\\n\\nそのため 上記で sota_sakuma さんがおっしゃるように、案件ガチャ云々のお話は同感なところがあります。\\n\\n逆に実際にIoTのシステムで納品まで行われている例となると、製造業でのIoT化の例よりは、\\nほとんど web系 クラウド系側の視点でシステム実装が完結できてしまうような例でないと、\\n納品できないものが多いだろうという感触です。\\n\\n今のIoTの仕事で必要なスキルは、たまたま、自分のこれまで転部・転職してきたキャリアのほぼ全てを使ってできているので、使命感があってそれなりに趣深く楽しいです。\\n・PLCを使った装置制御関連の基礎的な技術\\n・Linuxなどインフラ技術を使った応用力\\n・IoT関連デバイスの選定から含めた制御検討(ラズパイ/Arduino/obniz等々)\\n・PLCのリモート管理やVPNを安全に扱うネットワーク・セキュリティ技術\\n・劣悪な環境（例えば塩害対策、湿度が80%を超えるようなところなど）の対策検討\\n\\n\\nネットワークやセキュリティは、私個人ではそこまで専門ではないので、\\n会社から勘所を押さえて教わりつつ、インフラ環境を設定、検証したり、\\nREST API でIoTデバイス --- クラウド と連携しやすくさせたりなど、\\n業務で必要とされる技術の範囲はいままで関わってきた仕事で一番広いと感じています。\\n\\nまとめますと、、\\n\\n工場周辺 とくに FA関連・PLC関連で \" データを取得したい \" という要望に応える仕事で壁になってくるのは、\\nPLC周辺の扱いがおそらく一番大きく、それと、IoTデバイスを扱うためなどの電源確保周り、\\nその他、劣悪な環境(湿度・塩害・電気的ノイズだらけ)など超えるべき課題や 各デバイスの動作条件などがあります\\n(ふだん意識してなかった\"常識\"が通じないケースがそこそこある)。\\n-&gt; ラズパイ の機能が使えそうなのに、通常のラズパイの耐障害性では通じないケースなど。。\\n\\nIoT関連でSatoshiさんと情報交換できるところもあるかもしれません。\\nもし弊社の仕事のうち、IoT関連で興味ありそうでしたら、今度お話してみますか？\\nそこで場合によっては、仕事量は多くはお任せできないと思いますが、バイトというかワンショットといいますか、\\n弊社の仕事の一部を業務委託できるかもしれません。\\nIoT関連業務のうち、モニタリングなどWeb周りの実装からでよければといった感じです。', '<@UJRAL005U>\\n\\n各方面の方々へ情報展開ありがとうございました。\\n本当に助かります。:man-bowing:', '<@URDDX224S>\\n\\n貴重な情報のご提供ありがとうございます。\\n<https://jidounten-lab.com/y_6349>\\n親しいものであればこのような技術ということですね。\\nそれを支える基盤技術ももちろん必要不可欠ということですね。\\n\\nやはり私は産業に志向が強くありそうです。\\n\\nありがとうございました:man-bowing:', '<@UR7A5CJNA>\\n\\n&gt; 「IoTに軸を置いたキャリアにしたい」という感じでしょうか？\\nキャリアプランのひとつに、「IoTを武器にしているメーカーに転職」というのはいかがでしょうか？\\n\\nおっしゃるように`製造業`に志向性が強いのでその業界に転職しようと考えております。\\n\\n&gt; ①現場の生産設備の故障タイミングを予測して設備のダウンタイムを削減する\\n&gt; ②画像解析（機械学習）を使って不純物（髪の毛など）が入った製品を不良判定するシステムを導入し、工数削減する\\n&gt; この2つのテーマは製造業界では結構共通の課題みたいなので、案件としては製造業界の中では多いかもしれません。\\n①センサでログを取得し指数分布で予測する発展型のようなものかなと予想しています。そのセンサの精度の上げ方が工夫が必要なのかなとも。\\n②ありがとうございます。ラズパイを使って装置を自作し不適合品を学習させるポートフォリオを作成します。\\n\\n製造業界で共通課題のような物が私の興味のあるもので本当に良かったです。貴重な情報提供ありがとうございます。:smile:', '<@UKT3G90U8>\\n\\n&gt; 個人的に、検索ワードとしてiotよりも製造業向けのAI、データ分析の方がイメージに近い結果が出ると思います。\\n&gt; iotで探すとおそらく組み込み系 or iot ツールの案件が多くなってしまうと思います。\\n&gt; Iot の機器に近い部分(itとotの連携、GW、SDK開発等のデータを送る仕組みなど)をやりたいならば良いかと思いますが、元々web、BIに携っているのでIt側(集まって来たデータをどう活かすか)だと上記のワードで探すのが良いかと思います。\\nこれは慧眼です。ありがとうございます。そのようにいたします！:smiley:\\n\\n\\n&gt; 上がっている様な商品はオムロンだったり、三菱だったりが製品のメーカーではあるんですが、iotの部分は裏でベンダーが担当しているケースがほとんどだと思います。。\\n確かにメーカーはトヨタ方式よろしく昔からそのようではあるようです。\\nその製品を出しているから、という安直な思考はしないように気をつけます:slightly_smiling_face:\\n\\n&gt; 希望している様な業務をやっている会社としてはSi系のAI、iot系のチーム or AIベンチャーが多いと思います。ただ後者は、web系(基本的にitで完結する業種)が顧客に多い傾向に有ります。\\nわたしの現在所属している会社もPoCですが、そのようなことをしています。ただ、わたしが携わっていた案件としては立ち消えてしまいました。\\nやはりこれはわたしの問題ですが、客先常駐型はかなりの能力がないとこちらが仕事を選べるという立場は取れないということを学びました。（それでも、案件自体が0であれば不可能ですが）:sweat_smile:', '<@URTRU1W48>\\n&gt; 実際にやるかどうかは別として上がってくるIoT関連のネタとしては、製品の製造過程のセンサー情報、機器のGPS情報、現場の環境情報、従業員のヘルスケア情報などがあります。 \\n製造業で取集アクぁれる各種データ種類の貴重な情報をありがとうございます。ポートフォリオ作成の指標とさせていただきます。:man-bowing:\\n\\n\\n&gt; いまのところ、データを分析するよりも、インフラとしてデータ分析基盤を構築するのが主です。データ分析の方面もやりたいのですが、私もこの先どうしたらいいのかわかっていないです（このコミュニティに参加した理由のひとつです）\\nとはいえ、いまの案件は将来につながりうるいい案件だと思っております（製造業なのでデータ分析の仕事はあるかも）。\\n\\n基盤は絶対に必要なのでこれは完全に私も同意見でございます。更に後述の通りきちんと勉強を形にしているのは素晴らしいことだと思います。私も見習います。:man-bowing:\\n\\n&gt; 直近では、AWSのビッグデータ、機械学習の2つを取得しました。\\n&gt; それから、勉強したことはQiita等にアウトプットするようにしています。自分のレベル感や、なにを普段やっているのかを示せるので、そこからなにか仕事につながることもひょっとしたらあるかもしれません。', '<@UQL12TR3M>\\n\\n&gt; 私は製造業の生産技術にいますが、製造業がIoTに関わるタネが多いとは私も思います。\\n&gt; メーカの見極めは必要と思いますが。\\n&gt; (企業によってはソフトエンジニアの方があまりいないので、配属ガチャだと人材の取り合いになりそう(^_^;))\\n承知いたしました。配属できる力をつけるとともに、その点にも気をつけます。ありがとうございます。:man-bowing:\\n\\n\\n&gt; 私が工場の歩留りや稼働率改善のためIoT導入検討時には課題に対し\\n&gt; ・センサーの原理\\n&gt; ・どのようなデータになりそうか\\n&gt; ・そこから何が導けそうか\\n&gt; そのあたりの知識や具体的な製品情報と、何事もIoTを使うとどうなるかという大喜利的な訓練は遊びレベルででもやってた方がいいのかなと思います。\\nいえ全く見当違いではございません。実際の現場で使われそうな技術とアイデアを得るために勉強をするので、またポートフォリオ作成にもとても役立ちます。ありがとうございました。:blush:', '<@UPF4T5DE1>\\n\\nかなり多岐に渡るご経歴を持つ方からのアドバイスで恐れ多いです:man-bowing:\\n\\n\\n工場からのデータ分析業務（分析以前の取得）の現状の問題を詳細に記載していただき誠にありがとうございました。\\n\\nPLCが各社独自規格に加えてネットワーク接続しにくい（個別開発が必須）、そもそも環境が劣悪な状態での運用が想定されているため汎用IoT機器を設置してもノイズの混入、耐久性の問題があり、それをクリアしなければデータ取得自体ができない。（これも個別対応が必須）\\n\\nつまり分析以前のデータ取得時点のハードウェアの問題で加えて言えばかけるべき費用も限られているのでIoT化が進まない状態ということを理解しました。\\n\\n（ただ、現実を知らないからかもしれませんがトライアンドエラーの連続の職人芸的な\\n技術が必要とされそうで面白そうだなぁ！というのが個人的な意見です。）\\n\\nそのような理由から現状では予め顧客がデータ取得が可能のものに対してWEBで完結するサービス（ログ視聴・監視サービスのようなもの？）のほうが納品しやすいという理解でよろしいでしょうか？\\n\\nまた仕事紹介のご提案もしていただき誠にありがとうございまいした。:man-bowing:\\n\\nぜひお話をお聞かせ願いたいと存じ上げております。', '\\n仰る通りです。簡潔にまとめていただきありがとうございます:blush:\\n\\n&gt; （ただ、現実を知らないからかもしれませんがトライアンドエラーの連続の職人芸的な\\n技術が必要とされそうで面白そうだなぁ！というのが個人的な意見です。）\\n\\nこれも仰る通りです(笑)\\n\\n納品先のお客さんと協力して開発できる状態であれば、そのトライアンドエラーの連続が許され、\\n個人的には そのなかなか通信が繋がらない状態(仕様的にはできるかも状態)から、繋がった瞬間が最高に楽しいです！\\n\\n水が出てきた！井戸掘ったどーみたいな:thinking_face:\\n\\n恐縮です、拝承しました。\\n詳細個別で(˘ω˘)\\n何か役立てるものがあれば幸いです:relaxed:\\n', '完全に出遅れました:sweat:\\n私も去年客先常駐型の企業に転職しました。\\n案件ガチャの話はデータラーニングギルドでも、会社でも聞くので難しい問題ですね。。\\n例えば、IoT +データ分析コンペなどで実績を積んで（kaggleに類するような。あるかどうか把握できてないです）、メーカーへの転職を狙うというのはどうでしょうか？私は転職活動中にメーカーのデータ分析部門の面接を受けましたが、感触として生産技術のドメイン知識&lt;ITや数理統計の知識\\u3000を求められている感じがしました。なので、目に見える形で実績を提示するのが最も近道かと思います。本名でやっているので、大それたこと書けないのですが、私もメーカーへの転職をキャリアの候補として考えています。オフ会などでお会いした際にお話ししたいです^_^', '<@UMQ7CDJUR>\\n\\n返答送れて大変申し訳ございません。\\nおっしゃるとおり、SESは案件ガチャが多い印象でしっかりとやりたいことが決まっている場合はデメリットしか無いという印象です。\\nkaggle+IoTはたぶん今のところ無いと思います。もともと用意されたデータを分析するコンペなので、、、\\nポートフォリオが重要なのかなーっと自分では考えており、来週から試作を開始しようとしています。\\n一緒に頑張りましょう！！\\nありがとうございました！')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shunnosuke',)\n",
      "('masso', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '勝又健太 kenta.katsumata')\n",
      "('機械学習', 'ML', '初心者', 'Python')\n",
      "('将来機械学習を用いたアプリケーションを開発してみたいと思っており、今年からアプリ開発の勉強を開始する予定です。\\n自分はアプリ初心者なのですが、良い学習教材やどのように学習を進めれば良いなど意見があれば教えていただきたいです。\\nよろしくお願いします。',)\n",
      "('何か為になる返答をしたいのですが、質問の対象範囲が大きすぎる気がします。ターゲットを絞っていただけると、ほかの方々も返事がしやすいのではないでしょうか。\\n\\n初心者でいらっしゃるということで、「アプリ」が差す意味の広さが分かりにくい部分はあるかと思いますので、参考までに例をあげます。\\n\\nアプリ開発としては、大きく3つに分類されるかと思います。\\n①webアプリ(ブラウザ、モバイル)\\n②ネイティブアプリ\\n③組み込みアプリ\\n\\nそして、これは推測ですが、ご興味を持っていらっしゃるのは①のwebアプリではないでしょうか？理由は、日頃目にするアプリのほとんどがこちらに分類されるからです。\\n\\n次に、\\nwebアプリにも様々な種類があります。その分類をここに記載すると長くなるので控えますが笑\\n\\n例えば、世の中に出回っているアプリの中で「こんなもの作りたい」と思ったものはないでしょうか？\\nもしあれば、それを記載していただくとより質問に答えやすくなるかと思います。(学習すべき技術が少し明確になるから)\\n\\nここに記載したことは、本サロン以外の質問できる場所の、全てで共通して意識しておいた方が良いことかと思います。\\n\\n長々とすいません、参考になれば幸いです。\\n\\n', '確かに範囲が広かったですね、\\n作成しようとしていたのはカレンダーに毎日体調を書き込んむようなスマホアプリです。\\n（ユーザーデータから機械学習させ、ユーザー一人一人に適応させたライフスタイルのアドバイスをさせたいと考えてもいます）\\n\\n対象はiphoneを考えています。\\n（自分がIphoneを使用しているので挙動確認がしやすい？）\\nなので最初に勉強する内容は、Swift、Xcode、UIkitでしょうか？', '<@UQZ15RMMM>\\nなるほど、ヘルスケア系は今後ますます伸びると思うので、いいですねー！\\n\\nモバイルの開発は専門ではないので、質の高いアドバイスは出来なさそうです、すいません:sweat_drops:\\n<@UJRAL005U> さん\\n詳しい方いらっしゃいますかね？\\n', 'ネイティブ系の人はあんまりいないんですよねー・・・\\n\\nAndroidならkotlin、iPhoneならswiftって感じかと！\\n\\n\\n勝又さん（<@UJRDMQSAD>）の雑食系エンジニアサロンさんとかにはいっぱいいるので、そこで聞いた方が確実かもです！！\\n\\n\\n<https://kentakatsumata.net/archives/10|https://kentakatsumata.net/archives/10>', 'そうですね、勝又さんのサロンおすすめです。\\n僕も入ってます。', 'ありがとうございます！\\nチェックして見ます。', '月額980円なので、とりあえず入って聞いてみると良いかも！', '<@UJRAL005U>\\n\\nご紹介恐れ入ります！ｗ\\n\\n<@UQZ15RMMM>\\n\\n一応iOSでもCoreMLとCreateMLというライブラリを使えば機械学習アプリケーションは作れるようですが、まだまだかなり情報も少ないと思うので、機械学習の勉強も兼ねてということであれば、まずはPythonで簡単なWebサービスを作ってみる方が良いのかな〜という気はしますね:blush:\\n\\n<https://trinitas.tech/2019/04/22/apple%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%83%AF%E3%83%BC%E3%82%AFcore-ml%E3%81%A8create-ml%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/>', '<@UJRDMQSAD>\\nご丁寧に回答までありがとうございます！！\\n\\nやっとご紹介できる質問が来たので、紹介させて頂きました〜♪')\n",
      "('chan',)\n",
      "('こ ろ ん', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "('時系列', 'kaggle', 'AR')\n",
      "(\"あけましておめでとうございます:bow:\\n\\n時系列データの回帰問題におけるハイパーパラメータのグリッドサーチについて質問です。\\n今はXGBoostのRegressorを使っていますが、モデルに依らず一般論としてグリッドサーチの考えに関することになると思います。\\n文章のみの説明が難しいので、具体例を交えて説明させてください。\\n\\n{'A': [0, 1], 'B': [0, 1]}の合計4組のパラメータをサーチするとします。\\n1組目で\\n•学習データをTime series split（例えで5splitとします）\\n•各FoldのTrain dataで学習→Valid dataでEarly stopping→Test dataで評価\\n•5回分の評価の平均をパラメータ１組目の性能とする\\n\\nパラメータ2組目、3組目...と最後まで上記過程をループし、最も評価がよかったものをベストパラメータとする。\\n上記のテストデータで評価というものは学習データとは全く別の未来のデータです。\\n（Time series split したデータの直近の未来のデータ群）\\nという方法で理解しているのですが、この認識は正しいですか？\\n\\nもし正しいとすると、これを実装するにおいて\\nいまはsklearnのParameterGridというクラスを使い、パラメータをループして自作しています。\\nGridsearchCVがあるのにうまく使えばできるのではないかと考えているのですが、\\nそもそも見当違いのやり方なんじゃないかと思ったりもしています…\\n定石のようなものがあったりするのでしょうか？？\\n\\n長々と下手な説明ですみませんが、よろしくお願いします。\",)\n",
      "('あってると思います。グリッドサーチの場合はいまの例の4ペアのかわりに格子状に作られた多数のペアで上記の計算だされるだけです。', 'ありがとうございます！このまま検証していきたいと思います:bow:', '<@US2HKDVSL>\\n返答遅れました！\\n\\n特に問題ないかなーと思います！対象が時系列の場合は「バックテスト」という形でデータを作ってあがる必要があります。\\n\\n以下説明のバックテストの部分が分かりやすいかと思います。\\n\\n<https://blog.datarobot.com/jp/2017/08/31/mahine-learning-vs-linear-modelling-in-time-series-analysis>\\n\\n以下の記事にあるバックテストの場合、起点が揃ってしまっているので、訓練データの期間を揃えてあげる必要は、もしかしたらあるかもしれませんね。\\n\\n<https://upura.hatenablog.com/entry/2018/12/04/224436>\\n\\nモデリングの方の話に若干それてしまいましたが、グリッドサーチに関してはその考え方で問題ないと思いますー！', 'ご回答ありがとうございます！\\n見当違いのやりかたで無駄な作業ではなさそうなのでよかったです！', '<@US2HKDVSL> 解決していたらすみませんなのですが、XGBoostって時系列構造は検出できなかったような。\\n時系列データとは、各行が未来の時点を説明しうる状態を指しています。例えば株価なんかがそうですね。その場合、交差検証は上述の方法が適切ですが、XGBoostでは時系列構造を検出することはできず、多変量の場合はRNNなどが一般的に思います。逆に各行が独立している仮定をおける（特徴量にt-n時点の情報を持ったせた）場合は、XGBoostで問題ないですが、その場合行ごとの依存関係がないので、普通の交差検証で問題ないですね。', 'こんばんは。コメントありがとうございます！\\nkaggleのnotebookで時系列回帰にxgboostを使っているものを参考にしていました。\\n下記URLはその一例です。（探せば他にもありそうです。）\\n<https://www.kaggle.com/robikscube/tutorial-time-series-forecasting-with-xgboost>\\n\\nすみません、`時系列構造の検出`がちょっとわからないのですが\\n予測ができないということですか？精度が出ないということでしょうか？\\n\\nいま私が扱っているデータは、商品の需要予測のような形式なので独立ではないと思います。', '時系列構造を検出することを目的としたxgbってどういう意味ですか？', '<@UREUHGVAQ> さんのおっしゃるような形で、直近12カ月の売上を、当月のXX、1ヶ月前のXX、2ヶ月前のXXといった形で、相対的な特徴量にして予測することはありますね。RNNで精度が出るかと言われるとそういう訳でもなかったりするので、予測精度を上げる上では、相対的な特徴量を作って予測するというテクニックはよく使う印象です！\\n\\n直近12カ月のデータを使って翌月の離脱、再購入や売上を予測するようなシーンですね。\\n\\n一方で、直近1年くらいの推移を予測するとかなると、ARIMA、RNN、状態空間モデル（Stanとか使ってモデリングする）などが向いているのかなーと思いますので、ケースバイケースで、時系列にxgboostが使えないというようなことは無いかなーと思います！', '<@UJRAL005U> フォローありがとうございます(土下座:man-bowing:)\\n<@US2HKDVSL> すみません(汗)だいぶ説明がざっくりしてました。\\nもし今回のタスクには精度が必要で、かつ既に必要な精度が出ていれば問題ありませんので、以下読み飛ばしてもらって大丈夫です。\\n----------\\n気にしていたのは、データに対する仮定、モデル、交差検証の方法、の組み合わせです。\\n仮に一行一行が時間別のデータで、目的変数列と、特徴量の列があるようなデータがあるとします。\\nよくあるデータの関係は、特徴量が目的変数を説明している、という関係になると思います。式で表であらわすと、yi = f(xi) で、iは行番号を表します。f()の関数がxgbなどのアルゴリズムです。\\n式の通り、この関数には別の行の情報は含まれていません。\\nしたがって、並び替えても精度は変わらないことになりますので、交差検証の方法も通常のランダムシャッフルで問題ないことになります。\\n反面、ある行(時点)が別の行(未来の時点)を説明する場合について考えてみます。\\n式で表すと、\\nyi = w1 × yi-1 + w2 × yi-2 … wn × yi-n\\n(i-1 や i-n が行番号、w1…wnは回帰係数だと思ってください)\\n一例ですが、こんな感じです。ある行のデータが別の行のデータを説明しています。\\nまた、並び順にも意味があります。\\nデータに対してこのような仮定がある場合は、交差検証の方法はtime series crossvalが適切となります。このような関係性があるデータのことを私は「時系列構造がある」と定義していました。\\nxgbが時系列構造を検出できない、と言ったのは、アルゴリズムが行どうしの依存関係を仮定していないため、その関係を考慮出来ない、という意味になります。\\nただ難しいのが、多変量でかつ特徴量が目的変数を説明(特徴量どうしがお互いが説明し合わない)しながら、時系列構造があるような仮定を近似できる方法は限られていて、しかも精度を出すのが難しく、ほぼ職人芸になってます。\\nしたがって実務では、村上さんがフォローして下さったように、特徴量に1ヶ月前のxx、2ヶ月前のxxというような特徴量を使う事が多くなるようです。\\nすみません。めっちゃ長くなってしまいましたが、参考になれば嬉しいです！\\n', 'xgbやlgbmで時系列予測をするとき、時間に関係する特徴量を入力します。\\n月、日、時、分などです。その前提で話していました:bow:\\nそれがないともはや時系列データとは言えないので、噛み合わないのはそのせいかと今ふと思いました。\\n\\nデータの並び順が時系列を表していて、それをxgbに入力するようなイメージをされていらっしゃったでしょうか？\\nそう考えると <@UREUHGVAQ> さんの言わんとすることがわかる気がします。\\n\\nもしそうだとしたら私の言葉足らずの説明が原因でした、申し訳ありません。\\nいかがでしょうか？これでわかり合えたんじゃないかと勝手にスッキリしてますｗ', 'なるほど、データのイメージがつきました。ありがとうございました。\\nその場合は、Time Series Split せずに train_test_split -&gt; GridsearchCV でも問題にはならないですね。')\n",
      "('Katsuya Nagano',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'こ ろ ん')\n",
      "('pandas', '書籍')\n",
      "('`sklearn.metrics.f1_score` 関数について質問です。\\nbinary(0/1)が値となるsingle labelに対してf1-valueを求めるときに`f1-binary` ではなく、 `f1-macro`,  `f1-micro` を使う必要性ってありますか？\\n\\nというのも挙動としては、\\n\\nF1 macro : 陽性・陰性を入れ替えて算出したF1 binaryの算術平均\\nF1 micro : 陽性・陰性を入れ替えたそれぞれの状態でのTPやFP, FNの合計から算出したF1 binary\\n\\nが起きていて、入れ替えた算出をする意味/意義がよくわからないなと思いまして。\\n\\nついでに、multi labelに対してだと\\n\\nF1 macro : 各ラベルのF1 binaryの算術平均\\nF1 micro : 各ラベルのTPやFP, FNの合計から算出したF1 binary\\n\\nとなっていて、「陽性・陰性を入れ替え」計算はしてないので意味不明度が上がりました。\\nただ単に「single labelにmacro, microも指定はできるけど、それらへのインプットはmulti label想定なのでsingle labelにはbinaryしか使って駄目！」ってだけなのでしょうか？',)\n",
      "('ちょっとリサーチ必要そう内容なので、少し調べてから返信しますねー！', 'ありがとうございますー！', 'gistsにのなにか比較ノートブック例みたいなもの上げてもらえると助かります、、、', '途中で上記疑問が出たのであとで大幅リライトしますが、もともと記事を書いてたのでそれ載せますね（限定公開リンクのやり方がわからない。。。\\n<http://knknkn.hatenablog.com/entry/2020/01/07/193957?_ga=2.139102259.1201357534.1578272946-153306304.1520736990>', 'こちらの記事をベースにある程度理解できたと思うのですが、ここで扱っている問題ってどんな感じの問題でしょうか？\\n\\n<https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1>\\n\\n■f1-binary\\n2値分類問題にて使用\\n\\n■f1-micro, f1-macro\\n多クラス分類にて使用\\n\\nという感じの用途で使うような感じですよね。\\n\\n&gt; F1 macro : 陽性・陰性を入れ替えて算出したF1 binaryの算術平均\\n&gt; F1 micro : 陽性・陰性を入れ替えたそれぞれの状態でのTPやFP, FNの合計から算出したF1 binary\\n上記の記事を読む限りでは、\\n\\n■F1 macro\\n各カラムのf1-scoreの算術平均\\n\\n■F1 micro\\nTP・・・全体における正答数\\nFP・・・全体における誤分類の数\\nFN・・・全体における誤分類の数\\n\\nとした上でf1値を計算\\n\\nという算出方法なので、陽性、陰性入れ替えているようではないですね。\\n\\nまた、扱われているような問題として、\\n\\n一つのサンプルに対して複数の予測値が紐づくようなものを想定されているようですが、その場合だともう少し発展的な理論がいるのかもしれませんね・・・\\n\\n例えば、1枚の写真を読み込んだ際に、[\"猫\", \"犬\"]という複数ラベルが紐づくような問題を想定されている感じでしょうか？\\n\\nその場合の挙動を調べたいというのが主な意図ですかね？', '<@UPR6BE9S6>\\nベースのリサーチは概ねできたと思うので、上記不明点教えて頂ければ少し調べてみますー！', '<@UJRAL005U>\\n調査ありがとうございます。\\n私もF1macro microの認識は同じです。\\n\\nそもそもの疑問を正確に書くならば、\\nsingle labelにmacro, micro-F1って使うことはできるの？\\nできる場合`sklearn.metrics.f1_score` で計算すると変な挙動（「陰陽入れ替え」）が起きるけどこれは挙動として正しいの？正しいなら何故こういう挙動なの？\\n\\nですね。なので、なにかしらの問題を解きたいというわけではないです。', '書きかけの記事は、挙動が正しいという前提で書いてるのでややこしかったですね。すみません。記事はあくまでどういう挙動が起きているか？という部分のみ見ていただけると。', '仕様的には二値分類はbinary, 多クラス分類はmicroかmacroが推奨っぽいですが、使った時に何が起こるか考察したいってニュアンスなんですかね？', 'その認識であってます！', '正確には、\\n二値分類はbinary,  *多ラベル* 分類はmicroかmacroが推奨っぽいですが、使った時に何が起こるか(使う意味はあるか）', 'なるほど、結構レベル高い質問ですねｗ', '&gt; 使った時に何が起こるか(使う意味はある\\nこれ、二値分類で使った時です？\\n\\n多ラベル分類で使った時です？', 'microとmacroはクラスにウェイトを載せるか載せないかなので、そういう意味では必要がある場合があるのではないでしょうか？', '<@UJRAL005U>\\n二値分類ですー。', 'ありていに書けば「二値分類のときにmacro/micro使うと何故か陰陽入れ替え考慮したわけわからん挙動になるけどなんやねん。使い方間違ったから謎挙動すんのか？」なのでｗ', '<@UQSRC415Y>\\n例えばどういう目的のときでしょうか？\\nまた、何故 `sklearn.metrics.f1_score` の2値分類では通常と違う（？）陰陽入れ替えで計算されるのでしょうか？', '改めて調べて直しましたが僕の理解が間違っていたかもしれません。もう少し調べてみます', '意味合いとしては、0,1どちらとものターゲットを重視する的な感じにはなりそうですね。\\nまぁそもそもF1-macro/microの挙動として合ってるのかという疑問はありますが。', '確かに、多クラス分類のときと挙動違うっぽいですね・・・\\n\\n何故だ？？', '&gt;何故だ？？\\n:sorena: ', 'あ、イメージとしてもう機能したと思うので問題なさそうなら明日ブログは下書きに戻しますー', 'はいー！', '明日あたり、実装部分見てみますかねー・・・', 'これ見てみます。\\n\\n<https://github.com/scikit-learn/scikit-learn/blob/b194674c42d54b26137a456c510c5fdba1ba23e0/sklearn/metrics/_classification.py#L978>', '実装部分はこの辺すかね？\\n\\n<https://github.com/scikit-learn/scikit-learn/blob/b194674c42d54b26137a456c510c5fdba1ba23e0/sklearn/metrics/_classification.py#L1495>', '今日は撤退するっす', 'あー、メソッドの実装みたら挙動わかるので、想定の動きなのか的な部分のヒントになりそうですね。なるほど。\\nありがとうございます！', '動いてるコード見るのが早いっすねw', 'しかし、scikit-learnってこんなコメントびっしり書かれてんすね。\\n\\n親切ですね。', 'exampleとかもあるし、下手に解説文読むよりコードとコメント読んだ方がいんじゃないですかね？', '読んだことないですけど、pandasとscikit-learnはドキュメントが充実してるから学習のときにサイトや書籍いらんみたいな話はよく聞きますね')\n",
      "('しみずこうじ',)\n",
      "()\n",
      "('画像解析', '初心者', '書籍')\n",
      "('ラズパイを所有してます。\\n\\nこれを使ってカメラを防犯カメラのように使い、入退室する人を画像解析し、入退室管理ができる仕組みを作りたいと思いました。\\n\\n当方全くの初心者でして、何か参考になるようなサイトや書籍、勉強会などございますでしょうか？:man-bowing:',)\n",
      "()\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "()\n",
      "('ディープラーニング',)\n",
      "('<@US69FTTH6> さんこんにちは(*^_^*)\\n私が11月に参加したパソナテックの組み込みディープラーニングが正にそのままでした(笑\\n\\n定期的にそのセミナー実施していますので、参加ご検討なされては如何でしょうか(*^_^*)',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "()\n",
      "()\n",
      "('<@UN0HCK74M> まさにそのまま！笑\\nありがとうございます、探してみます！',)\n",
      "()\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "()\n",
      "()\n",
      "('これです。\\n<https://www.pasonatech.co.jp/search/feature/detail.html?p=1902>',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "()\n",
      "()\n",
      "('ありがとうございます！\\n\\n\\n》今後パソナテックよりご就業頂ける方に限り受講頂けます。\\n\\nここが引っかかってしまいました:sob:\\nすみません、ありがとうございます！:pray:',)\n",
      "()\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "()\n",
      "()\n",
      "('あ～そんな制約あったのですか・・・あったかも(^_^；\\n\\nでも、参加した身としては、Webで会員登録は促されたけど、就業に関しては特に何も言われなかったです。実際就業時期に関しては応談可と成っているので、「受けるまではやる気満々だったけど、受けてみて、気が変わった」事にしてみては？(^m^)\\n\\nメールでお仕事案内とかは来るかもですが、直接電話でゴチャゴチャ言われたり、誓約書書かされたりとかは無いので、「気が変わる前提で」申し込んでみては？\\n\\n無料とは思えない位濃い＆オススメでしたよ・・・今回の用途そのものが講習の内容でしたし(*^_^*)',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "()\n",
      "()\n",
      "('なるほど、そういう手も！笑\\nやってみようと思います:blush:',)\n",
      "()\n",
      "('ｹﾛﾏﾂ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "('回帰分析', '統計')\n",
      "('<!channel> \\nRでの重回帰分析でパラメータがNAと出た時の原因なんですけど、\\nNAと出た特徴量が他の特徴量の線型結合で表せるのが原因かと思ってるんですけど、\\nそれを確かめるにはどうすればいいですかね？\\n\\n他の変数でNAが出た列を重回帰するのは試したんですけど、エラーが出てしまって、\\n\\n',)\n",
      "('実行ログ欲しいっす！', '`a + b = c`\\n\\nみたいに表せる変数 `a, b, c` を使っているって理解で良いですかね？', '変数選択を自動でやるのであればステップワイズとかで行けた気がしますが、そこらへんの検証、どうやるんでしたっけね。\\n\\n少し調べてみますー。', 'えっと、\\n特徴量ベクトルがx_1,x_2,..,x_nとあってこれからyを重回帰で予測したい時に、\\nx_nの係数に当たるパラメータがNAと出て、その原因は\\nx_n = a_1 x_1 + a_2 x_2 + ... + a_n x_n\\nとなるようなa_1,a_2,...a_nが存在するのが原因ではと考えています。', 'なるほど。それはありそうですね。\\n\\n全部の変数は入れる必要がある感じですかね？\\n\\n予測が目的なら変数選択で除去できる気はします。', '<https://datachemeng.com/stepwise/>', 'この辺ですかね。', '実はこれ友達の卒業研究(セミナー)での内容で、おそらくうまくいかない原因をはっきりさせておかなければならないという感じです。', 'なるほど・・・', '&gt; x_n = a_1 x_1 + a_2 x_2 + ... + a_n x_n\\nこれを示すだけであれば、該当の変数を重回帰で予測してみるという方法で検証はできそう。（相関係数行列出すくらいのノリで出す方法がありそうな気もしますが、パッとは出てこないですね・・・）', 'そうですよね、ありがとうございます！\\n相関行列では1 or -1となっている列がなかったので、おそらく複数の変数が絡んでいるのではないかと考えています。', '`x_n` を目的変数、それ以外を説明変数と置いて重回帰してみれば、その仮説は検証できるかと！', 'NAが一つだけであれば、それが分かりやすいし早そうです！', '最初にも書かせていただいたんですけど、なぜかエラーが出てしまっていて、\\nちょっとそのエラーの原因を探してみます。', 'ランク落ちは、RのVIFが一発ですよ', 'パッケージ名称は car です。\\n作成したモデルを突っ込んで実行するだけなので、もしRを触ったことがあれば簡単に動かせると思います。\\n参考までに、VIF値とは\\n1/(1-決定係数)で表される値で、完全にランク落ちしている変数は、確かinfになるはず。', 'あ、Rの重回帰って書いてありましたね。失礼しました。', '<@UNJD36PFG>', 'おおお！！！！\\n多重共線性調べる統計量があるんですね！\\nありがとうございます！！！')\n",
      "('ｹﾛﾏﾂ',)\n",
      "('こ ろ ん',)\n",
      "()\n",
      "('あと、これ以外で考えられる原因ってありますか？',)\n",
      "('切片がダブってる説', 'どゆこと？', '切片のベクトルが複製されてるんじゃない？使ってるデータがわからんからあれやけど')\n",
      "('しみずこうじ',)\n",
      "()\n",
      "()\n",
      "('<@UN0HCK74M><@UN0HCK74M><@UN0HCK74M> 申し込んでみたら返事が来ました！:raised_hands:\\n学んでこようと思います！\\nありがとうございました！:man-bowing:',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "()\n",
      "()\n",
      "('ぬお、なぜ3個メンションが……失礼いたしました:man-bowing:',)\n",
      "()\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "()\n",
      "()\n",
      "('あはは！まぁまぁ落ち着いて(^m^)',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('1@で書いたのに複数@で投稿されるのはslackのバグっぽいです。発生条件はよくわからないですが、私も前なりました',)\n",
      "()\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Yuta Kita', '尾銭泰徳 ozeni.yasunori', 'ﾋﾛﾘｰ')\n",
      "()\n",
      "('あまりこのサロンには関係ないですが、4月に技術者試験を受けてみようと思いますが、ほぼ未経験ですが、基本から受けるべきか、応用いっちゃうべきか、PMを来年に向けてテスト受験するかどれがいいでしょうか？\\n時間ですが、\\n2月〜3月で合計100時間ぐらいは確保できるかな〜と思っています。',)\n",
      "('PMってレベル4ですか？', 'IPAのプロジェクトマネージャ試験？', 'であれば、確か午前免除されるので応用取っといた方が良かった気がします', '<https://www.jitec.ipa.go.jp/1_00topic/koudo_menjo.html>\\n\\nこんな感じなので、応用か午前問受かっとくと楽な感じですね。', 'ですw', '私の会社では応用以上でないと評価されません…\\n逆に言えば、応用を持っていればそれなりに評価されてる感じですね', '応用情報で合格率が20%ぐらいですね\\n<https://www.jitec.ipa.go.jp/1_11seido/ap.html>', 'ちなみに応用は持ってて、ITストラテジストはおちましたw', '応用情報から受けることを絶対的にお勧めします！\\n未経験の人であれば逆に基本の方が難しいという人が多いですし、PM目指すなら応用情報を2回受けた方がいいと思います！', 'ITストラテジストの受験年齢、めちゃくちゃ高かったですねｗ\\n\\n受けた時に「データを活用して改善した経験」の小論文が出てドンピシャだったのですが、午後1で落ちて採点されず残念でした・・・', 'ITで実務やってれば応用は案外行けるイメージですね。広く浅くなので、案外知ってること多い感じあります。', 'いくつか上位資格持ってますがSIerにいたときは社内ポジション取りに活躍してくれたので、とってよかったなーと思ってます。頑張ってください！（僕もPM欲しい。。。）', 'IT系の試験なんだから、小論を手書きでやらせるのやめて欲しいｗ', '思考というより、物理的に間に合わないので結構悩ましかった記憶がありますｗ', 'PM系の資格に興味ありますー\\n小論文がある試験もあるのですねぇ\\n応用情報受けてみよっかなぁ\\n&gt; 小論を手書き')\n",
      "('maimai',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '小竹(fishb)')\n",
      "('設計', 'OCR', 'クラウド', 'テキストマイニング', '可視化', '書籍')\n",
      "('データ分析素人の質問です。\\nVOC分析手順シミュレーションを作成中です。\\n実際にプロの手順や手法を具体的に知りたいです。\\n※製品諸々に関しては架空です。\\n\\n\\n毎年春に学生向けスマホ（仮称：学スマ）を販売しているメーカーからの依頼です。\\n背景：アンケートを集計したので活用したい\\n目的：次期モデル改善\\n決定事項：？アンケートのテキスト項目を活用したい\\n前提条件：？学生向けなので親がプレゼントすることが多い。\\n\\n\\n件数：500件\\n期間：去年の4月から12月\\n取得方法：Webサイト、製品同梱のアンケートハガキ\\n取得条件：会員IDや製品IDの登録がなくても誰でもアンケートを送ることができる。\\nデータ内容：デザイン、使いやすさ、価格帯など5段階評価の定量データとフリーテキストによる定性データ。\\n個人情報として年齢、性別、居住地域、購入モデル名。\\n\\n★以下知りたい\\n手順\\n1.データークレンジング\\n2.データベース登録？\\n3.テキストマイニング？\\n4.可視化？ユーザー分布？構成比グラフ？\\n5.仮説を立てる\\n6.検証\\n\\n他、不足している情報などありましたら教えてください。',)\n",
      "('1.\\n\\n500件ならオペレーターにやって貰えば大丈夫ですが、OCRとかである程度効率化はできそうですね。\\n\\n2.上記の方法によりますが、手入力 or 自動抽出って感じだと思います。\\n\\nその後のステップに関しては、何が検証したい感じでしょうか？\\n\\n先に何が知りたいかのリサーチデザイン、アンケート項目設計ありきかなーと思いますー。', '回答ありがとうございます！\\n手順にある仮説、検証は講座資料をそのまま書いただけでした。\\nわからないことがわからない質問恐縮です；\\n\\n漠然と製品改善したいと言われた場合にどんなことをヒアリングしていけばいいのでしょうか。\\n\\n仮定するとして\\n・フリーテキスト項目に、こんな機能欲しい、こんな機能いらないとあった場合\\n・フリーテキスト項目にここのボタンが押しにくくなったなどの不満があった場合\\n\\n上記二つに関して対応する場合\\n・希望機能や不要機能がが全体から見た割合でどのくらいを占めているかで、\\n機能の実装、取り消しを検討する形をとるのでしょうか。\\n\\n・ボタンの不満に対しては操作性に関することと考え、ボタンの共起ネットワークを探して\\nボタンの配置、素材感、かたさなどの内容をピックアップするのでしょうか。\\nまたこちらも割合で検討を決めるのでしょうか。', 'アンケート項目設定も\\n目的に次期モデルの改善とあるのであれば\\n\\n操作性\\n色のバリエーション\\n大きさ\\n重さ\\nなどもアンケート項目に入れていくということですね。', '&gt; 500件ならオペレーターにやって貰えば大丈夫\\n重ねて質問となりますが、何件くらいからオペレータきっつい感じになりますかね。データベースを視野にいれる目安件数ってありますか？テキスト量としてはアンケートのフリーテキストなので書かない人も多いイメージですが…', 'ツール使うかは、導入コスト、利用料などと時給、作業工数を比べて算出する感じなので、ROI計算してみるといいと思いますー！\\n\\n1帳票3分くらいで入力終わるなら1週間以内には終わるかなーと！', 'あと、500件のアンケートで共起ネットワークがそこまでしっかり出てくるかは、微妙な感じあるとおもいます。', '500件のフリーテキストの解析なら、\\n\\n・ポジネガ判定\\n・ワードクラウド\\n\\n辺りが現実的かなぁと思いますね。文章量によりますが、任意のアンケートならそんなに文章量多くないでしょうし。', 'アンケートリサーチにおける仮説や勘所がないのであれば、事前にユーザーテストとかをして、どこら辺に課題があるかの当たりつけた方が良いかもしれませんね。', '&gt; 目的に次期モデルの改善とあるのであれば\\nこちらに関しては、NPSなどを用いて定点観測して行くと良いと思いますー！', '現在の状況ですと、仮説も固まっていないような状況な気がしますので、\\n\\n・UI・UXなどの専門家にエキスパートレビューをしてもらう\\n\\n・ユーザーテストを行って改善点や仮説を発見する\\n\\nということをまずやった方が良いような気がしますね。', 'ありがとうございます！今レスいただいた内容で資料作成してみます！またわからないことがありましたらここでまた質問させてください！\\n取り急ぎお礼でした！！', '今自宅にいないので、そこらへんの書籍も少し見てみますー！', '共起ネットワークは500件くらいではそこまでしっかり出てこないのですね…やはりプロに聞くとそのあたりの数値の意見聞けるのありがたいですね…', '同じことに多く言及されてば多分出て来るので、一概には言えないのですが。\\n\\n例えば、飲食などの評価だったら、「美味しい」、「旨い」みたいな特徴的な言葉は抽出できると思うのですが、スマホのアンケートとかだとばらつきそうかなと思います。', 'アンケート項目設計をどういった情報が欲しいかを仮定して\\n設計してみます。\\nリサーチデザインという単語を覚えました。\\n専門用語聞けるの本当ありがたいです。', '村上さんも「先にアンケートの項目設定ありき」とおっしゃってますが、本当にそうだと思います。\\n\\nアンケートって、誰でもなんか回答したことあるし、コードと違って日本語だし、なんか誰でも「それっぽく」作れちゃうんですよね。\\n「何を知るためにどう聞くか」というリサーチの設計がないままにそれっぽい質問を並べただけで実施されてるアンケートが本当に多いなと思います。\\n\\n\\n<@UMTMKBB1Q>\\n調査票未見なのでなんとも言えませんが、上記情報だと、「大人用か、子供用か」「学生で自分で機種を選べる人、親が決めたものを使わざる得ない人」みたいな軸で分析してみたいですね。\\n\\n例えばですが、「学生はデザインの優先度が非常に高いが、実際は中高生の７割が親が選んだスマホを利用しており、親は端末金額をもっとも重要視している」みたいな調査や情報があれば、結局端末価格が重要だなってなりますけど、ただ個別の端末に関するアンケート結果だけみてたら、「この機種は使いやすさが評価が高いので、そこをアピールしよう！」ってなっても、それは全然訴求ポイントじゃない、みたいな。', '<@UKPAM2942> 返信ありがとうございます！！\\nそれっぽく作れる、それはありますね。\\nこんな目的にはこんなアンケートがいいですよといったフォーマットを作れるようになると喜んでもらえそうですね♪\\nリサーチの設計等調べてみます。\\n\\n学スマ自体は架空でして（実際に依頼されそうなアイテムが学生向けで毎年モデルが出ているものだったのでスマホと仮定した）…\\nしかしお金払うのは親というのは共通なので、単なる機能だけを追求するのではなくモデル毎の価格帯（上位機種下位機種）ごとに出す必要がありそうです！！\\n\\nありがとうございます！！')\n",
      "('sho.kumada',)\n",
      "('Hiroyuki.Tachikawa',)\n",
      "('ベイズ',)\n",
      "('optunaのlightgbm_tunerて使われたことある方いますでしょうか？\\n昨年PFNから発表されたoptunaの新機能で、ハイパーパラメータの範囲を指定せずに、\\nlightgbmのパラメータチューニングができてしまう代物です。実験的に使ってみました。\\nハイパーパラメータの範囲指定は、ある意味ハイパーパラメータでしたが、それすら行わなく良いということみたいです。\\n\\n【疑問点】\\nlightgbm_tunerを使った最適化コードの中にハイパーパラメーターの探索範囲を指定している箇所が見当たらない。\\n（これが売りなので、当たり前ですが）どうやって探索範囲を決めているのか？\\n\\n【調べたこと】\\nPFNからの発表（P59〜）\\n<https://www.slideshare.net/pfi/pydatatokyo-meetup-21-optuna>\\nコード例\\n<https://blog.amedama.jp/entry/optuna-lgb-tuner-stepwise-tuning>\\n\\n【試したこと】\\nとあるデータで、2クラス分類の予測をlightgbm_tunerを使った場合と、使わない場合で比較。\\n確かに精度が上がっていた。\\n```accuracy\\nチューニング前 81.05872622001654 %\\nチューニング後 81.30686517783292 %```',)\n",
      "('確かにこれではソースコードを読み込まないと分かんないですね...。全然解説が見当たらない。', 'ただの予想ですが、初期値はランダムシードでベイズ最適化っぽい気が。', \"コメントありがとうございます！\\n上記2個目のリンクのコードだと以下の箇所で初期値を指定しているようです。おっしゃる通り、ドキュメントを見るとrandam_seedがデフォルトで入っているようです（明示しなくてOK)\\nなので、初期値はランダムに決めて、そこからベイズ最適化で範囲を絞っていく感じですかね。で、決めた回数だけ絞り込みを行うと（このコードだと1000回）。そうすると、良い感じに範囲を決めてくれていると言うよりは、ランダム値から始めるから範囲設定の手間が省けますよと言うイメージですかね。。まずベイス最適化を勉強してから、ソースの中身覗いてみます。\\n\\n```    # 学習用基本パラメータ\\n    lgb_params = {\\n        'objective': 'regression',\\n        'metric': 'rmse',\\n    }```\\nLightGBMのパラメータ\\n<https://lightgbm.readthedocs.io/en/latest/Parameters.html>\", 'おお！なるほど！もし何かわかれば是非シェアしていただきたい！！', '承知しました！誰でも意識せず使えるようになるのは便利ですが、納得感持って使うために中身を理解する力が求まれらますね、、顧客や上司に概略説明できないと使えないかもです笑')\n",
      "('sho.kumada',)\n",
      "('Yuta Kita',)\n",
      "('pandas', '可視化', 'Python')\n",
      "('連続投稿で恐縮です。\\nseaborn、pandas plotを使った可視化で、あるデータの性別ごとの解約率を可視化したいと考えています。\\n下記、2つの方法で縦軸をデータ数にしたグラフは描けました。\\nしかし、男女数と解約数が均等でないため、縦軸を割合にしたいです。\\nつまり、性別1の内、解約1の割合と解約0の割合を図示。同様に、性別2の内、解約1の割合と解約0の割合を図示したいです。\\n簡単に言うと、下記のグラフの縦軸をデータ数ではなく割合にしたいと言うことです。\\nデータフレーム上で割合に変換せずとも簡単に達成できる方法ありませんでしょうか？\\n\\nseaborn、pandas plot以外の方法でも構いません。\\nPythonでデータを読み込んでいるため、できればPythonで可視化したいです。\\n```modeling_dataは\"性別\"、\"解約\"カラムをもつデータフレームになります。\\n下記は、いずれもほぼ同じグラフになります。\\n\\n・seabornを使った場合\\n\\u3000sns.countplot(x=\\'性別\\', hue=\\'解約\\', data=modeling_data)\\n\\n\\n・pandasのplotを使った場合\\n\\u3000modeling_data[\\'解約\\'].groupby(modeling_data[\"性別\"]).value_counts(dropna=False).unstack().plot.bar()\\n\\u3000plt.xlabel(\"性別\")\\n\\u3000plt.ylabel(\\'count\\')```',)\n",
      "('pandasの場合、value_countsのオプションの以下設定で可能かと思います。\\n`normalize=True`\\n<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html>', 'そんなオプションがあったとは、、ありがとうございました！\\n見事に目的の形にできました。')\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "(\"すっごい初歩的な質問で申し訳ないですが、lightGBMでtrainしたときに出力されるloss結果を表示しないためにどうしたらいいでしょうか。\\n<https://lightgbm.readthedocs.io/en/latest/Parameters.html#io-parameters>\\nこのあたりに書いてないかなー、と思ったのですがわからず。。。\\n↓こういう出力(valid_0's binary_logloss: …)\",)\n",
      "()\n",
      "('れごん-島根のﾌﾘｰﾗﾝｽ',)\n",
      "()\n",
      "()\n",
      "('<https://lightgbm.readthedocs.io/en/latest/Parameters.html#verbosity> の数値で何個ごとに出るか指定できるはずです。',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('<https://qiita.com/nabenabe0928/items/6b9772131ba89da00354#verbosity>\\nとかにも、-1とすると表示されない、ってあるけどめっちゃ表示されるんですよね。。。2とか10にしても2こごとに出力されてるようにはみえませんし。\\n\\n(他のパラメータはテキトーにやってるので気にしないでください）',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "('jupyter',)\n",
      "('jupyter labのせいとかすかね :thinking_face:',)\n",
      "()\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('verbose_eval かも\\n<https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html>\\nここに以下のような記述が\\n```verbose_eval (bool or int, optional (default=True)) –\\nRequires at least one validation data. If True, the eval metric on the valid set is printed at each boosting stage. If int, the eval metric on the valid set is printed at every verbose_eval boosting stage. The last boosting stage or the boosting stage found by using early_stopping_rounds is also printed.```',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('できました！ありがとうございます！',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('`verbose_eval` は標準出力有無の制御で、 `verbosity` は内部的なものとかなんですかね？loggerに吐きたいときの制御というか。',)\n",
      "()\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('ぽいですね。後者はloggerを呼び出してるのかなぁ',)\n",
      "()\n",
      "('Katsuya Nagano',)\n",
      "()\n",
      "()\n",
      "('とりあえず、`train` メソッド使ってるからそっち自体のドキュメントも読もう、という学びも得られました。よく考えたら読んでたのはlightGBM自体のドキュメント。ありがとうございました！',)\n",
      "()\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('いえ！私も勉強になりました！',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@UREUHGVAQ> <@UL0NZCCMT> <@UQXUSE316> \\n回答しなきゃなーと思って開いたら解決してた！！\\n\\nご回答ありがとうございます！！',)\n",
      "()\n",
      "('shinji',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('すでにどこかにまとめがあったらすみません。\\n\\nチャンネルの一覧はどこかにまとまっていたりしますか？\\n最近チャンネル自体も増えているようなのですが、\\nキャッチアップできていないものがある気がするので、\\n教えていただけますと大変ありがたいです。',)\n",
      "('以前アップデートしていたのですが、最新版には更新できていないのですね。。。\\n\\nこちらのリンクに記載してある手順で確認頂ければチャンネル一覧は確認できるかと思うのですが、こちらの手順だと検索大変でしょうか？？\\n\\nチャンネルリストの更新をすべきか判断したいです。\\n\\n<https://slack.com/intl/ja-jp/help/articles/205239967|https://slack.com/intl/ja-jp/help/articles/205239967>', 'ありがとうございます。\\nこちらのご案内で大丈夫です。', '了解です！解決したようで良かったです！！')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('すずきしげお',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'Katsuya Nagano', '小竹(fishb)', 'しみずこうじ', 'ｸﾛ\\u3000京大医学部3年', 'Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('AR', '転職', 'ビッグデータ', 'AI', '統計')\n",
      "('みなさんは「なぜデータ活用をしなければならないのか」と聞かれたらなんと答えますか。いつも経営陣とこの議論になり結局「よくわからないからデータ活用しない」という結論になります。「意思決定を迅速かつ正しくします。」という旨を答えているのですが、いまいち説得することができません。自分の仕事の根幹となる問いなので、きちんと答えられなくて悔し恥ずかしなんですが。（以前にお伺いした社内研修でも同様の議論があります）',)\n",
      "('それは、経営者がいなくても意思決定できるようにするためだよ・・・・:scream:', 'はさておき、なんかよい論法をあとで考えます。', '勘ではなく、定量的なエビデンスをもとに判断するためとか？\\n\\n勘だと認知バイアスなどが原因で誤った判断をしてしまう。\\nまた、定量化されているので勘がない人でも数値さえみればわかる（勘を持っている人=経営者？がいなくても意思決定できる）。', '自分も、いまだデータよりも経験と勘と人脈がすべてと言ってもいいレガシーな業界（音楽業界）に居るので、その気持ちは良く分かるというかもっとヒドイ状態かも知れません。\\n\\nAIとか予測モデリングとかの3段階くらい前の、「データ見る」「データを参考にする」という意識や文化がありません。\\n（一方で、たしかにデータを見て意志決定すればヒットが生まれるわけでも、ブレイクする新人を見極められるわけでもないので仕方ない部分もあると思っています）\\n\\n底辺過ぎる例えで参考にならないと思いますが、会社で良く言うのは、「データを見ないのは体重計乗らず、今の体重も知らずにダイエットを始めるようなもの。体重計に乗っただけで痩せる（売れる）わけでもないし、体重計乗ったからと言ってどんな食事をすれば良いか（どんなプロモーションや施策を打てば良いか）が自動的に分かるわけではないです。でも、体重計に乗らなかったら、果たして痩せてるのかどうか、その運動が効果あったのかどうかもまったく分かりませんよね」という話をします。\\n\\n「データ」「分析」「データ分析」が指す意味や範囲がかなり人によって違うと思うので、議論する際はそのすり合わせからした方がいいかもしれませんね。ビッグデータのような大量の数字の羅列だけが「データ」と考える人もいるし、分析結果なども含めた広い意味での「情報」をカタカナで行ってるだけの人もいるし。', '煽り気味に言いますかね……\\n\\n『羅針盤持たずに航海に出る人はいませんよね、\\n羅針盤って海の真っ只中でも方角という事実がわかる仕組みなんです、\\nデータもそうで、ちゃんと行きたい方向に向かってるのか、確かめることが出来るんですよ、\\nもう一度聞きますけど、あなた羅針盤なしでグランドライン目指しますか？』', 'データ分析に対して不信感がある可能性がありますね。\\n「この歌手がヒットするか予測する分析します！」といわれた結果が当たらなかったとか、「60%の確率でこの人はヒットします！」と言われてもよくわからんわ0か100で言え、みたいな。', '権威の力を借りるなら、この本読んで、「少し前に流行ったのでご存知かもしれませんが、USJでは… 」みたいに言いつつ自社の場合に置き換えた話をするとか。\\n<https://www.amazon.co.jp/dp/4041041422/ref=cm_sw_r_tw_dp_U_x_2bBhEbQYNYWYY>', 'この手の経営陣（でいいんですかね？）は、漢気見せて欲しいだけのこともあります。\\n\\n何かあっても責任はわたしがとります！（ハッタリ）\\nが1番有効なこともありますよ', '皆さん色々とありがとうございます。\\n・意思決定の自動化、標準化ができるよ\\n・データという指針なくして何もできないよ。\\n・事例を示すよ\\n・求められてるのは実は正しい説明じゃないかもよ？\\nって感じでしょうか。\\nもう一つ難しいのは私の会社の経営陣はすぐ忘れるということですね、、、一度納得してても油断ならない。これに関しては根気しかないかなと諦めてますが。', 'なんとなくの感覚から出した結論と、統計から出した結論のギャップが大きいっていう事例が世の中にはたくさんあるので、それを例に出すと説得力が増すかもしれません\\n\\nみなさん難しい話をされてるので、卑近な例を出すと違ってくるかもしれません', '実務に就いたことのない学生の戯言かもしれませんが...!', 'ありがとうございます。なんかしっくりくる事例探してみます！', '適切かわからないですけど、モンティホール問題とか面白いですよね...感覚でやっちゃうと大多数の人が間違える典型', '経営陣なんですね。。\\n\\n転職\\u3000というのが1番手っ取り早いかもですよ。。', '<@US69FTTH6> 転職は簡単なんですが、こういう会社こそ何とかしたいというマゾヒズムにも近い課題認識なんです。', 'フェーズがあると思うんですよ。\\n基本的に優秀な人材が多く、成長フェーズにおいてはデータによる意思決定よりも人的なエネルギーやモチベーションになどの意思決定の方が会社が成長できますが、鈍ったり人が多くなったり、迷いが生じた時にデータで意思決定した方がミスが少ない（トータルとして良い選択ができる）と思っています。\\nなので、社運をかけたプロジェクトにおいてはデータ分析はいらないと思っています。', '<@URRKHGARX> むむむ、無事上手くいくことを願っております……！\\nですが沈没する船に巻き込まれそうになったら逃げてください:+1:', '<@US69FTTH6>  確かに映画タイタニックでも船に残るバンドマンに感情移入するタイプですねw見極めは頑張ります\\n\\n<@UL2TY2ERL> 創業100年超の日本的伝統的大企業で市場は右肩下がりなので、完全停滞ムードです。だからこそデータ分析によるレバレッジも効きやすいと思うのですが', '「科学的な意思決定を行うためにデータを活用する企業が増えています。科学的とはただの思い込みなのか、そうでないかが明らかになるということです。つまり、現在の権威にあぐらをかいている方には損ですが、そうでない方にとっては得なのでどの企業もデータ分析に取り組んでいるんですよ。」\\nと教えて差し上げる！というのはどうでしょうか(笑)\\nまぁオススメはしませんが….合理的な意思決定ができないタイプの人達を動かすのは、この手のアプローチが最も聞きます。（コツはあるのでミスると地獄）\\nただし、タイプの仕事のやり方は成果を出すことはできたとしても、会社の文化によりますが出世に時間がかかります。', '<@URRKHGARX> お気をつけくださいませ:man-bowing:', '&gt; 100年超の日本的伝統的大企業で市場は右肩下がりなので、完全停滞ムードです。だからこそデータ分析によるレバレッジも効きやすいと思うのですが\\n完全な個人的な考えですが、もうそこまで来ると自分が定年するまで変革する理由がないと全体が思っているので強烈なトップがいない限りは変わることはなく、内部から変える社内政治力は悪手なような気がするんですよね。もし、大株主だったら別ですけど。', '変革をミッションとして与えられてる人たちも与えられた変革をこなしてるだけですしね..変な表現になりましたが。', '泥舟には泥舟の醍醐味があるので、個人的生存戦略を睨みながらもうちょい粘ってみようかなと思います。また皆さん相談乗ってください！', '<@URRKHGARX>\\n講座で使用した資料の抜粋ですが、大枠としてはこのようなイメージですかね。\\n\\n大企業であれば、経費削減、コスト構造を効率化するみたいな話が分かりやすいかもですね。みんなコスト削減好きですし。', 'ありがたく参考とさせていただきます！')\n",
      "('ﾂｷまくりﾏﾝﾎﾞｳ',)\n",
      "('Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('AutoML', 'ML', 'DataRobot', 'データサイエンティスト', '機械学習', '初心者')\n",
      "('機械学習初心者の機械系エンジニアです。はじめて質問させていただきます。\\n\\n仕事でデータサイエンティストの方にテーブルデータの分析を依頼したら、TPOTを使った予測結果が送られて来ました。決定木回帰ベースみたいです。\\n\\n皆様に質問なのですが、TPOPってどんな場合に使うのが良いのでしょうか？遺伝的プログラミングを使うといった、アルゴリズムの概要はググって理解したつもりなのですが、利点がイマイチわからず…\\n\\nデータサイエンティスト本人に聞けば良いところなのですが、海外にいるのと英語なのでなかなか、、、\\n\\nざっくりした質問で恐縮ですが、こんな感じで質問して良いのでしょうか？どうぞよろしくお願いいたします。',)\n",
      "('TPOTってそこそこ精度のいい予測モデルを手軽に作りたい時に使うかな。他のシーンはちょっと想像つかないかも。', 'さっそくありがとうございます！そうなんですね。そういった感覚的なところが知りたかったので、助かります！', 'おお！お役に立てたようで良かったです！\\nなんか一応使ったことあるんですけど、AutoML系ツールの一つって感じでした。（つまりほぼよくわかってないw）', 'なるほどです。AutoML使うなら、普通はこれ使うよ、とかってありますか？', 'す、すみません。実験でちょっと触ったことあるぐらいでほぼ使ったことないっす。なんとなくGoogleAutoMLが流行っている気がする…。\\nだれか知ってる人〜\\n```AutoML使うなら、普通はこれ使うよ、とかってありますか？```', 'あ、とんでもないです！全体メンションありがとうございます！', 'AutoMLに関しては、DataRobotとかが高いですけど、メジャーですかね。\\n\\n次いでGoogleのAutoMLといったイメージです。pythonで複数モデル走らせてくれるようなやつも結構あるけど、使ったことはないですね。', '返信ありがとうございます！\\nなるほどです。\\nDataRobotは高額\\nGoogleのAutoMLはGoogleにデータ見られる\\nといったところでしょうか\\nちなみに興味なのですが…DataRobotっておいくらくらいなのでしょうか？プランはいくつかありそうですが…ググッても価格は見つけられず…', '詳細なプライシングは共有できないのですが最低限売上100億くらいの企業じゃないと導入厳しそうだなぁという印象の価格帯ですね。（100億でも厳しいかも？）', '外資のSAASだなぁというプライシングですね。\\n\\n自分は正確なプライシング知ってるので逆に共有できずでして、誰か噂話を共有頂きたい所ですw', 'なるほどです！すみません興味で聞いて閉まったので、これ以上深掘りしないでおきますm(_ _)m\\nそれだけ高価でも導入する会社があるということはすごいんですねぇ', 'めちゃ便利ですね！！', 'data robotの価格は本当の噂なんですけど、月額数百マンぐらいのはずです。', '数百万ですか〜〜\\n当然ですが会社単位で導入するしかないですねぇ。')\n",
      "('maimai',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('コーポレートサイトをリニューアルします。\\nGAを使い定期的に分析レポートを提出することとなりました。\\nレポートに入れた方がいい項目やおすすめCVなどのご意見がいただきたいです。\\n逆にこの項目はみんないれるけどあまり分析に使わないなど…\\n\\n【リニューアル理由】\\n・Webサイトを営業ツールとして活用したい。\\n\\n【営業ツールにするにはどうしたらいいか？】\\n・各種サービスに対する問い合わせを増やす？\\n・検索流入を増やす\\n\\n【CV項目】\\n問合せフォーム\\n将来的に資料DL\\n\\n【レポートに入れるもの】\\n・流入が多いのはどのサービス紹介ページ（orブログ記事)か？\\n・どのサービス紹介ページか（orブログ記事)からの問い合わせが多いか。\\n・どのサービス紹介ページが滞在時間が長いか、読了率が高いか\\n・基本のPV数、UU数、SS数、離脱率\\n\\n【どう分析レポートを活用するか？】\\n・読了率の低いページについては改善する\\n・ブログ記事へのリピーターを増やすために人気のあるブログ記事をランキングにする\\n・問合せフォームの配置場所を効果的にするためにどこからCVをしたか比較する\\n\\nあまりアクセスがないと思うこと、CVに問合せフォームを入れはしたものの実際問い合わせてくる人はしばらく０だと思います。\\n分析レポートで問い合わせ０なので、まずはこんな認知してもらえるように、施策をうちましょうといった流れでいくことになるのかなと考えているのですが、CV数はおいておいて、UU数を前月より増やすという目標を掲げていくレポートを作成するのがいいのでしょうか。\\n\\n\\n\\nサービス紹介特化なWebサイトというよりは、よくあるコーポレートサイトです。\\n企業情報、代表挨拶、サービスの説明、ブログ（実績一覧）、よくある質問、採用情報、問い合わせフォーム',)\n",
      "('取得するデータ自体は概ねそのような所で問題ないと思います！\\n\\n営業におけるカスタマージャーニーを書いてみて、それのどの部分をWebサイトがカバーしているのか、その目的を果たしたかどうかをどう図るかを営業のポイントごとに指標化してあげるのが良いのかなーと思います！',)\n",
      "('こ ろ ん',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'れごん-島根のﾌﾘｰﾗﾝｽ', '澤祐斗\\u3000東工大3年', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'maimai')\n",
      "('VR', '可視化')\n",
      "('いい描画ソフト？アプリ？サイト？を探してます\\n\\nたとえば球体に接する面を描画するソフトってありますか？',)\n",
      "('そういうやつか。数式とかの描画？\\n\\n3Dモデリング？', '数式じゃないです！デザイン的にビジュアライズしたいので数式でのプロットではなくて\\n\\n感覚的なプロットです', 'なんというか', 'うまく説明できませんが、とにかく数式を用いた厳密なプロットではなく、\\n\\nあくまで絵という意味での3dプロットをしたいです', '例', '<@UL0NZCCMT> \\n\\n3Dモデリング系ですかね？\\u3000VRとかだと何を使ってます？', 'これは球面じゃないんですけど、こんな感じです', 'これであれば、python、Rあたりの数式可視化で良さそうな気もしますね。', '最終的にパワポに貼り付けて発表したいんですけど、もしツールがないとなると\\n\\n手書きなので、、、', 'あとネジレとかです\\n\\nここにベクトルを書いたりしたいです', '手軽にとかだと、 <https://www.vectary.com/> とかですかね。球面上に描画するとかは、もう少し面倒ですが。', '用途に合うか分からないですけど、figmaの3D描画プラグインは3Dデザインにいいかもです\\n<https://www.vectary.com/3d-modeling-news/figma-3D-vectary-plugin/>', '<@UL0NZCCMT>\\nありがとうございます！！', '球面上の直線とかかく予定です。イメージは飛行機の航空路的な感じです。', '<@UL08YKGLU>\\n便利そう。確かに生命系とか科学とかだと描画多そうなイメージあるけど、そういう用途で使う感じ？', 'みなさんありがとうございます。とりあえず試してみます', '<@UJRAL005U>\\n大学で使ったことはないですね。。インターン先でバナーデザインとかする時に遊び半分でって感じです！', 'もう3D CAD', '調べてみます！！！', 'Google SkectchUp\\n前は無料で使ってたけど、球体プラグインとか、素材でなんとかならんかな', '<@UQSRC415Y> \\n使ってみた所感とかまとめて貰えると嬉しいかも！')\n",
      "('chan',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "('時系列', 'AR', 'ベイズ')\n",
      "('<@UREUHGVAQ>\\n返事が遅れてすみません。\\nいろいろ考えていたのですが、ひとりで考えるよりせっかくのコミュニティですのでいろんな考え方を聞きたく思いました。\\nそして質問の趣旨が変わってきたのと、もう少しオープンになるように改めて新スレッドで投稿します。\\n\\n質問はxgbやlgbgなどを使って時系列データの回帰（予測）タスクにおけるデータの分割についてです。\\nもともとの質問はこちらです。\\n<https://data-learning-guild.slack.com/archives/CJCNV9LG2/p1578273060356300>\\n\\n&gt; Time Series Split せずに train_test_split -&gt; GridsearchCV でも問題にはならないですね。\\nこのtrain_test_splitはシャッフルスプリットでも問題ないということでしょうか？\\n問題にならないというのは、パラメータを決める上で問題にならないという意味ですか？\\n私はシャッフルスプリットすると、精度が高く出てしまいモデルの評価が難しくなると考えてしまいます。\\nテストデータにおける予測の精度も変わらないのでしょうか？',)\n",
      "('イメージとしては、\\n\\n1月～12月のデータを使うとして\\n\\n■パターン1\\n全期間で6分割してクロスバリデーション\\n\\n■パターン2\\n時系列で1～10月をtrain、11月, 12月をtestとする\\n\\nみたいなイメージで、パターン1でも問題ないかを確認していという意図ですよね？\\n\\nその場合、時系列変化によって、構造が変化しない（トレンドなどが存在しない）という前提を必要するかなと思います。\\n\\nその前提を持つのは大体の時系列データで難しいと思うので、パターン2のtime series splitが必要という認識です。', '例えば、接種栄養素を説明変数、1ヶ月以内に病気にかかるかを目的変数と置いたようなものだと、時系列があったとしても特に時系列情報は捨ててあげても問題なさそうですが、\\n\\nイベント施策と1か月後のリピート率みたいなモデルの場合は時系列効果が効いてくるので難しいのではという感じです。', 'ありがとうございます。村上代表の認識で私も理解できます。\\nパターン１でも問題ないか？確認というよりも、\\nパターン１では問題がありそうと考えてるけど、どうなんだろう？というかんじです。\\n\\nちなみにデータは商品の需要予測のような時系列で、トレンドがあります。\\nおそらくひっかかっているのは、\\nデータの性質によって分割を決める（村上代表の例のように）のではなく\\nxgbだったらこの分割方法で大丈夫というかんじでモデルによって変えることがあるのか？という疑問です。\\n内部アルゴリズムを完全に理解してないので、実質同じことになる可能性もあると思ったりしてました。', '①ある行が別の行を説明している場合\\n②そうで無い場合\\nによってアプローチが変わります。\\n①の場合は time series sprit が必要ですが、xgbは不適切で恐らくびっくりするぐらい精度が出ないはず。\\n反面②はxgbは適切ですが、time series spritはしなくても良く(してもいい)、シャッフルスプリットの交差検証で問題ありません。\\n理由については文章表現が難しいので、後ほどスライドを書いて説明します。', '<@US2HKDVSL>\\nモデリングの手法とバリデーションの分割方法は必ずしも対応している訳ではないですね。\\n\\n時系列データってかなり扱いが難しくて、リーマンショックの前後、東日本大震災の前後で全く違ったモデルになるとかがあるので、前と後でできるだけ共通したモデルにしてあげなきゃいけないんですよね。\\n\\n例えば、リーマンショックの後のデータが使えるのであれば時系列に対応して急激に株価が下がっているような予測モデルが出来上がると思うのですが、それってもはやカンニングなので適切ではないです。\\n\\nリーケージ、リークといった用語で調べて見ると分かりやすいかもしれませんね。\\n\\n<@UREUHGVAQ>\\n①のパターンって、そこから特徴量を追加で作るのではなく、加工できない前提でしょうか？\\n\\n①の場合はLagとか階差とかを取るような処理をするイメージです。それができない前提であれば、精度でないというのは合意です。', '<@UJRAL005U>\\nまさしくその通りです。SARIMAやVAR等で解きたいようなデータ構造を指してます。\\n\\n仮にxbgを使う前提があるとした場合は、time series split は理論的にはあまり意味がないと思います。もしランダムシャッフルでリーケージが起こるなら、バリデーションの方法ではなく、リーケージした変数が含まれていることが原因になるかと。もちろんランダムシャッフルした後にlag変数を作るのはNGですが...。\\n\\nただ、期間によって分布自体が異なることを学習データに織り込みたい場合など例外はあると思います。', '理解しました！\\n\\n&gt;ただ、期間によって分布自体が異なることを学習データに織り込みたい場合など例外はあると思います。\\n\\n経験則としてはこれとの戦いな所がある気がしますねw\\n\\n特に自分が扱う時系列は需要予測とかが多いので、消費構造とかビジネス構造自体が変わるので。', '```経験則としてはこれとの戦いな所がある気がしますねw```\\n&gt;なるほど。むしろ例外ではないんですね。\\n私の場合は実務でapplyを始めてから期間が短いのであまりこの被害を被ったことがないのですが、モデルのupデートのタイミングや学習に使う期間などめちゃくちゃ難しそうですね...。ドメインによっても変わりそうだし。参考になります。', '時系列モデルは何回かやったことあるのですが、考慮する要素が多く、サンプルが少なく、構造が変化するなどモデリングの難易度かなり高いですね・・・', 'う〜ん。村上さんも難しいのですか...。以前練習で時系列データをstanで階層ベイズ頑張ったんですが、職人芸としか思えませんでした。RNN(LSTM)も職人芸とした思えませんでしたし、多変量の時系列問題はそもそもかなり難易度が高いような気がしてます。最終的にはlag変数を作ってGBDTでなんとかしに行っちゃいますね。', 'ドメインによって考慮する内容も全然違いますし、職人芸ですねw\\n\\nドメイン知識フル導入して鉛筆ナメナメしてる人達の予測値に勝つのが難しいんですよ・・・', '培われて来た現場の感と経験に対するリスペクトが増すので、KKDとか馬鹿にできないです・・・', '逆に言えば現場感がある方々がデータ分析出来るようになると、めっちゃ強いってことでもありますね！', 'ですね。そういった現場でこそ、データ分析の民主化の重要性はすごく感じますね。', '<@US2HKDVSL> 簡単に作ってみました。xbgをはじめとするよくある教師あり学習アルゴリズムの図解です。違う行のデータの影響を鑑みることができないので、並び順の構造が壊れても問題ありません。\\nただ村上さんご指摘の通り、学習期間により分布自体が異なることを織り込みたい場合はこの限りではありません。', '図まで作っていただき本当にありがとうございます！恐縮です:bow:\\nおかげさまで理解できました。\\n&gt; 学習期間により分布自体が異なることを織り込みたい場合はこの限りではありません。\\nこのへんが私の中で理解が十分でなかった気がします、勉強します！\\nまた違うことでも質問すると思いますが、またよろしくおねがいします！', 'いえ、とんでもないです！私がわかることも少ないですが、ぜひ気軽に聞いてください！')\n",
      "('K.FUKUHARA',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "('pandas',)\n",
      "('こんばんわ。pandasのconcatにおけるパラメータsortが読み込まれないバグに遭遇しました。緊急性は低いのですが、もし関係する情報があれば教えて頂きたいです。',)\n",
      "('エラーの対象箇所に関するコードなどあると、回答しやすいかと思います～♪', 'なるほど。あとで追記します。')\n",
      "('maimai',)\n",
      "()\n",
      "()\n",
      "('最初からてんこもりにすると続かなくなってしまうので（今もGAいれてるけど全く分析していないようで…）\\n本当最初は自然検索を増やすにしてみます。\\nそのためにもカスタマージャーに書いてみますね♪\\nいつも相談にのってくださりありがとうございます。\\n\\n施策増やして様子を見たりまでいくまで半年～1年で見ていきます。',)\n",
      "('レスする場所間違えました；\\n失礼しました＞＜',)\n",
      "('ｹﾛﾏﾂ',)\n",
      "('こ ろ ん', 'Katsuya Nagano', 'shimizu.yohei', 'Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('可視化', '統計', '回帰分析', '前処理')\n",
      "('重回帰分析の結果を、統計を知らない人に説明する際の可視化方法ってなにかありますか？\\n質問がアバウトで申し訳ないです。',)\n",
      "('重みのプロット', '具体的にどんなプロット？', '横軸が重みで縦が実数', 'うーん、なるほど？', '変数が多くて可視化できんくて困ってる系？', 'そうそう', '各パラメータの寄与率をプロットするのがいい気がしてきた', '目的によるのでなんともですが、ただただ各変数の寄与(係数の大きさ)を見せたいのであれば係数に応じたヒートマップとかは直感的に値の大きさわかりますね', '各変数で「係数÷係数の和」を出して、\\n上位の変数を使って「ここらへんの変数（パラメータ）が結果に大きく関係してそうです」\\nというのはいかがでしょうか？\\n（変数を標準化したりする前処理も必要だと思いますが）', '<@UPR6BE9S6>\\nなるほどです！ヒートマップはわかりやすいかもしれないです！\\n目的による、とゆう部分をもう少しご教示願えないでしょうか？', '<@UR7A5CJNA>  \\n目的変数への影響度とゆうことですよねっ？\\nやっぱり寄与率とか標準回帰係数を見せるのがよさそうですよね、\\nありがとうございます！', '変数はいくつぐらいあるんですか？', '<@UREUHGVAQ> \\n10個です！', 'なるほど。相手側のリテラシーなど状況にもよるのですが、変数を種類で分けてあげると伝わりやすい場合がありますね。差し支えなければどのような変数を使っていますか？', '例えばですが、何か顧客分析系なら、\\n顧客属性系の変数、と行動系変数に分けて説明するとか。例えばそんなイメージです。', '<@UREUHGVAQ> \\nなるほどです！！\\nそれは伝わりやすそうです。\\n変数名は確認中ですが、種類に分けて説明はできそうです！ありがとうございます！', '目的や変数量よっては見せ方、手法が変わるので気になった感じです。\\n例えば、100とかあるなら上位だけ見せるとかLASSOで絞り込んどくとか。あと気になりそうな変数や、介入が可能そうな変数だけにするとか。\\n\\n10個もそこそこ多いので、統計あまり詳しくない人だと全情報渡すのでなく、必要そうなものだけに絞った方が伝わりやすいとかもです。\\nあと、入れる変数によっては真の係数の正負が逆転した結果になったりもするので必要かつ信用できる値だけでもいいんじゃないかなーと。p値が云々とか言っても伝わらないでしょうし。\\n', '<@UNJD36PFG> あと参考にならないかもしれないんですが、個人的には編回帰係数を棒グラフやヒートマップであまり表現したくない派です。（でも結局やるんですが…。）\\nそれぞれの編回帰係数間で意味が違うものを比べて値が大きいものを重要であるかのように錯覚させたくない意図があります。\\nさらに、施策を打って改善したい説明変数があった場合に、1単位だけ向上させるための「コスト」も異なるはずなので「並べて比べるのは無理があるよな〜」と思っちゃうタイプです。', '&gt; それぞれの編回帰係数間で意味が違うものを比べて値が大きいものを重要であるかのように錯覚させたくない意図があります。\\nこれはあまりやらないですね。大小が重要という訳でもないので、p値と、Rの出力してくれる `**` や `*` などを記載して、「 `*` が付いている部分が重要な変数です」というような書き方をすることが多いですかね。', '（共線性が無いことなどは事前にチェックしたり、ステップワイズで変数選択したりした上でです）', '細かい話なので、読み飛ばしてもらってもよいです。\\n\\ny = a x1 + b x2 + c x3 のとき、興味があるのは x1,x2が1増加したときのyへの効果。\\nx3はコントロールのために置いてるだけで、興味がない(あるいは、性別みたいに試作で動かしようがないもの)場合は、a,bは正しい推定値の必要はあるけどcは間違っててもいいんですよね。\\nなので、そういう目的のときは誤った推定のcも含めて可視化はすべきじゃないんですよね。cはいらない上に、誤ってるから。\\n\\nちなみに、これはa,bと誤差項への相関(共線性)やaとbの相関はないけど、cは誤差項との相関がある。みたいなときに起きます。\\n\\n誤差項は、真の関係を示す線形モデル\\ny = a x1 + b x2 + c x3 + d x4 + e x5+ ...\\nのうちx1 x2 x3以外の要因変数(x4,x5...)の影響+ノイズのことを指します。\\n')\n",
      "('ｹﾛﾏﾂ',)\n",
      "()\n",
      "()\n",
      "('<!channel> ',)\n",
      "()\n",
      "('sho.kumada',)\n",
      "()\n",
      "()\n",
      "('Pandasの使い方について質問させていただきたいことがあります。\\n\\ndf と言うデータフレームがあり、“kcal” , “name” , と言う名前のカラムを持ちます。\\n “kcal” が平均値より大きく、“name”が“豚肉の生姜焼“である“kcal” , “name”カラムの値は以下の書き方で取り出せました。\\nこれをdf.queryを使って書くとどうなりますでしょうか？df[‘kcal’].mean()の箇所の表現が分かりません。\\nqueryを使った方がシンプルに書けるので積極的に使って行こうと思った矢先ぶち当たりました。。\\n\\ndf.queryを使わずに書いたコード○\\n```df[(df[\\'kcal\\'] &gt; df[\\'kcal\\'].mean()) &amp; (df[\"name\"] == \"豚肉の生姜焼\")][[\\'name\\', \\'kcal\\']]```\\n書いてみたがダメだったコード:heavy_multiplication_x:\\n```df.query(\\'kcal &gt; df[\\'kcal\\'].mean() &amp; name == \"豚肉の生姜焼\"\\')[[\\'name\\', \\'kcal\\']]\\n\\n  File \"&lt;ipython-input-34-424001f53be9&gt;\", line 1\\n    df.query(\\'kcal &gt; df[\\'kcal\\'].mean() &amp; name == \"豚肉の生姜焼\"\\')[[\\'name\\', \\'kcal\\']]\\n                            ^\\n  SyntaxError: invalid syntax```\\n',)\n",
      "()\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('```kcal_mean = df[\\'kcal\\'].mean()\\nquery_str = \\'kcal &gt; {kcal_mean} &amp; name == \"{name}\"\\'.format(kcal_mean=kcal_mean,name=\\'豚肉の生姜焼\\')\\ndf.query(query_str)[[\\'name\\', \\'kcal\\']]```',)\n",
      "()\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('即席なので汚いですが',)\n",
      "()\n",
      "('sho.kumada',)\n",
      "('Hiroyuki.Tachikawa',)\n",
      "('pandas',)\n",
      "('早速、ありがとうございます！.formatを使うんですね。初めて知りました。。\\n\\n一文で書くと以下のようになりますね。df.queryを使わずに書いたコードより複雑になっているようなので、\\nqueryを使って簡素になるかどうかはケースバイケースと言うことですかね。\\n```df.query(\\'kcal &gt; {} &amp; name == \"{}\"\\'.format(df[\\'kcal\\'].mean(),\\'豚肉の生姜焼\\'))[[\\'name\\', \\'kcal\\']]```\\n',)\n",
      "('<@UMQ7CDJUR> \\nこういう記述方法もあるみたいです。\\n<https://qiita.com/c_c_c_c/items/f7ed474caf1dcc02f33f|https://qiita.com/c_c_c_c/items/f7ed474caf1dcc02f33f>', '情報ありがとうございます！\\n@で変数を指定できるとは。。便利ですね。\\n簡略化できる表現でも、可読性を優先して、あまり知られていない表記は避けた方が良いんですかね？今回の件とは別に一般論の話です。', 'そうですね。まぁ状況にもよるので一意には言えないとは思いますが、私の個人的な目安は、書いてあること(変数名や関数名など含む)と意味が一致しているかどうか、を考えて書き方を選んでますね。\\nその意味で@は意味が幅広いのであまり用いたくないかも。', '確かにデコレーターでも使うし、知らないと初見戸惑うかもしれませんね。この使い方は。', \"ですね。\\nお会いした時の話ですが、だいたい以下のような感じで書くことが多いです。\\nage_over35 = df.age &gt; 35\\nmale = df.sex == 'male'\\ndf[(age_over35)&amp;(male)]\", '↑あくまで私の場合は。なので一般にどうかと言われると自信ありません。。。', 'なるほど、そいう風に書くんですね！読みやすい！\\nめちゃくちゃ参考になります。\\n確かに、age_over35の中はbool値ですね', 'はい。bool値のリスト構造になってます。', 'またまた、pandasでお聞きしたことが、、\\n下のようなデータフレームで同じ週（日曜〜土曜）の行に存在する店番のユニーク数を数えたいのですが、どのようにしたら良いでしょうか？トータル209週あり、各週ごとに存在する店番のユニーク数を数えたいです。', '`week_2012_count = pd.DataFrame({\"週\":[i for i in range(1,54)],\"レコード数\":[\"\"]*53})`\\n`for i in range(len(week_2012_count)):`\\n    `week_2012_count.loc[i,\"レコード数\"]=sum(df[df.index.year == 2012].index.week == i+1)`\\n\\n上記のようにdf.index.weekで週ナンバー（１〜５３）をとって、1年ごとに数え上げていけばできそうですが、もっと簡単な方法がないものかと。。', 'こちらの質問の件はなんとか解決できました！')\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "()\n",
      "('ですね。かなり簡単な条件の時でないと意外と可読性が落ちちゃいますね。おしい。',)\n",
      "()\n",
      "('UR',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'はやと-休学中の文系学生')\n",
      "('初心者', 'BQ', 'kaggle', 'Python')\n",
      "('こんにちは！つい最近kaggleを始めて、過去のテーブルコンペを2つほどこなしたのですか、画像コンペってものに、勉強がてら手を出してみたいと思ってます。\\nそこで、初心者におすすめの過去コンペ、並びに参考書（本/記事/チュートリアルなど）はありますでしょうか？\\nテーブルコンペを始める際は、タイタニックのデータはわりと身近でわかりやすかったですし、解説記事や本も多く出回っていて、すごくとっつきやすかったですが、画像コンペはもう最初に何をすればいいのかすらよくわかりません。。\\nみなさんの知恵を貸してください！お願いいたします:hugging_face:',)\n",
      "('<@UKT5BQD3P>\\n画像コンペのおすすめとかってあります？', '<@URXPGQ7U3> \\nDog catの分類のやつが一番おすすめです！', '僕も実際に手を動かしたわけではないですけど意見をちらほら見ます', 'ありがとうございます！\\nもしあればですが、初心者におすすめの本や動画はありますか？？\\n英語でも良いです(^^)', '本ですと、kerasが一番画像は直感的に扱ってるんでいいと思います、僕が使ったのは下のリンクのやつです', '<https://www.amazon.co.jp/Deep-Learning-―Python×Kerasでアイデアを形にするレシピ-Antonio-Gulli/dp/4873118263>', '理論はあんまり書いてないので、理論を知りたいなら0から始めるとかが良いのかなって感じです〜', 'ありがとうございます！Kerasってのか良いんですね！勉強してみます。', 'あ、0から始めるっていうのは0からはじめるdeep learningってことです')\n",
      "('ｸﾛ\\u3000京大医学部3年',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '吉村政彦ｰ産業ｽﾊﾟｲ', '澤祐斗\\u3000東工大3年', 'sho.kumada', 'すずきしげお', 'UR')\n",
      "('統計', '統計検定', 'AR', '入門')\n",
      "('統計検定1級を持っている方に質問です\\n\\n現在、1級を目指して勉強しているのですが、どのような勉強をしたのか教えていただきたいです。\\n\\n現在、東大出版の統計学入門(通称赤本？)を読み終えて、おそらく2級範囲はカバーできています\\n\\n自分では\\n・本を買ってさらに勉強を進める\\n・過去問を解いてわからなかったところを調べながら勉強する\\nというやり方を考えています。皆さんのご意見を聞きたいです\\n',)\n",
      "('統計検定持っている方は<@URXPGQ7U3> さんですかね！\\n\\n勉強されてる方だと、\\n\\n<@UMQ7CDJUR> <@URRKHGARX> <@UL08YKGLU>\\n 辺りですかね！勉強されてる方の勉強方法も参考になると思うので、是非シェアして頂けると！', '俺も総務省のオンラインのやつ（gacco）で統計の勉強するぞ！(*￣0￣)/ オゥッ!!\\n\\n今年はやる事一杯で忙しいなぁ・・・でも頑張る！(*^_^*）', '自分は、1球合格した先輩の勉強法を参考にしてますが\\n・試験範囲を勉強する\\n・過去問解く\\n・分からない分野深掘りする\\nなので、割とクロさんの想定の勉強法に近いと思います〜', '新年会で<@ULM6FBU11> さんにアドバイスいただきました。\\n数理分野の話になります。\\n\\n記憶が正しければ、、\\n・確率分布間の関係や式、母数をさらで書いて説明できるようにする\\n以下のイメージです\\n<https://qiita.com/drken/items/089b8443305df047b44e>\\n・2級合格レベルから半年の勉強でOK（実質は最後の2ヶ月で追い込む！）\\n・教養過程の積分問題をバリバリ解く（重積分に苦手意識なくなれば、勝負できる）', 'よく合格者のブログなどにあるこれやってます\\n\\n\\n現代数理統計学の基礎 (共立講座 数学の魅力) <https://www.amazon.co.jp/dp/4320111664/ref=cm_sw_r_cp_api_i_OoJjEbCXZWEM8|https://www.amazon.co.jp/dp/4320111664/ref=cm_sw_r_cp_api_i_OoJjEbCXZWEM8>', '数理のみの合格ですが、ご参考になれば:grin:\\n（応用は、選択分野に大きく依存するので割愛）\\n\\n上記でも紹介されていますが、私も共立講座の現代数理統計学の基礎を使いました。\\n過去問をすでに解いているとのことですので、もしまだ歯が立たないのなら、赤本以外に手を出したら良いと思います。\\n2014/2015の過去問は他の年よりも難しいので、この2年が解けたら準備万端だと思います。\\nあとは、スピード感を身につけることと、計算ミスを減らすことも念頭に入れて練習すれば、本番で悔しい落ち方はしないはず！', '確率分布曼荼羅いいですね。関係性知っていると計算時間が全然変わりますよね', 'その通りですね。去年の問題だと、指数分布とガンマ分布の関係性を使えば、大問一つ一瞬で終わりますね笑', 'みなさんありがとうございます！')\n",
      "('しみずこうじ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'はやと-休学中の文系学生', 'Katsuya Nagano')\n",
      "('BQ', 'kaggle', 'signate')\n",
      "('初級〜中級くらいのスキルでKaggleに挑む前提で、タイタニックは鉄板としまして、その他何がオススメでしょうか？:pray:\\n\\nチームを組んでやりやすいもの等もあると大変助かります！\\n\\nお手数おかけいたします、どうぞよろしくお願いいたします:man-bowing:',)\n",
      "('<@US69FTTH6> \\nタイタニック、犬猫判定とかですかねー！\\n\\n結構頻出なので、流れやオススメコンペ、まとめておきたいですね。', 'おお、これは失礼しました！:man-bowing:', 'テーブルなら昔のだとhouse priceがいいですね、タイタニックが分類だとすると住宅価格は回帰の問題です', 'でも、チーム組むなら今現在開催してるものなので、確かテーブルコンペは無かったかもしれないです、、、', '基本参加人数が多いコンペはとっつきやすくて人数多くなってるやつが多いです', '<@UKT5BQD3P> ありがとうございます、仲間内のお試しなところもありますので、今やっているものだけでも問題ございません！', 'なるほど、その観点で見ていけばよいのですね！', 'house priceで感覚掴んでからチームで出るとかが良いですかね？', '今の段階だとsignateかkaggleでテーブルコンペ来るまで待ってそれで良いと思います〜！', '不動産コンペ的なのを昔誰かにおすすめされたような（ちゃんとした名前じゃなくてすみません\\n\\nただ、はやとさんがおっしゃるように開催されているコンペにスタートから参加した方がやりやすそうです。\\n- 公開notebookに強いやつ出る→みんなそれベースでやる\\n- ディスカッションが徐々に深化していく\\nみたいな流れを追ってやれるので', 'なるほど、ありがとうございます！\\n差し支えありませんでしたら、Googleドキュあたりにまとめて、トピックに貼っても大丈夫でしょうか？', 'なるほど、やはりリアルタイムで進んでると熱量があって良さそうです！\\n自分たちへのプレッシャーにもなりますし笑', 'ギルドのscrap boxがあるので、それが良いかもです！', 'おお、なるほど！\\nscrapbox？', 'これですかね、私でも編集できるんでしょうか\\n\\n<https://scrapbox.io/dl-guild/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%82%AE%E3%83%AB%E3%83%89%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B%EF%BC%9F|https://scrapbox.io/dl-guild/%E3%83%87%E3%83%BC%E3%82%BF%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%82%AE%E3%83%AB%E3%83%89%E3%81%A8%E3%81%AF%E4%BD%95%E3%81%8B%EF%BC%9F>', 'これはギルド内の共有に便利そうです！ありがとうございますー\\n\\n<https://scrapbox.io/product|https://scrapbox.io/product>', '編集できますー！', ':raised_hands:', 'いただいた情報に＋αしてまとめてみました！\\n<https://scrapbox.io/molt/Kaggle_%E5%88%9D%E7%B4%9A%EF%BD%9E%E4%B8%AD%E7%B4%9A%E3%81%8A%E3%82%B9%E3%82%B9%E3%83%A1%E3%82%B3%E3%83%B3%E3%83%9A>')\n",
      "('ﾋﾛﾘｰ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'Katsuya Nagano', '吉村政彦ｰ産業ｽﾊﾟｲ', 'maimai')\n",
      "()\n",
      "('このギルド内で利用できる絵文字を自社にも入れたいのですが、どの絵文字セットを入れたのでしょうか？\\nインポートしたのは <@UJRAL005U> さんでしょうかね\\nこれでしょうか？\\n<https://github.com/decomoji/slack-reaction-decomoji>',)\n",
      "('最初のいくつかは自分で作って、大量に入れたのは<@UPR6BE9S6> さんですね！', 'なるほど!ありがとうございます！\\n意識低い系チャンネルでの絵文字楽しいなと感じまして！', '会社に昔ぶち込んだセットなので、それをどこから取ってきたかはぶっちゃけ忘れました。\\nネットでだれかが自社用にやっていたやつだった気がします（なので渋谷ネタが多い）\\n↑のサイトはそれベースでプラスアルファされたやつなんじゃないすかね', '<@UPR6BE9S6> \\u3000レスありがとうございます！\\nそうなんですね！\\nemojiレパートリー自社用に育てていくの面白いですね〜\\u3000:point_up_2:のやつベースに絵文字文化育てていきます！', '現場猫のヤツは僕が入れました(^m^)', '<https://zk-phi.github.io/MEGAMOJI/>\\nとかを会社で全体共有しておくと、各自でemojiを勝手に作ってくれるのでよいです。\\nただ、モラル的にあれなのが大量発生したら偉い人に怒られるので注意を。', 'ここで使われてる絵文字URLから保存して自社のslackに入れさせていただきましたｗ', 'あと都度絵文字作ってますね…治安悪いジェネレータにはお世話になってますｗ')\n",
      "('ｱﾗﾝ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '吉村政彦ｰ産業ｽﾊﾟｲ', 'すずきしげお', 'Katsuya Nagano', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('統計', 'データサイエンティスト')\n",
      "('初めて質問させていただきます。\\n\\n就職活動において、映画業界をデータサイエンティストとして分析したいのですが、この際データとかはどこから引っ張ってこれるのでしょうか？自分でデータ収集すべきでしょうか？(周りの人にアンケートを頼む)\\n\\n例えば、君の名はが日本でもヒットし、海外でもヒットした要因を分析しようと思っています。\\n\\n面接やエントリーシートにおいてデータサイエンティストとしての将来性を語る際に重要なこととはなんでしょうか？\\n\\nなんでもいいので意見がほしいです。\\nよろしくお願いします。',)\n",
      "('よろしくお願いします！！\\n\\n現在就活中で、映画業界におけるデータ分析を自分でやってみたいという感じでしょうか？', '公表されているデータベースとかだと、ここら辺ですかね？\\n<http://www.eiren.org/toukei/index.html>', '映画業界に興味があり、映画オタクとは違う目線を持ちたいと思っています。多くは一般職で文系理系問わないので、自分の分野であるデータサイエンスを武器にしたいとおもっています。そのため、データ分析を自分でやってみようと思っています。', 'ありがとうございます。', 'そのステータスだと、まずは一般的な業界に関する統計情報とか、リサーチのレポートとか読むのが良さそうですね！\\n\\n既に色んなアプローチで調査がされてるはずですので、何がやられていないかを調べてみるのが良いかと！！', 'なるほど、とらいしてみます。', '<https://research.nttcoms.com/database/data/002109/>', '例えば、イメージとしてはここら辺ですかね？\\n\\n簡易なアンケートは既に取ってあったりするので、こういうので業界の理解は深まるかと思いますー！', '自分が新しい業界の分析をするときも、まずはこういう感じの調査機関が出している統計を探して肌感をつけるところからスタートするので、まずは色々調べてみると良いかと思います！', '|柱|`.w´)ﾁﾗﾘ・・・', '<@UN0HCK74M> \\nあ、データ持ってる人いましたねw', 'なにとぞ... お願いします', '<@UJRAL005U> \\nまだ入手（生成）はしてない。方針として提案中（無理矢理首を縦に振らせる予定w）\\n\\n<@URTLUNZ3K> \\n業界レベルではなく、映画館単位での取り組み（事業再生）なので、分析用の教師付データの「生成ツールから作成」段階だけど、興味あるなら「貴重な体験の提供（超意味深w）」を検討しないことも無い(^m^)', '国の統計はこういうのがあったりします。(私は入札〜納品まで関わってました..)\\n他にもここで検索すると国の統計で映画系はどんなのあるかなーってわかります\\n\\n\\n<https://www.e-stat.go.jp/stat-search/database?page=1&amp;layout=dataset&amp;stat_infid=000031439108&amp;statdisp_id=0003155601|https://www.e-stat.go.jp/stat-search/database?page=1&amp;layout=dataset&amp;stat_infid=000031439108&amp;statdisp_id=0003155601>', '映画でデータサイエンスといえばNetflixですね。調べてみるといいかもです\\n\\n<https://japan.zdnet.com/article/35146712/|https://japan.zdnet.com/article/35146712/>', '確かに、コンペとかやってましたもんね！', 'おお・・・俺にとっても棚からぼた餅（この場合ひょうたんから駒では無い）な展開(^m^)\\n\\nいゃあ〜DLGに入って良い事ばっかりだなぁ(*￣m￣)ﾌﾟｯ', '昔映画の興行収入分析したときは、データは配給会社からもらいましたけど、興行収入や館数とかはスクレイピングでいける気がします。\\nあと、メタ情報として出演者や、出演者自体のメタ情報はwikipediaクローリングして抜いてましたね。\\nデータの話ではないですけど、netflixがどういう情報をどうやって分析しているかとかはnetflixブログやそういう海外記事とかにある気がします（調べてないけど、国内には当時あまり情報なかった', 'ネトフリテックブログ\\n<https://netflixtechblog.com/>', '動画業界ですけど\\u3000インターンはないかなw', '盛・り・上・が・っ・て・参・り・ま・し・た！(笑', '映画産業自体の構造がいろいろあるのとデータが必ずしも正しくないのですがその辺を覆したのがネットフリックスなんで面白い世界ですね。\\n')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'chan')\n",
      "()\n",
      "('XGBoostからLightGBMに乗り換えたのですが、列名が日本語のものは使えない問題（Pandasでrenameしたら大丈夫でした）は通常のことなのでしょうか？\\n列内の要素はcategoryで英語は使えていますが、日本語は未検証です。',)\n",
      "('label encoderとか噛ましたら行けないですかね？', 'あ、値ではなく、列名でしたか。。。', 'LGBMはカラム名に日本語NGで、出くわしたときいつもめんどくせえと思ってますw', 'そ、そうだったのですね！ありがとうございます！')\n",
      "('しみずこうじ',)\n",
      "('yuji.imuta', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'Kanai', 'ｼﾞｭﾝﾃｨｰ', 'Katsuya Nagano', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('SQL', '入門', '初学者', 'BigQuery', 'ビッグデータ', '入門書', 'AI')\n",
      "('既出の質問かもしれませんが、SQLを学ぶのに良い教材はありますでしょうか？\\nProgate、StartSQLをやって、データ数が多かったり、より複雑な多重入れ子のSQLを練習したいなぁという気持ちになりました、どうぞよろしくお願いいたします:man-bowing:',)\n",
      "('ビッグデータ分析・活用のためのSQLレシピ <https://www.amazon.co.jp/dp/4839961263/ref=cm_sw_r_cp_api_i_sBSkEbWAKW7K5|https://www.amazon.co.jp/dp/4839961263/ref=cm_sw_r_cp_api_i_sBSkEbWAKW7K5>\\n\\n\\nこの本めちゃくちゃオススメです！', 'その本気になってました！\\n買ってみます:blush:', 'いいですけど初学者には辛いです\\nミックさん、Arbert 分析、レシピ(黒魔術)の順番がオススメです', 'なるほど……！', 'Albert\\n<https://www.amazon.co.jp/%E3%83%87%E3%83%BC%E3%82%BF%E9%9B%86%E8%A8%88%E3%83%BB%E5%88%86%E6%9E%90%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AESQL%E5%85%A5%E9%96%80-%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BEALBERT-%E5%B7%A3%E5%B1%B1-%E5%89%9B/dp/4839951519|https://www.amazon.co.jp/%E3%83%87%E3%83%BC%E3%82%BF%E9%9B%86%E8%A8%88%E3%83%BB%E5%88%86%E6%9E%90%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AESQL%E5%85%A5%E9%96%80-%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BEALBERT-%E5%B7%A3%E5%B1%B1-%E5%89%9B/dp/4839951519>', 'ミックさん\\n\\n<https://www.amazon.co.jp/%E9%81%94%E4%BA%BA%E3%81%AB%E5%AD%A6%E3%81%B6-SQL%E5%BE%B9%E5%BA%95%E6%8C%87%E5%8D%97%E6%9B%B8-CodeZine-BOOKS-%E3%83%9F%E3%83%83%E3%82%AF/dp/4798115169|https://www.amazon.co.jp/%E9%81%94%E4%BA%BA%E3%81%AB%E5%AD%A6%E3%81%B6-SQL%E5%BE%B9%E5%BA%95%E6%8C%87%E5%8D%97%E6%9B%B8-CodeZine-BOOKS-%E3%83%9F%E3%83%83%E3%82%AF/dp/4798115169>', '<@UL2TY2ERL> こちらのことでしょうか？:man-bowing:', 'です', 'ありがとうございます！\\nミックさんから攻めてみます！', 'ミックさんは入門書なので立ち読みして理解できているなら飛ばして良いです', 'なるほど、サンプルダウンロードしてみてます！', 'リンクのミックさんの本は第二版がでているはずです。ご参考までに', 'おお、ありがとうございます:man-bowing:', 'はじめまして！\\n初学者には、\\n“スッキリわかるSQL入門” が最良かなと思います（<https://www.amazon.co.jp/スッキリわかるSQL入門-第2版-ドリル222問付き-スッキリシリーズ-中山清喬/dp/4295005096/ref=sr_1_1?adgrpid=51361540737&amp;gclid=EAIaIQobChMIgtii4IWc5wIVGamWCh0xGAvaEAAYASAAEgLQjPD_BwE&amp;hvadid=338518033641&amp;hvdev=c&amp;hvlocphy=1009293&amp;hvnetw=g&amp;hvpos=1t1&amp;hvqmt=e&amp;hvrand=9839639832054109971&amp;hvtargid=aud-759377471933%3Akwd-333587866250&amp;hydadcr=27265_11561133&amp;jp-ad-ap=0&amp;keywords=%E3%82%B9%E3%83%83%E3%82%AD%E3%83%AA%E3%82%8F%E3%81%8B%E3%82%8Bsql%E5%85%A5%E9%96%80&amp;qid=1579862317&amp;sr=8-1>）\\n\\nその後に、黒魔術書を読む流れが、ベストかと思いますm(__)m', 'はじめまして、おおなるほど、色々本があるんですね:blush:\\nありがとうございます！', '自分にとっては、ダントツで分かりやすかったので、ご検討いただけますと幸いです(^^)/', 'とりあえず全部サンプルダウンロードしてみます！\\nありがとうございます:man-bowing:', '実案件で直面するめんどくさいことを実現したいSQL系は一般化しづらいからかレシピがあまりなく、論理思考でがんばるしかないのでどうしたらいいんでしょうね。例えばこういうやつ（自ブログに昔テキトーに書いたやつ\\n<http://knknkn.hatenablog.com/entry/2018/05/05/164824>', '<@UPR6BE9S6> おっしゃるとおり、少し触った印象、エクセルと同じで、実際に触ってナンボの印象ありますよね。\\nデータベース好きなだけ触れる環境が欲しいな……と思いました', '中身軽くしか見てないですが、これとかパズル的な感じでめんどくさい集計を論理的思考力使って解かせるので実績力がつくかも？\\n<https://www.amazon.co.jp/SQL%E3%83%91%E3%82%BA%E3%83%AB-%E7%AC%AC2%E7%89%88-%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%81%8C%E5%A4%89%E3%82%8F%E3%82%8B%E6%9B%B8%E3%81%8D%E6%96%B9-%E8%80%83%E3%81%88%E6%96%B9-%E3%82%B8%E3%83%A7%E3%83%BC%E3%83%BB%E3%82%BB%E3%83%AB%E3%82%B3/dp/4798114138>', '<@UL2TY2ERL>\\nALBER分析、レシピの著者から共に直接教えて頂いたので、そりゃSQL書けるようになるわなと改めて思いましたｗ', '入門としては10年戦えるのやつがおススメすすめです！（10年の折り返しすぎたけどｗ）', '色々あるんですね、ありがとうございます！', 'さすがです。\\n最近、365日分の分析書くの面倒で、365行のクエリ書いたりしています。（サブクエリをUNIONする）', '数十件のマスタデータであれば、INSERT分をEXCELで生成して入力したりするので、そんなノリですねｗ\\n\\n分かりますｗ', 'SQLってエクセル取り込めるんですね', 'COUNT( start_date &lt;=login_date AND DATA_ADD(start_date,INTERVAL n day) &gt;login_date or null) AS day_1day_agg  な感じでひたすら書いたりw', 'あ、いや、普通にやると\\n\\n１．csv変換\\n２．ファイルをサーバにアップ\\n３．SQLからインポート\\n\\nとかの手順でやるのですが、 `INSERT INTO` を使えばSQLで直接変換できるので、\\n\\n１．EXCELで文字列としてSQLのクエリを作成\\n２．SQLのクエリとして実行\\n\\nという手順でインポートするって感じですね！', 'BigQueryはSpreadsheet直接読み込めたりします。', '&gt; EXCELで文字列としてSQLのクエリを作成\\nあるあるすぎるｗ', '<@UJRAL005U> おお、ありがとうございます:blush:\\n自作にもチャレンジしてみます！', 'あるあるなんすね笑', '<@UPR6BE9S6>\\n状況によっては数倍早いですよねｗ', 'マスタデータは大体EXCELでもらいますしｗ', '実務の流れ、勉強になります！笑', 'INSERT hoge ( SELECT * FROM fuga WHERE date AAA BETWEEN BBB)\\n\\nみたいなのを大量の期間おこなう場合。\\n\\nAAAとBBB期間をExcelに縦に書く。それぞれA列、B列とする場合、C列の1行目に\\n“INSERT hoge ( SELECT * FROM fuga WHERE date ” &amp; A列 &amp; “BETWEEN ” &amp; B列 &amp; “)”\\nを書いて下行に伸ばすと、期間に相当する部分にA列B列の内容が自動で入るのであとはC列をすべてコピペしてSQL流す\\n\\nみたいな感じっす', 'やっぱみんな似たようなことしてるんですねw', '皆さまありがとうございます:blush:\\n\\nスマホだとscrap boxがうまく操作できなかったので、とりあえずGoogleドキュにまとめてみました、\\nオススメ本を一通り見て、買ってみようと思います！:raised_hands:\\n\\n<https://docs.google.com/document/d/10KhXtXVvewvY_S5fOAB0Na3N13mdSLkNHzwt8vbHXKs|https://docs.google.com/document/d/10KhXtXVvewvY_S5fOAB0Na3N13mdSLkNHzwt8vbHXKs>', 'Scrap Boxに差し替えてみました！\\n<https://scrapbox.io/molt/SQL%E3%81%8A%E3%81%99%E3%81%99%E3%82%81%E5%AD%A6%E7%BF%92%E6%B3%95>', '<@US69FTTH6>\\nありがとうございます！！ギルドのscrap boxがあるので、共有しておきますねー！\\n<https://scrapbox.io/dl-guild/>')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "()\n",
      "('最近、CASE分でStart_dayとend_dayを挟み込んで期間を変えた集計する手法ばっかり書いている。',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('<@UJRAL005U> 節々にワードを耳にして気になってたのですが、村上さんの分析講座ってなんでしょうか？:raised_hands:',)\n",
      "('プライベートチャンネルで、この1月からデータ分析の講座をやっていますー！！', 'おお、途中参加とかできる感じですか？', '途中参加ですか〜！可能ではあります！', '動画受講がメインになってしまいますが・・・', '大丈夫です！\\n簡単にググって見つからなかったので公開されてない感じでしょうか？', '個別にお送りしますねー！', '今は非公開です！！', '承知しました！')\n",
      "('Komiya',)\n",
      "('yuji.imuta', 'Hiroyuki.Tachikawa', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析')\n",
      "('機械学習', 'データエンジニア', 'データサイエンティスト', '転職', 'AI', '統計', 'API', 'Python', 'ML', 'AutoML', 'kaggle', 'Slack', 'SQL')\n",
      "('機械学習分野への転職活動をはじめようと思っています。\\n実務未経験です。\\nもしよろしければ、アドバイスをお願いします。\\n（長くなるので詳細はスレッド内に続けます。↓）',)\n",
      "('# 聞きたいこと\\n自身の成長をプライオリティと考えた時、どのような企業への転職を目指すべきか。\\n\\n\\n# こんなやつ\\n    - 機械学習実務未経験\\n    - 前職フロントエンド開発\\n    - Javascript -&gt; 2年\\n    - Python -&gt; 半年(独学)\\n    - SQL  -&gt; 少しだけ\\n    - 数学 -&gt; 中高から勉強し直してるレベルです\\n    - 機械学習系のスクール修了\\n    - ３６歳\\n\\n\\n# やりたいこと\\nエンジニアリングに重心を置きつつ、分析スキルを身につけたい。\\nデータエンジニアにも興味あり。\\nコンサルティングがメインとなるのは避けたい。\\n\\n\\n# どんな企業がよい？\\n    - SES (数ヶ月間の研修の後、客先へ出向)\\n        - どこかしらには就職できそう\\n        - 出向先ガチャのリスクは考慮すべき？？\\n        - 研修があった方がその後の成長は早い？？\\n\\n    - 自社で分析の受託やサービス開発をやっている企業\\n        - 難易度高そう\\n        - 人のレベルは高い？？\\n\\n\\n現状ではスキルが全然足りていないので間口の広いSESへの就職を目指し、実務経験を積んでから次のステップアップを考えるのが良いのかなと思っているのですがどうでしょうか？\\n上記以外の選択肢などもあれば伺いたいです。\\nちなみにPythonで作ったツール（BOT、スクレイピング、コマンドラインツールなど）やコミュニティ内コンペのSlack分析、Kaggleの銅メダルなどを実績として転職活動しようと思っており、未経験可のSESであればどこかしら入れるのでは無いかと考えています。\\n\\nいろいろな方からのご意見伺えるとうれしいです:man-bowing:', '僕は、SESで機械学習エンジニアやってますけど、案件ガチャがあるので、そこがちょっとネックです。\\n\\n\\n分析系の現場に行けるか、MLopsで機械学習には関わってはいるが、分析はできない、がっつりモデルを作ってるってところもあるので、、、ただ、SESの会社は研修が充実してる印象で、弊社もそれで研修は充実してました！', '<@UMG0947NY>\\n実際に働かれている方のお話、参考になります！\\nやはりガチャ要素は避けられないんですね。\\nやりたい分野の勉強をつづける &amp; 希望を伝えることで、多少緩和されるようなイメージでしょうか。\\n\\nSESだとプロパーに比べて裁量が小さくなるのかなと思うのですが、このあたりでデメリットをお感じになることとかってありますか？', '<@UN1V4ELKV> さん\\n多分私と同じ歳か私の一つ上ですね。\\nちょっと気になったんですが、考えた選択肢はSES以外にないんですか？', '<@UREUHGVAQ>\\nご返信ありがとうございます。\\n同年代なのですね！\\nSESに限定しているわけではないのですが、実務経験ナシで入れる可能性が高そう + 研修制度に惹かれるという点で選択肢としています。\\nもしTachikawaさんが私のような立場であれば、どのような転職を目指されますか？？', '<@UN1V4ELKV> なるほど。確かにそのような側面はありそうですね。\\nKomiya さんと私とでは恐らくバックボーンや志向性が異なるでしょうから何とも言えませんが、機械学習を用いるならまずプロダクトを作るでしょうし、統計を使うならデータ取ってきてレポートを作ると思います。', 'あとはそれらをばらまいて条件の良いところを探す感じでしょうか。', '未経験からってほんとに難しいですよね。', '<@UREUHGVAQ>\\n&gt; 機械学習を用いるならまずプロダクトを作るでしょうし、統計を使うならデータ取ってきてレポートを作ると思います。\\n&gt; あとはそれらをばらまいて条件の良いところを探す感じでしょうか。\\nなるほどですね！\\n転職活動と並行してアウトプット増やしていきます。\\n\\n現職で活躍されている方のご意見が伺えて、とてもありがたいです:man-bowing:', '<@UN1V4ELKV> いえ。お役に立てたようなら嬉しいです。実は私も大学は文系、仕事も文系だったんですが大人になってから勉強して実務についたので、本当に勝ち取ってほしいなと思ってます。ぜひ頑張ってください！応援しています！また何かあれば、私でよければ何か役に立ちたいので気軽に聞いてくださいね。', '<@UREUHGVAQ>\\nTachikawaさんのバックボーンも少し伺えて、とても励みになりました！\\n相当な努力をされたんですね…。\\nありがたいお言葉、本当に感謝です。\\nよろしければまたご相談させて下さい:man-bowing:', 'データサイエンティストでモデルつくる感じですかね？\\n結構幅ひろくて難しいです。\\nよくある感じですが、結構データサイエンティストが、手あまりな感じもするんですよね。\\nうちのチームにいる人もデータの汚さが原因で業務が進まずそのへんからになるとデータサイエンティストよりもデータエンジニア必要だったりと・・・。', 'コンサルティング避ける意味でもデータエンジニアから入っていき、データサイエンティストのモデルのレビューアー（検定を聞きながらできればOK）だとニーズあるかな～と思います。トップデータサイエンティストのサポート役がほしいところ。そのへんの役回りまとめますね。（2月ぐらいかなw', '<@UN1V4ELKV> \\nやりたいことは言い続ける必要がありますね。ただ、最初からやりたいことさせず、苦労させてから、徐々にステップアップさせていくって方針もあったり、、、、\\n\\n\\nプロパーとの裁量は完全に現場によってまちまちです。現場の勉強会には出るなって場所もあれば、会議に出席したりする現場もあります。\\n\\n↑で増田さんがおっしゃってるように、データエンジニアの方が需要があると思います。SESだと、機械学習などがわからないけど、とりあえず機械学習やりたいからエンジニア派遣して。って話しがあり、行ってみると、データはなにもなくなんもできないってパターンもあります、、、、', 'そうするとデータプロジェ（ダ）クトマネージャーが必要になるとおもっていますが、SIerサイドに需要あるのかな～。', '<@UL2TY2ERL>\\nとても興味深いお話ありがとうございます!\\n\\n統計知識や分析能力は身につけたいと思っているのですが、\\nモデル構築に特化したスキルは避けたいと思っていて、\\n  - AutoMLによるリプレイスのリスク\\n  - アカデミックモンスターと同じ土俵で戦うべきではない\\nやはりこのあたりは気にして立ち回らないとなと考えています。\\n\\nなので教えて頂いた、\\n&gt; データエンジニアから入っていき、データサイエンティストのモデルのレビューアー \\nこのようなポジションはとても興味があります。\\nもしよろしければ、\\n*` データサイエンティストのモデルのレビューアー（検定を聞きながらできればOK） `* の内容を少し具体的に教えて頂けませんでしょうか？？', '<@UMG0947NY>\\n&gt; 最初からやりたいことさせず、苦労させてから、徐々にステップアップさせていくって方針もあったり、、、、\\nこれは恐ろしいですね...。\\n\\n裁量やリスクの件など現場の方しか分からないと思うので、非常に参考になります！\\nありがとうございます:man-bowing:', '<@UN1V4ELKV>\\n職種と、業種業態の領域を切り分けて考えるのが良いのかなと思います！\\n\\n■職種に関して\\nデータサイエンス周りでエンジニア中心でやっていく場合、\\n\\n・データエンジニア\\n・機械学習エンジニア（構築済みモデルを本番環境にリリースしたりする役割）\\n\\nというような役割があります。\\n\\nフロントエンドの領域と親和性が高いデータ周りの仕事だと、\\n\\nデータ分析に関するデータ取得に関するような領域の仕事（ビーコン実装やタグマネジメント）、フロントエンド側の機械学習のAPI実装（予測モデルから受けた結果を実装する）といった領域があるかと思います。\\n\\n未経験からのデータエンジニアに関してはなかなかハードルが高い部分があるので、経験がある領域で7割～8割、データ領域2割～3割といった形の仕事に就くのが良いのではないかと思います。\\n\\nAPIのフロントエンド側で、機械学習エンジニアと直接やり取りするような感じですね。\\n\\n\\n【業種・業態に関して】\\nある程度自分で\\n\\n■データをこれから蓄積していくフェーズの自社開発企業\\nなんでもやることになりやすいので、データ周りの仕事も手を挙げればやれる可能性大、ただし、教えてくれる人が身の回りにいる可能性は低い\\n\\n■機械学習システムなどが運用している自社開発企業\\nこちらは、そもそも会社数自体が少なく、求められる水準が高いので、合格するのはなかなか難しいと思います。\\n\\n■データ分析受託企業\\nSESか、受託かと大きく2パターンあるかと思います。\\n\\nSESの場合は客先常駐になってしまうので、案件ガチャが発生してしまいますが、受託会社の場合は社内での開発がメインになります。\\n\\nまた、分析官の方が身近にいるという所を考えても、受託中心の会社の方が良いのかなという印象は受けますね。\\n\\nSESが入りやすい気がしますが、フロントエンドの経験があるのであれば、案件がその領域に寄せられる可能性は高いのかなと思います・・・\\n\\nザっとではありますが、ご回答させて頂きました！', '<@UJRAL005U>\\nありがとうございます:man-bowing:\\nとてもわかり易くまとめて頂いて、いろいろとクリアになりました。\\n\\n&gt; SESの場合は客先常駐になってしまうので、案件ガチャが発生してしまいますが、受託会社の場合は社内での開発がメインになります。\\n&gt; また、分析官の方が身近にいるという所を考えても、受託中心の会社の方が良いのかなという印象は受けますね。\\nこのあたりは特に気になっていたので、とてもありがたいです！\\n受託会社、SES両方視野に入れて探したいと思います。', '<@UN1V4ELKV> \\n結局は、同僚・上司と業務内容に恵まれるかだと思うので、面接でその辺見極められるかがポイントだと思います！\\n\\nkaggleのメダルとコンペのレポートがあれば、未経験の実績としては十分かと！', '<@UJRAL005U>\\n&gt; 結局は、同僚・上司と業務内容に恵まれるかだと思うので、面接でその辺見極められるかがポイントだと思います！\\nなるほど。\\nこのあたりは可能な限り事前リサーチもやっていきます。\\nありがとうございます！', 'あと、面接の際に、データの集め方とか、基盤など、正解ラベルはちゃんとあるのか聞くようにしてました！', '<@UMG0947NY>\\n覚えておきます！\\n&gt; データの集め方とか、基盤\\nちなみに、この良し悪しはどのように判断されますか？\\nよろしければ良い企業の例、悪い企業の例など教えて頂けませんでしょうか？', '<@UN1V4ELKV> そうそう。Kaggle含めて機械学習系はオフラインイベントが色々ありますが、参加されたことあります？私は仕事の都合上イベントの時間帯が埋まってしまうことが多いですが、もし参加されたことがなければ行ってみるといいと思いますよ。\\nなかなか一般の公開求人から面接に進むと、一緒に働く人の様子が掴みにくいですが、そこでできた人脈からの採用なら、一緒に働く人たちの雰囲気も掴みやすいと思いますし。', '明確な基準を言えないのですが、僕はデータを外部から買ってるのかどうかは必ず聞くようにしています！外から買ってるので、その会社のデータの質にかなり左右されることになるとも思うので、それと自社でデータを集める気はないのかとか、聞いてました！もし、データがとりあえず必要だから買ってるって会社で、そのデータが使えないとなると集め直しになるので、そういうことも考えて質問してました！', '<@UREUHGVAQ>\\n実はTeamAIというコミュニティで勉強会の運営サポートや、もくもく会のファシリテータのような事もやらさせて頂いており、1 - 2日/週ほどで参加しているんです。\\n今まで転職の話などあまりしてこなかったので、これから積極的に聞いて行こうと思います。\\nありがとうございます！', 'あ、そうだったんですね！\\n僕も一度、勉強しに行かせていただきました！笑\\n半年以上前ですが！', 'おお！そうだったんですね！すごい！実は転職したいんですってアピールするだけでもいい話くるかもですね！', 'そしてteam AI careerに吸い込まれて行くんですね.', '<@UMG0947NY>\\n&gt; データを外部から買ってるのかどうかは必ず聞くよう\\nなるほど！\\n勉強になります。\\n必ず聞くようにします。\\n\\n半年前であればまだ私は運営に関わってないかと思いますが、もし今後ご参加頂くようなことがあればご連絡頂けるとうれしいです。\\n心の準備ができるのでｗ', '<@UREUHGVAQ>\\n人とのつながりは大切ですね。\\nアピール心がけます！', '<@UJRAL005U>\\nteam AI careerはもっとハイスキル人材なのではないかな？？と思うので、きっと吸い込まれないと思いますw')\n",
      "('Komei',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'maimai', 'yuji.imuta', 'れごん-島根のﾌﾘｰﾗﾝｽ', '小竹(fishb)', '吉村政彦ｰ産業ｽﾊﾟｲ', 'ﾔｴﾘ_営業ｱｯﾌﾟﾃﾞｰﾄ', 'Katsuya Nagano')\n",
      "('VR', 'データサイエンティスト')\n",
      "('こんにちは。現在エンジニアをしていてデータサイエンティストではないので普段プレゼンなどをやったりすることはないのですが人前で話したりするのが苦手で克服したいと思ってます。定期的に人前で話す場を提供してくれるようなもの(サービス？)って何か思い当たるでしょうか？',)\n",
      "('うちでLTしましょう！！企画しますよー！！', '<https://www.street-academy.com/myclass/3207>\\nこういうサービスもあるようですが村上さん言う通りDLGでLTがコスパ的にもいいですね', 'こことかも<https://www.kokuchpro.com/feature/%E3%82%B9%E3%83%94%E3%83%BC%E3%83%81%E7%B7%B4%E7%BF%92%E4%BC%9A/#>', '企画するのが良いかと！！', '村上さんとかぶりました笑', 'ZOOMでやったりしてもいいかもしれないですね。', 'VRでプレゼン練習できるアプリとかもありますね。<https://www.newsweekjapan.jp/stories/world/2016/04/post-4834.php>', '<@UJRAL005U>\\nご返信ありがとうございます。\\nLTというものを知らなかったのでちょっと調べてみました！短いプレゼンテーションみたいな感じなんですね。\\nそのような機会を提供していただけるのならぜひ参加したいです！', '<@UMTMKBB1Q>\\nありがとうございます！リンク確認しました。\\nプレゼン道場気になりますね。\\n実際に練習する場を探していたので参考になります:smiley:', '<@UMG0947NY>\\nいえ全然大丈夫です笑\\n自分でも勉強会開催とかに興味があるので色々調べてみようと思います！', '<@UL0NZCCMT>\\nおぉ、すごいですね。。リアルではないですがこれで練習しておくと実際に聴衆の目の前に立った時に心理的負担がかなり軽減されそうな気がしました:thinking_face:\\nありがとうございます！', '<@USU3HJY20>\\n輪読会に参加して発表とかもいいかもですね\\n<https://data-learning-guild.slack.com/archives/CNX7CKQJ1/p1579745890003300>', 'イイネ！イイネ！(*^_^*）', '<@UKPAM2942>\\nこういうの理想です！何かに対して自分の意見を述べる練習はぜひやってみたいですね。明日はちょっと無理どうですがまた別の日に調整したいと思います！', '<@UN0HCK74M>\\n色々教えてくださって嬉しいです:smile:', '横からすみません。\\n会社員であれば、普段から社内で「人前で話したい！」を公言しておくのがおすすめです！\\n回数を重ねれば重ねるほどうまくなるので、やったもん勝ちです！\\n私はこの手で、定期的に講演させてもらってますw', '<@URSAAN0J3>\\nアドバイスありがとうございます！\\nそうですね。自分も出来るだけ多くそういう機会を作って感覚を麻痺らせたいと思ってます笑', 'あ、LT練習場channel企画してたこと忘れてました。使うかはさておき、数日中に作っておきますね！', '<@UPR6BE9S6>\\nそんな企画があったんですね！よろしくお願いします:smiley:', '<#CT77LBTBR|07-15-lt練習場> \\n作りました :innocent: ', '<@UPR6BE9S6>\\nありがとうございます！参加しました:smile:')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'こ ろ ん', 'ｸﾛ\\u3000京大医学部3年', 'すずきしげお')\n",
      "('統計', '教科書')\n",
      "('みなさん数理統計はどんな本使って勉強してましたか？？',)\n",
      "('あんま参考にならないと思いますが、大学でやったので、どの教科書だったかもはや覚えてないですね・・・\\n\\n資料とか配られたような気もします。', '確率分布とか、ポアソン分布に関しては待ち行列の計算とかしたときに倣ったような気がするので、情報系学部のカリキュラムとか案外参考になるのかと思います。', '<https://www.amazon.co.jp/%E5%85%A5%E9%96%80%E6%95%B0%E7%90%86%E7%B5%B1%E8%A8%88%E5%AD%A6-P-G-%E3%83%9B%E3%83%BC%E3%82%A8%E3%83%AB/dp/4563008281|https://www.amazon.co.jp/%E5%85%A5%E9%96%80%E6%95%B0%E7%90%86%E7%B5%B1%E8%A8%88%E5%AD%A6-P-G-%E3%83%9B%E3%83%BC%E3%82%A8%E3%83%AB/dp/4563008281>', '<@UMG0947NY>\\n数理統計と統計学って分野違うんでしたっけ？\\n\\n東大赤本とかでは足らない感じです？', 'どう違うのかはっきりと言葉で説明できないので、そういうのも含めて勉強してみたいと思ってます！東大赤本は僕の読解力の問題なのかもしれないですが、説明がわかりづらくて・・・', '<@UQSRC415Y>\\nありがとうございます！！', 'そういう意味だと学校の統計学の授業で使った本がこれですが、東大赤本より簡単ということはないですｗ\\n<https://www.amazon.co.jp/dp/4563008397/>', 'ホーエルですね・・・ころんさんが上であげてくださっていた！結構難しいですか？？', '難しくはないですけど冗長なのでそこは好き嫌い出るかと思います', '所謂教科書っぽい書き方なので、分かりやすく解説というよりは坦々と解説して行く感じですねー！', '<@UQSRC415Y>\\n冗長なのですね！なるほど！ありがとうございます！\\n知り合いにもこれ勧められてたので気になってました！', '<@UJRAL005U>\\nなるほど！！本屋でちょっと立ち読みしてみます！', '今東大赤本と見比べてみたのですが、東大赤本よりは若干優しいかもです。', '文章と図解多めですね', '図解多めはいいですね\\nイメージしやすいので！', '初版見て1963年ってなってて、歴史を感じましたｗ', 'なるほど！\\n現在でも、人におすすめされてる本って確実に名著ですね！笑', '現代数理統計学の基礎という本を今読んでます！東大の赤本の後に読んでますが..\\n赤本は理解しやすかったですが、こちらの本は苦戦中です。数式が一気にわかりにくくなってます。人によってどうかはわかりませんが！', 'なるほど。。。数学に強いわけではないのでその本は敬遠する方向で行こうかと思います・・・・笑', 'ちょっと古いけど演習中心が好きなら\\n\\n\\n明解演習 数理統計 (明解演習シリーズ) <https://www.amazon.co.jp/dp/4320013816/ref=cm_sw_r_cp_api_i_F2-lEbVBE7ZKF|https://www.amazon.co.jp/dp/4320013816/ref=cm_sw_r_cp_api_i_F2-lEbVBE7ZKF>', '数学力に自信なければマセマからがとっつきやすいかと。\\n\\n\\nスバラシク実力がつくと評判の統計学キャンパス・ゼミ―大学の数学がこんなに分かる!単位なんて楽に取れる! <https://www.amazon.co.jp/dp/4866151021/ref=cm_sw_r_cp_api_i_T3-lEbVY08JYN|https://www.amazon.co.jp/dp/4866151021/ref=cm_sw_r_cp_api_i_T3-lEbVY08JYN>', 'マセマいいですよね！線形代数・微積・確率統計やりました！', 'マセマの統計完了したレベルなら現代数理統計学の基礎も大丈夫だと思いますよ。', '本当ですか？？\\n本屋でみてみます！ありがとうございます！！', 'わたしもやってるので一緒にやりましょ～', 'そうなんですね！！\\n書店でみてみます！！！')\n",
      "('ｲﾏﾀﾞﾃﾂﾛｳ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'yuji.imuta', '小池達朗', 'sota_sakuma', 'Hiroyuki.Tachikawa')\n",
      "('転職', 'データサイエンティスト', 'Slack', '書籍', 'AI', '統計')\n",
      "('はじめまして！\\nYouTuber KENTAさんの雑食系エンジニアTVから村上智之さんとの動画を拝見しましてこちらのSlackに辿り着きました！\\n\\n現在私はFamilyMart店長をしております。年齢は30です。転職を考えております。\\n\\nプログラミングというものも以前から「手に職」というところと、今後必ず必要となる技術（世のテクノロジー化や学校での必修科目化）ということで注目してました。\\nまた現職では日々データの分析（特に発注業務において）、予測、実行、振り返り。の繰り返しで、こういった経験、経緯から『データサイエンティスト』という職業に非常に興味が湧くようになりました。\\n\\nそこで質問なのですが、30歳未経験（IT業界、プログラミング歴等すべて未経験。\\n文系でしたので数学に関しては数１数A程度。\\n統計学は大学で少しだけ…）という背景からデータサイエンティストという職業へどういった道を辿れば良いのか（そもそもなれるのか！？）、意見・アドバイス等あればお聞きしたいです！\\n宜しくお願い致します。\\n\\n【補足】\\nデータミックスさんのデータサイエンティスト育成コース（転職支援付き）の無料体験に行かせて頂きましたが今からだと就職まで早くても約10ヶ月かかるとのこで、時間的にも経済的にもやや厳しいなと感じ躊躇しております。。',)\n",
      "('<@UKT3G90U8> <@UKFMDBUV9> \\nこれは二人の出番ですね！！\\n\\n背景事情とか、置かれてる状況とか諸々詳しいと思いますので、何かアドバイス共有頂けると助かりますー！', '村上さん！早速のお返事ありがとうございます！大変恐縮です。\\n詳しい方いらっしゃればどんな些細なことでも構いませんのでアドバイス等いただければ幸いです。宜しくお願い致します！', 'はじめまして！\\n僕も文系出身でデータ分析系の仕事についていますが、数学にかなりの時間が取られました・・・新しいこと覚えるにも数学の知識が必要になるので、転職しようと思って準備するのは大変なので、早めに準備するのが良いかもしれません！１０ヶ月かかるのは確かにそうかもしれないって感じですが、会社を派遣業中心のような会社（SESと言われるやつです）に絞れば、わりと入りやすい＆研修があるので、給料もらいながら勉強ができます！笑 ただ給料は安いですが・・・', '<@UT8JLANH4>\\n\\nはじめまして！小池と申します^^\\n\\n私は29歳までセブンイレブン-ジャパンのOFC（本部社員）として働いていました、\\nその後、独立を目指し、個人事業主の道を選んだので境遇が似ているかもしれませんね。\\n私も文系でした。\\n\\nあくまで私の見解ですが、\\n結論から申しますと、文系出身で未経験でもデータサイエンティストになれると思います。\\nしかし、理系出身者より時間がかかるでしょうし、30歳という年齢は決して若い方ではない印象です。\\nなので、「やられるなら1日も早い方が良い」のではないかと思います。\\n\\n今の仕事に疑問や将来不安を感じているからこそ、転職を検討されていると思います。\\n\\n時間的にも経済的にも色々あるとは思いますが、\\n\\n・ご自身が将来的にどうしたいのか？\\n・今の環境のままで一生を終えても後悔しないのか？\\n・転職をして、結果どうなりたいのか？\\n\\nこの辺りをしっかりと明確にされておくと、迷いがなくなるかと思います。\\n\\n佐久間さんはファミリマートのSVでしたし、\\n業界のこと、勉強する環境のこと等に対して、より詳しいと思いますので、\\n色々聞かれてみると参考になるかと思います。\\n\\nマインド的な部分しかアドバイスできず、申し訳ないです・・・\\n\\nイマダさんがご活躍されることを心から祈っております(^ ^)', '<@UT8JLANH4>\\n初めまして佐久間です。\\n小池さんに紹介いただいてますが、FMで１年半前までSVをやっていました。\\n細かい敬意を記載すると長くなるので割愛しますが現在は、中堅SierのAIデータ分析チームで受託案件のプリセール、エンジニア、PLをやっています。\\n\\n今後の方針としてまずは、現在の仕事をしながら学習をスタートするのが第一になると思います。\\n多少費用はかかりますが、書籍で自主学習ではなく何かしらの講座等をペースメーカーにして進めることをお勧めします。\\n厳しいことを言う様ですが、やはり人には向き不向きがあるので、学習してみて思ったのと違った等ならそれはそれでありかと思います。データサイエンスではなくエンジニアを目指すなど。\\n\\n文章では語りきれない部分が多いので気軽にご相談ください。\\nオフ会 or 電話等で相談に乗ります！', '後は自己紹介見た感じ、このslackで普通に使われるワードが聴き慣れないことが多いと思いますが、我慢してググると良いと思います。\\n\\n最近多少慣れましたが、聴き慣れないアルファベット3文字や横文字のオンパレードなので。。', 'データミックス の中の人です。もし体験講座に参加されたのが最近ならたぶん私が作ったコンテンツですね。講師も私かもしれません。ここで繋がったのも何かのご縁だと思いますので、是非なんでも聞いてください。コンプラに違反しない範囲でなんでも答えます！', 'お返事頂けた方、貴重なご意見・アドバイス本当にありがとうございます！\\nなんと優しい方々の集まりのコミュニティなのかと、思わず感銘を受けました。。\\n\\n今一度自分自身と向き合いながら検討したいと思います。\\nこれも何かのご縁かと思います。\\n今後また相談させていただければ幸いです。')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', '小竹(fishb)')\n",
      "('マーケティング', '可視化', '設計')\n",
      "('<@UJRAL005U>\\nslackって有料プランに移行する予定とかありますか？？\\n過去の会話とか見れなくなってて・・・',)\n",
      "('<@UMG0947NY>\\nあります！！が、高いので、会員200人辺りを目処に考えています。', 'なるほど！了解しました！ありがとうございます！！', '気になる会話ツリーにするとかできればいいんですけどね', 'ツリーってどんなイメージです？？', 'アーカイブページで見れる', '例えばどんな会話見たいんです？', 'このペースで行くと1ヶ月で1万件超える日も近い・・・', '<@UL2TY2ERL>\\nマーケティングのチャンネルと自己紹介のチャンネルです！！', '自己紹介だけ形にしますかね', '<@UL2TY2ERL> \\nですね！やはり、自己紹介チャンネルのニーズは高いですね！', '<#CSWECLG79|11-3-自己紹介企画>\\n見せるだけのツールとかなら、アジャイルチックな分析と可視化プロセスでプロジェクトやるのも楽しいんだけど興味ある人いれば。', '高いというか1人あたりでかかっちゃうから厳しいですよね。実質会費を千円以上下げるのと同じことになりますもんね', 'その前提で設計しているから大丈夫なんですけど、想定以上に無料枠を配りすぎてる感じですｗ', 'あと、アクティブ率が非常に高いｗ')\n",
      "('すずきしげお',)\n",
      "('上田真也_Shinya Ueda', 'Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000筋ﾄﾚで学ぶﾃﾞｰﾀ分析', 'たかぎあきみつ')\n",
      "('可視化', 'ML', '書籍', 'API', 'データサイエンティスト')\n",
      "('課題の発見にあたって、業務プロセスをヒアリングしたりすることが多いのですが、業務プロセスを可視化するための有効な方法論はありますか。',)\n",
      "('ヒアリングだけではなくて、実際に入り込んで数時間ないし１日その業務プロセスを体験してみるのが一番早いと思います。初見での違和感が一番実は正しかったりします。大手コンサルでも最近は現場主義などといって、コンサルタントを現場に派遣して体験させたりしています。', '現地現認、エスノグラフィーですね。データサイエンティストとして心がけていますが確かにサボりがちです。それを経て言語化/図示化するには何かよいお知恵ありますでしょうか。', '業務プロセスとは少し切り口が異なりますが、\\n<https://www.amazon.co.jp/UX%E3%83%AA%E3%82%B5%E3%83%BC%E3%83%81%E3%81%AE%E9%81%93%E5%85%B7%E7%AE%B1-%E2%80%95%E3%82%A4%E3%83%8E%E3%83%99%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AE%E8%B3%AA%E7%9A%84%E8%AA%BF%E6%9F%BB%E3%83%BB%E5%88%86%E6%9E%90%E2%80%95-%E6%A8%BD%E6%9C%AC-%E5%BE%B9%E4%B9%9F/dp/4274222187>\\nこれとか', 'あとは、QC7つ道具と新QC7つ道具の中から使えそうなものがあると思いますよ。\\n以下の書籍はオススメしたいのですが、データ分析が主眼の書籍なので、今の課題感に対して役立つのは数ページかもです。\\n<https://www.amazon.co.jp/14%E3%81%AE%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%A7%E8%80%83%E3%81%88%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8-%E9%AB%99%E6%A9%8B-%E5%A8%81%E7%9F%A5%E9%83%8E/dp/4761270241>', 'ただ言われて見れれば私も都度考えている感じで、あんまり「これだ！」という方法はちょっと思いつかないかも。なんとなく有向グラフで考えるのがいい様な気がしてはいるものの、現地の状況の様な生の情報の扱いを考えると結構難しいですよね。\\nRPAコンサルの方なんかだと得意なのかなぁ。', 'QC7つ道具...昔学部で習いました。ここで活きてくるんですね。ちなみにRPAも業務で噛んでいます。うまい表現ができると資料作成など私自身作業効率アップできるのですが。', 'おお。そうなんですね。まぁ私も「あると思いますよ。」とか偉そうに言ってしまいましたが、正直人間が可視化して理解出来るような表現方法ってなんだかんだ結構限られているし、「まぁだいたいその中にあるんじゃね？」ぐらいの感じで言ってるだけっす。すみません。実際使えるのあるとは思いますが。', 'いえいえ。とりあえずご紹介いただいた２冊は早速ポチりました', 'BPMN(ビジネスプロセスモデリング表記法)というのがISOにあるらしいです。\\n\\n<https://ja.wikipedia.org/wiki/%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E3%83%97%E3%83%AD%E3%82%BB%E3%82%B9%E3%83%A2%E3%83%87%E3%83%AA%E3%83%B3%E3%82%B0%E8%A1%A8%E8%A8%98%E6%B3%95>', 'それに近いしいですが、UMLのアクティビティ図に整理してあげたりするのは結構有効ですね！\\n\\n<http://www.itsenka.com/contents/development/uml/activity.html>', 'あと、ここら辺はまだまだ過渡期ですが、プロセスマイニングなども熱いかと思います！！\\n\\n<https://www.heartcore.co.jp/process-mining/guide/index.html>', 'UMLよさそうです！BPMNは調べてみると要素とルースが多すぎかもです。\\nプロセスマイニングはちょっと私自身がパッと理解できないですね。分析と業務フローの可視化の掛け合わせみたいな？ご教授いただけますと幸いです', 'プロセスマイニングは、業務フローをデータ化して、そこからプロセスをシステム的に可視化するって物ですね！！', 'どんな種類のツールがあるかまではカバーしきれていないですが', 'ボトルネックや手戻りが多い箇所がどこにあるのか、分析的に求めるって感じですかね。', '数百人とか、数千人規模が業務プロセスに関わるような会社でワークするイメージですねー！', 'なるほど。それができれば理想的ですね。弊社は未だに業務標準化もできていない上、紙での記録も残り、salesforeceも入れられておらず課題山積みで遠い未来という印象です。\\nコールセンターとかECサイトなら可能なんですかね？', 'そうですね！後は製造業、銀行や不動産など、プロセスが複雑な所で結構生きてくるっぽいですね。', '工場だけならできるかもです！工場の自動化はほぼ完了しているので次はデータを取りまくる（カネの問題だけ）', 'bpmnで書くことが出来て、プロセスの実行はAPIで実現できるので環境に依存せず、saasなのでスモールスタートできるワークフローエンジンがありますよ。<https://questetra.com/ja/|https://questetra.com/ja/>', 'saasなので、企業を跨いだワークフローなんかも実現できます', 'ワークフローを導入すれば、業務のボトルネックが可視化されるので、イメージされていることは実現できると思います', 'ありがとうございます！たしかにイメージに近いです。\\n次の課題は、いろんなシステムに共通する問題かもしれませんが、ユーザーである社員たちがまじめに入力してくれるのか？というところです。何を作っても結局ここで挫折している気がします。', '自分の経験だと、承認フロー系から始めると良いと思います。無くても回る業務から始めると、メリットを感じてもらう前に使ってもらえないので。特に営業とかは苦戦しました')\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'yuji.imuta', 'Ryusuke Miyaji', 'Riita Satsuki')\n",
      "('Docker', '機械学習', 'jupyter', 'SQL', '入門')\n",
      "('docker学ぼうかなと考えていて動画教材がいいなと考えてこれやろうかなと考えています。\\nしかし、webアプリケーション用なので機械学習用のインフラとかなり方面が違うのかもと考えて迷っています。\\n機械学習とwebアプリケーションで必要なdockerの技術がどの程度違うのか教えていただけると嬉しいです。\\n\\n<https://kirohi.com/docker_study_resources#Udemy_Docker>',)\n",
      "('これ結構良かったです！\\n\\n<https://knowledge.sakura.ad.jp/13265/|https://knowledge.sakura.ad.jp/13265/>', 'アプリとの違いとかはあまり分からないので他の人に任せたw', 'ありがとうございます、読んでみます！\\nただモチベ維持のために動画がいいなっていう感じです:joy:', '\\n\\n\\n\\n<https://www.slideshare.net/zembutsu/docker-basis|https://www.slideshare.net/zembutsu/docker-basis>\\n\\n<https://www.osscons.jp/cloud/%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89/?action=common_download_main&amp;upload_id=698|https://www.osscons.jp/cloud/%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89/?action=common_download_main&amp;upload_id=698>\\n\\n\\n会社のインフラの人にこの人のスライドが一番良いよって言われました！', '分かりやすそう！', '<@UMG0947NY> ありがとうございます〜', '私はWebアプリを作る人間ですが、、\\n⬆︎のDocker入門と記事中のudemyの講座で学習しましたね。\\n\\n<https://px.a8.net/svt/ejp?a8mat=2ZRX32+KU6YA+3L4M+BW8O2&amp;a8ejpredirect=https%3A%2F%2Fwww.udemy.com%2Fdocker-k%2F|https://px.a8.net/svt/ejp?a8mat=2ZRX32+KU6YA+3L4M+BW8O2&amp;a8ejpredirect=https%3A%2F%2Fwww.udemy.com%2Fdocker-k%2F>\\n\\ndocker-composeでRailsとDjangoの環境を作るので、使い方のイメージはしやすくなるかなと思います。\\n\\nすると、その次のステップとしてご自身でJupyterとかMySQLのコンテナを作っていく感じになるかなぁと', '<@UTE5WQUBA> ありがとうございます！まさしくそれを検討していました、railsとかを作って後にJupyterとかMySQLのコンテナを自力で作るのはそこまで難易度高くない感じでしょうか？', '個人的には動画中の内容がわかれば、そんなに難しくないと思ってます！\\n\\n↓の記事でJupiter labのコンテナを作ってますが、先にDockerを学んでおけば、何をやっているかググりながら理解出来るのではないかと\\n\\n\\n<http://datawokagaku.com/startjupyternote/|http://datawokagaku.com/startjupyternote/>', 'なるほど、みやじさんのいう通りの流れでやってみます、ありがとうございます！', '今のやり取りからも一旦のゴールがあるのも感じたのではやとさんならすぐ使いこなせるようになるかなと！\\nお互い頑張りましょう！', 'Dockerfileの書き方は\\n<https://qiita.com/riita10069/items/7c6d2958294910d346d1|https://qiita.com/riita10069/items/7c6d2958294910d346d1>\\nこれとかどうですか…笑\\n\\nDockerの仕組みは\\n<http://docs.docker.jp|http://docs.docker.jp>\\nが日本語なので読みやすいと思います。\\n新しい技術をキャッチアップするときって本かドキュメントを読まないと知識が断片的になって汎用性のあるスキルにならないと思うんですよね。個人的な意見ですが…\\n\\nあと、機械学習とwebで必要なDockerの知識は同じなのでそこは気にしなくて大丈夫です！', '<@UNFAV5EDB>\\nありがとうございます！機械学習とweb知識同じというのは有り難いです、確かに結局最後はドキュメントみたいなところありますよね笑', 'とりあえず半分ちょっと動画でやってみたんですけど、一旦インフラ学んでから戻ってこようかなって思います、いろいろアドバイスありがとうございました！')\n",
      "('maimai',)\n",
      "()\n",
      "()\n",
      "('コーポレートサイトや企業のサービスLP（B２B）の閲覧デバイスはPCが多いのでしょうか。\\nコーポレートサイトに記事投稿が多くなるとリピーターが増えてモバイルからの閲覧が増えたりなどもあるのかなと気になったり。\\n\\n基本会社PCから見ている人が多いからPC閲覧の方が多いのかなあという想像なのですが',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Katsuya Nagano', 'sho.kumada', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'Hiroyuki.Tachikawa', 'ﾋﾛﾘｰ')\n",
      "('SQL', 'BigQuery')\n",
      "('BigQueryを使ったSQL集計で質問させてください:man-bowing:\\n\\nアプリゲームのログデータを想定しています。\\n\\n4月に課金した人が、5月にログインしてるか？みたいな集計をしたいです。\\n\\n課金データテーブルとログインデータテーブルがあります。\\n\\n①4月に課金→5月にログインした人、は正しく集計できているのですが、\\n\\n②4月に課金→5月にログインなし、の人を正しく集計できず……\\n\\nWhereにて、5月ログインあり、でフィルターをかけると、②が集計結果に表示されなくなることは理解しました。\\n\\n\\nそこでフィルターは使わずCOUNTIFを使うのかな？と試行錯誤しているところで止まっております:sob:\\n\\nググっても良くわからずテキストからもうまく情報を拾えず……お力をお貸しくださいまし:man-bowing:',)\n",
      "('```--① 4月に課金した人を出す\\nWITH april_paid_users AS(\\n  SELECT\\n    user_id\\n  ・・・\\n),\\n\\n--② 5月にログインした人を出す\\nmay_login_user AS(\\n  SELECT\\n    user_id\\n  ・・・\\n),\\n\\n--③ 「4月に課金した人」に「5月にログインした人」をLEFT JOIN\\nwrk_tbl AS(\\n  SELECT\\n    paid.user_id,\\n    SIGN(login.user_id) AS login_flg\\n  FROM\\n    april_paid_users AS paid\\n  LEFT JOIN\\n    may_login_user AS login\\n  ON\\n    paid.user_id = login.user_id\\n)\\n\\n--（課金した人 - ログインした人）で課金後ログインなしユーザーを抽出\\nSELECT\\n  COUNT(*) - SUM(login_flg)\\nFROM\\n  wrk_tbl```', '<@UPR6BE9S6> さんと大体同じ感じですが、クエリのイメージとしてはこんな感じですかね？', 'signでNULLを0、user_idがあれば1にしてます。（自信ないけど、こういう使い方できたはず。）', 'スレッドに書き直します。\\n\\n① 4月に課金した人を出す(+定数1をつけたflg列つける）\\n② 5月にログインした人を出す(+定数1をつけたflg列つける）\\n③ 「4月に課金した人」に「5月にログインした人」をLEFT JOINして、WHERE 5月flg列 IS NULL\\n\\nで出せる気がします :innocent:\\n\\n\\n```WITH 4月 AS (\\n\\tSELECT DISTINCT\\n\\t\\tid,\\n\\t\\t1 AS flg,\\n    FROM 4月課金log\\n), 5月 AS (\\n\\tSELECT DISTINCT\\n\\t\\tid,\\n\\t\\t1 AS flg,\\n    FROM 5月ログインlog\\n )\\n  SELECT\\n  \\tCOUNT(4月.id) AS cnt\\n  FROM 4月\\n  LEFT JOIN 5月\\n  \\tON 4月.id = 5月.id\\n  WHERE 5月.id IS NULL\\n )\\n ;```\\nかな？\\n4月課金logと5月ログインログはテキトーに作ってください。', '確かに、こっちの方がシンプルですね', '`SIGH` の存在知らなかった :innocent:', '`SIGN` 関数便利ですね簡単にフラグ化できます。', '`1 AS flg` ってやってますけど、1じゃなくてもいいです。定数が欲しいだけなので。', '（この問題、どこかで見たことある気がする・・・きっと気のせいかな？？）', 'めっさ伸びてる……！\\nありがとうございます！\\n理解しきれない自分が悲しい:sob:\\n\\n帰宅してPCと睨めっこして消化してみます！\\n\\n<@UJRAL005U> おそらく気のせいではない気がします:sweat_smile:', '問題を抽象化した上で集合知に頼ることもスキルですねｗ', '<@UPR6BE9S6>\\nこれですね。NULLはNULLのままっぽいので、`COALESCE`とかと組み合わせないとダメでした・・・\\n\\n<https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators?hl=ja#sign>', 'なんと言いますか、奥が深いですね……浅いところで打ちのめされ中です！:sob:', '私も週末色々躓きそうです笑', '中堅者でも引っかかるnull問題', \"では私もちょっと試しに...。\\n```WITH 4月課金データ AS (\\n\\tSELECT\\n\\t\\tDISTINCT ユーザーID AS 4月課金ユーザー\\n    \\tFROM 利用履歴\\n\\tWHERE 課金=した\\n  \\tAND 4月にログイン=した\\n), 5月ログインデータ AS (\\n\\tSELECT\\n\\t\\tDISTINCT ユーザーID AS 5月ログインユーザー\\n    \\tFROM 利用履歴\\n\\tWHERE 5月にログイン=した\\n ),  結合データ AS (\\n\\tSELECT\\n\\t\\t*\\n\\t  \\tCASE\\n\\t\\t\\tWHEN 5月ログインユーザー IS NULL THEN '5月ログインなし'\\n\\t\\t\\tELSE '5月ログインあり'\\n\\t\\tEND AS ログインステータス\\n\\t  FROM 4月課金データ\\n\\t  LEFT JOIN 5月ログインデータ\\n\\t  ON 4月課金データ.4月課金ユーザー = 5月ログインデータ.5月ログインユーザー\\n) SELECT \\n\\tログインステータス\\n\\t,COUNT(*)\\nFROM 結合データ\\nGROUP BY ログインステータス\\n ;```\", '方向性としては、大体みんな同じですねー！！', 'クエリの書き方は結構性格が出たり、アイディアがあったりで面白いですよね。', '結構クセ出るかなーと思ったのですが、フラグの扱いだけ違って、デーブル2つ作ってJOINするのは同じなんですね！\\n\\nなんかスマートにできる方法ありそうな気がするんですけどねー！', 'う〜ん。確かに。', 'LEFT JOINのWHEREの中で条件一気に指定するとかは良さそうかもですね', 'ですね〜。あと、ちょっとこれは私の性格なのですが、集計結果がMECEになってないと不安で、今回の例で言えば、①と②の結果が両方出力できないと不安...。みたいのないです？私だけ...?', '分かりますw', '都度実行して確認しますw', '多少パフォーマンス犠牲にしても読みやすさと確実性優先することのが多いですね。', '超わかります。', 'ありがとうございます！\\nSQLもこだわりや嗜好が出てくるものなんですね、奥が深いですね……！', '流れに乗り遅れたけど SIGN関数の便利さに感動！！！\\n\\n```case when user2 is not null then 1 else null end```\\nって長い文字打ち込まなくてよくなるのかな\\nちょうど、超横長な中間テーブル開発中なので早速試してみます！', '<@ULKPET3UK>\\n`SELECT COALESCE(SIGN(user_id),0)`\\n\\nNULLダメだったポイんで、こんな感じですね！ユーザーIDが文字列の場合はダメっぽいです。', 'ありがとうございますー！\\n一気にコードはスッキリするけど、認知度の低さから、今後の保守性考えると置き換えるのは悩ましさも出てきました。。。', '冗長なコードは読みやすいですしねー！', 'マート作る用のコードだったらCASE WHENで良いような気もします。', '個人で分析する分には早いですし、便利ですよ！', 'そうですねぇ\\n個人でやるアドホックな時から意識的に使ってみますー！', '教えていただいた構文？を重ねるやり方がうまくできず、COUNTIFにて\\u3000「月に課金→5月にログインなし」\\u3000は実現できたのですが・・・、もう一つ新たな問題が出てしまい、これも自己解決できず、質問させてください:sweat_drops:\\n「月に課金→5月のログイン回数（0回含む）、に加え、5月のクエスト実施回数」を集計しようと下記のように、\\nクエストデータテーブルを結合したところ、\\n新しくくっつけたデータの数だけ、ログイン数が膨れ上がってしまいます。。。\\n正しい5月のログイン数\\u30000回、4回\\u3000⇒\\u3000結合後のログイン数\\u30000回、28回（7倍になってしまう。。）\\nSELECT\\n      COUNTIF(DISTINCT Login.timestamp BETWEEN～)\\nとするとログイン数が\\u30000回、1回\\u3000になってしまい、どうすればいいのやら弱っております。\\n度たびで恐れ入りますが、どうぞよろしくお願いいたします:man-bowing:\\n```SELECT\\n    Login.user_id,\\n    --5月にログインした回数\\n    COUNTIF(Login.timestamp BETWEEN TIMESTAMP(\\'2016-05-01 00:00:00\\') AND TIMESTAMP(\\'2016-05-31 23:59:59\\')) as Login_TIMES\\nFROM\\n    魔法石取引テーブル as Magiq_Stone\\n    INNER JOIN ログインテーブル.login_log` as Login\\n        ON Magiq_Stone.user_id = Login.user_id\\n    INNER JOIN クエストデータテーブル` as Quest       ###追加###\\n        ON Magiq_Stone.user_id = Quest.user_id           ###追加###\\nWHERE\\n    --魔法石を購入したユーザー\\n    category = \"buy\"\\n    AND\\n    --魔法石の取引が4月に行われている\\n    Magiq_Stone.timestamp BETWEEN TIMESTAMP(\\'2016-04-01 00:00:00\\') AND TIMESTAMP(\\'2016-04-30 23:59:59\\')\\nGROUP BY\\n    Login.user_id```\\n', '<@US69FTTH6> \\nちなみにしみずさんてExcelのピボットふつうに使える感じです？', '普通に使えます！', 'てことは、ピボット前の状態がイメージできてない感じですかね？', 'case句で集計キーとなる列を作っていってjoinを使わないのが、たぶんわかりやすいと思います。\\nちょっとこの後夜まで反応できないのですが、きっと誰かがクエリを描いてくれるでしょう(人任せ)また夜に戻ってきます！', 'そうですね、エクセルだと見ながら作成できますので問題ないのですが、SQLのような作成過程が見えないものですと、頭にイメージ図を想像するのが苦手なもので、厳しい感じです:sweat_drops:\\nアドバイスありがとうございます！', '<@US69FTTH6>\\n一回手書きで中間デーブルとか書くと良いですよー！！', '<@UJRAL005U> なるほど・・・！', 'アルベルト本にもそのようなことが書いてました！', '多分その人の教えですw', 'なるほど笑', '作業指示もらう時もそんな感じだったのですが、それならズレにくいですしね。', '素晴らしい方ですね、みんな指示する側にまわると、めんどくさがってしなくなるやつです笑', '&gt; 教えていただいた構文？を重ねるやり方\\nこれはWITH句のことですか？よっぽど古いバージョンじゃない限り使えるはずですが。。。MySQLだけ1,2年前のバージョン（1つ前のメジャーバージョン）では使えなかったはずですが。\\nCREATE TEMP TABLE でWITH句と同じものをひとつずつ作るという方法もあります。\\n\\n今回の質問ですが、データがわからないのでなんともですが、1回で一気にやろうとせずに、WITH句なりCREATE TEMP TABLEなりで1つ1つの処理を作って最後に結合とかの方がわかりやすいですよ。', 'ですねー！サブクエリが理解できていない疑惑あるかもですね。', 'WITH句\\n<https://tech.tvisioninsights.co.jp/entry/2018/08/06/144208>', 'なるほど！ありがとうございます。\\n&gt; case句で集計キーとなる列を作っていってjoinを使わないのが、たぶんわかりやすいと思います。\\nこちらも試してみます！', 'With、ちょっと前に行ったSQLの入れ子（サブクエリ？）を簡潔にするためのものなんですかね……\\nMySQLはないんですね、恐ろしいです……', 'それです。入れ子にするとコードが複雑に見えてしまうので、WITHを使った方がシンプルに書けます！', 'MySQLは最新メジャーバージョンから導入されてますねー', 'ありがとうございます、使いこなせるよう練習してみます！\\nできなかったのは、よくわかってなかったので書き間違えたように思います:sweat_smile:', 'WITH使うと便利ですね・・・！\\n元々の問いが、\\n『4月に課金して魔法石を購入したユーザーについて、ユーザーごとに、\\nユーザーID・5月のログイン回数・5月でクエストを行った日数・5月でクエストを行った回数を出力しなさい。』\\nなのですが、\\nWITHをうまく使って、下記の個別の数字は出せました！\\n後はうまく組み合わせるだけ・・・！\\n・4月に課金して魔法石を購入したユーザー\\n・ユーザーごとの5月のログイン回数\\n・ユーザーごとの5月にクエストを行った日数\\n・ユーザーごとの5月にクエストを行った回数\\nありがとうございます！:pray::pray::pray:')\n",
      "('yuji.imuta',)\n",
      "()\n",
      "()\n",
      "('R studioでrJavaをインストールできないのですが、どなたかやり方わかる方いませんか？？',)\n",
      "()\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "()\n",
      "('寝起きですが全く同じこと昔やっていたので瞬殺できるような気がするw',)\n",
      "()\n",
      "('柳沼 諒平',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'chan', 'K')\n",
      "('Python',)\n",
      "('pythonのmath.sinって符号おかしくないですか？',)\n",
      "('テスト的に実行したサンプルって、共有頂く事ってできます？？', 'これです！', '直感的には反時計回りに描きそうなんですが、時計回りに描かれています！', '↓がy軸正の方向とか？', '<@US2HKDVSL>\\nなんかそうっぽいですよね。\\n\\n<@UTE90UH6Z>\\n実際動かして数値で出力してみて、数値見た方が早いかと思いますー！', 'なるほど、ありがとうございます！', '画像をPythonに読み込ませると原点が左上で、そこから右下が正の方向になっているためかも知れません、')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Yan')\n",
      "()\n",
      "(\"*# ご質問*\\nTarminalでファイル名の特定の文字以下拡張子のこしてすべて切り取りたい。\\n\\n*## 実行環境*\\nMac OS : High Sierra\\nrename: stable 1.601 (bottled)\\n* rename は brew で入れました。\\n\\n*## 質問内容（実現したいこと）：*\\n特定の文字が含まれているファイル名を、その特定の文字以下すべて切り取るが拡張子は残したい（.以下は保持したい）\\n\\n*## ここまではできます。*\\n特定の文字が含まれる`ディレクトリ名`を置換する。\\n例:\\n.\\n└── directory\\n    ├── 00_dir\\n    ├── 01_dirのコピー\\n    ├── 02_dirのコピー2\\n    └── 03_dirのコピー3\\n\\n```rename -n 's/(.*)の(.*)/$1/' * ```\\nでフォルダ名を変更はできます。\\n\\nでも、それを``ファイル名``に於いても処理したいです。\\n\\nどうぞよろしくおねがいいたします。\",)\n",
      "('どういったディレクトリに対して、renameをして、どんなアウトプットを期待しているイメージでしょうか？\\n\\n具体的なサンプルがあればイメージ付きやすいかと思います！', 'type f, find, xargsあたり組み合わせていけないすかね。', 'これ組み替えたら行けそう。\\n\\n<http://ktykwsk.com/rename%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%82%92%E4%BD%BF%E3%81%88%E3%81%AA%E3%81%84%E7%92%B0%E5%A2%83%E3%81%A7%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E5%A4%89/|http://ktykwsk.com/rename%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%82%92%E4%BD%BF%E3%81%88%E3%81%AA%E3%81%84%E7%92%B0%E5%A2%83%E3%81%A7%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E5%A4%89/>', 'ご返答遅れて申し訳ございません。\\n本日中に試してみます。報告します\\nありがとうございました！')\n",
      "('shimizu.yohei',)\n",
      "()\n",
      "()\n",
      "('インフルエンザなどの流行によってエンジニアチームがリモートを検討しているんですが、\\nリモートで質問があった場合やMTGをしたいときに便利なツールって何がありますかね？\\nやっぱりZoomですかね？',)\n",
      "()\n",
      "('Shinya Ueda_上田真也',)\n",
      "()\n",
      "()\n",
      "('whereby\\nがいいですよ！',)\n",
      "()\n",
      "('Shinya Ueda_上田真也',)\n",
      "()\n",
      "()\n",
      "('私が持ってますから、一度お試しください\\n',)\n",
      "()\n",
      "('Shinya Ueda_上田真也',)\n",
      "()\n",
      "()\n",
      "('<https://whereby.com/shinya.ueda2|https://whereby.com/shinya.ueda2>\\n\\nPCの場合これを踏むだけです\\nスマホはアプリが必要',)\n",
      "()\n",
      "('shimizu.yohei',)\n",
      "()\n",
      "()\n",
      "('旧appear.inですね！\\nありがとうございます！検討します！:blush:',)\n",
      "()\n",
      "('Shinya Ueda_上田真也',)\n",
      "('shimizu.yohei',)\n",
      "()\n",
      "('そうですそうです！\\n私はこれで、「取締役会」や「経営会議」までやっています\\nここまでくるのに、相当時間がかかりました。。\\n（変な機器設備が必要な社内会議システムとか、いろいろ試されて。。）',)\n",
      "('<@UR7A5CJNA> さん\\u3000新型コロナやインフルエンザ対策としてのリモートワークの他社事例について報告する場（もちろんリモートで）を設けた場合、ご参加興味ありますか？\\nもし興味を持っていただけるのであれば、雑談窓に投げかけてみたいと思います。平日の1時間くらいで、各自持ち寄る形での共有から始めたいと考えております。', '<@URYTPRJ7P>\\n興味はあるのですが、申し訳ないことに弊社ではあまり積極的にリモートワークをやっていなかったので\\nあまり共有できることが無いんですね〜:cry:\\n参加しても聞き専になってしまいそうです:man-bowing:', '<@UR7A5CJNA> 率直なご意見ありがとうございます！そもそもリモートワークについても、積極派消極派あり、さらに積極派のリモートワークのやり方もいろいろなので、今のところは難しいですよね。ありがとうございました。\\nでは、皆さんには、そもそも会議システムを使う以前のその場面として、リモートワークをどう考えているか、みたいなところを投げかけてみようと思います。\\nありがとうございました。引き続きよろしくお願いします。', '<@URYTPRJ7P>\\nこちらこそ、お声掛け頂きありがとうございました！\\n共有できることがあった際にはぜひ共有させてください！:man-bowing:')\n",
      "('maimai',)\n",
      "('しみずこうじ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('データサイエンティスト', '因子分析')\n",
      "('アンケートによる販売促進施策や結果解析に基づく改善策の提示などをしてくれるところを探している人がいるのですが、データサイエンティスト領域ですかね。\\nアンケート会社でノウハウありそうなのでそちらでどうぞというところでしょうか？\\n※引き合いはまだないけど知識として知りたいと言われました。引き合いあるようならDS紹介しますと営業しときましたｗ',)\n",
      "('データサイエンティストがやるほどアンケート回収数があるのか気になりました……\\n\\nやってるところは多そうですが、この手の調査は、マクロミルやインテージが大手だったかと思います！', 'ですねー！\\n\\nアンケートはしみずさんのおっしゃる通り、パネル調査に強いマクロミル、インテージなどが第一候補かなーという印象です！\\n\\nDSプロジェクトの一部としてアンケートデータを使うことはあるのですが、教師なしで因子分析などの手法がメインですね！', 'お二人ともありがとうございます！\\nもし分かれば知りたいのですが、アンケート〇〇〇〇枚以上、または〇種以上ならDSに頼む目安などってありますかね？\\nそのくらいの枚数なら頼みましょう！と持っていく目安', '<@UMTMKBB1Q>\\n特に、枚数目安で変わることはあまりない気がしますねー！データ量は必ずしも必須ではないですし。基本的には\\n\\nアンケートデータを取る→調査会社\\nアンケートデータの分析→データサイエンティスト\\n\\nという切り分けですね。', 'DSもあんまり件数気にしないんですねー')\n",
      "('Riita Satsuki',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('SQL',)\n",
      "('SQLについて質問です。\\nreservationテーブルに予約が常に入っているのですが。\\nその予約がキャンセルされると、reservation_cancelにreservation_idが追加されます。\\nSQLを使って、reservationテーブルにcancelしたかどうか(0, 1)の列を追加したいのですが、\\ninやexistを使っても列は追加できません。\\nいい感じに列を追加する方法はありますか？',)\n",
      "('①reservation tableに、reservation id をキーにLEFT JOINする\\n②CASE分を使って、reservation_cancel.id が存在する場合は1、しない場合は0を入力\\n\\nって感じでいかがでしょう？', 'そうですね！\\nできました！ありがとうございます！', '```SELECT\\n  reservation,\\n  CASE\\n    WHEN logs.id IS NULL THEN 0\\n  ELSE\\n  1\\nEND\\n  AS cancel\\nFROM\\n  `reservations` AS reservation\\nLEFT JOIN\\n  `cancel_logs` AS logs\\nON\\n  logs.reservation_id = reservation.id\\nORDER BY\\n  reservation.created_at DESC\\n  ```')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('AR', 'BigQuery', 'BQ')\n",
      "('BigQueryについて質問です。\\nSPLITしたデータの2つ目を取り出す。\\n“hoge,hoge2,hoge3”\\nのhoge2を抽出したい。\\n場合SPLITで、分解できるとしてARRAYは\\nSPLIT(“hoge,hoge2,hoge3\",“,”)[1]とかする方法ありましったけ？\\nUNNESTするしか無理？',)\n",
      "('<https://cloud.google.com/bigquery/docs/reference/standard-sql/array_functions?hl=ja>\\n```[OFFSET(1)]```\\n\\nでできるっぽい。', \"正に講座でやりましたー！\\n\\n```SELECT\\n\\xa0\\xa0\\xa0pagePath,\\n\\xa0\\xa0\\xa0SPLIT(pagePath, '/')[SAFE_OFFSET(1)]\\nFROM\\n\\xa0\\xa0\\xa0dlg_mart. page_views```\\n\", '```SAFE_OFFSET```\\nだと、NULLの時エラー出ないので、SAFE_OFFSET使ってあげるのが良さそうな気がします。', 'この辺の小ネタまで入れると中級から上級な感じがするw', 'よく出てくる関数の紹介って文脈でやってます。', 'こんな感じですねー！現場で使える所まで目指してますので！！', '今\\u3000presto -&gt;bq ですがチート評価欲しくなる。', '世の中に無いんですかね？', 'ありそうでない', '作ったらコアな人から結構ニーズありそうですね', 'TD→BQはちらほら聞くので', 'と思いつつ100個ぐらい書き換えましたw')\n",
      "('Gento Sunoda',)\n",
      "('Riita Satsuki',)\n",
      "('BQ', 'DWH', 'BigQuery', 'GCP', 'ML', '設計')\n",
      "('Data Lake→DWH→DatamartをすべてTDで処理しているクライアントがいるんですが他事業部のデータも集約したいらしく、そうなるとTDだけではコスト高すぎるのでData LakeとしてBig Queryを検討してます。\\nその場合、Data Lake→DWHまではBig Queryで処理してData Martの部分をTDで処理するのが一般的ですかね？ ',)\n",
      "('Bigqueryだけではだめなんですか？', '将来的にはBigqueryだけという案もあるのですがそれには大幅な改修が必要なので一旦共存する形にするしかないのかなと。。。', 'これまで書いた分析クエリが使い回せないということですか？\\nそれとも中身のデータの移行のはなしですか？', '両方ですね笑', 'TresureData高すぎなので、\\n正直BigQueryに早々に移行したほうが安くすみそうですけどね。\\nDataLakeのdump作ってBigQueryに突っ込めばいいような気もします。\\n分析クエリはちょっと大変かもしれないですね。', '高いですよねw ただ会社間の付き合いもあるのでコストだけで切り捨てるわけにもできないですし、私もTDの導入サポートの仕事が最近はメインなので複雑ですw\\n\\nデータそのものの移行というより、YMLの修正だったりのほうが時間かかりそうですね。', 'ymlですか…？', 'オンプレからembulkでTDにデータ転送してますがテーブルがたくさんあるのでBQに向き先変えるとなるとそこも手が入りますね。', 'あー、DBからのバッジがembulkなんですね。\\n&gt; Data Lake→DWHまではBig Queryで処理してData Martの部分をTDで処理\\nだと結局話変わらなくないですか？', 'TDとBigQueryつなぐ設計もそれはそれで大変そうな気がするので、\\nLakeがBQなら全部BQでいいと思うんですよね。\\n機能的にもGCPの他のツールと繋ぎやすいので、BQが便利だなぁって思っています。', 'TDをそのままいかしつつ、リソースをためないという思想だと\\nTDを中間DBにしてBQ（Lake &amp;DWH）にデータ移したら削除するみたいな変則的な運用になるんですかね...\\n\\nBQに集約した方が明らかに運用は楽ですよねw', 'いっそembulkもやめてDumpにするというのもありますよ')\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "('Gento Sunoda',)\n",
      "('BQ', '前処理')\n",
      "('一般的といえば一般的ですね。\\n特にTDはメモリ制限あるのでBQ側で前処理オススメします。(コストかかるけど時間が早い。)\\nただデータの読み込みは工夫ひつようです',)\n",
      "('なるほど、やはりデータフローからガラっと変更しないとダメですよね。。。ありがとうございます!',)\n",
      "('maimai',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人',)\n",
      "()\n",
      "('検索キーワードについて質問です。\\n全て同じ期間（１週間）、全て同じキーワードです。\\n以下３つで検索キーワードを比較した場合に、GA連携サーチコンソールのクリック回数が少ないようです。内部トラフィックをGAに設定しているのでそこの差が出たりするのでしょうか？\\n\\n\\n・データポータル連携サーチコンソール：クリック11回、表示20回\\n\\n・GA連携サーチコンソール：クリック3回、表示20回\\n\\n・サーチコンソール：クリック13回、表示20回\\n\\n\\nsearchコンソールの反映時間考慮して2/14日が締めとしています。',)\n",
      "('ＵＲＬのインプレッションとサイトのインプレッションが合算されるとかあったりしますか', 'GAは有償と無償で機能が違いすぎるのとその割には知見が少ない\\u3000泣', '今の会社無償ですね…\\n有償のもサンプリング？(忘れてきました)のせいで隣の人と数値が違うから確かめできんな！て憤ってたの思い出しました')\n",
      "('yuji.imuta',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "()\n",
      "('非線形回帰とノンパラメトリック回帰って違うのでしょうか？？\\n\\n説明変数と目的変数が非線形の関係であると仮定するならどちらも違いがあるようには感じないのですが、、、、仮定とかが違うのでしょうか',)\n",
      "('<http://cse.naro.affrc.go.jp/takezawa/faq1.html#Q1>', '厳密な区分はないっぽいですね・・・\\n\\nイメージ的には、モデル式をある程度数式化できるもので、その係数を探っていくような形をパラメトリック回帰（非線形回帰）ってイメージで良いのかなーと思います。', '非線形回帰≒一般化線形モデル\\n\\nって感じだと思うのですが、若干自信ないです。', '非線形回帰→モデルが線形じゃなくて、指数とか、対数とか、シグモイド関数で近似する\\n\\nノンパラメトリック→そもそもどんな分布に従っているか分からない。という感じかと。（X, Yの関係、誤差の分布共に）', '<@UMG0947NY>\\nという感じでいかがでしょう？', '<@UMG0947NY> 非線形回帰とノンパラメトリックというのは別々の概念です。\\nロジスティック回帰は非線形回帰ですが二項分布を仮定したパラメトリックなんですね。\\n非線形回帰という用語には厳格な定義はなさそうな気がしますが、たぶん線形回帰以外の回帰モデルは全て非線形回帰になると思いますよ。同様にノンパラメトリック回帰はパラメトリック以外の全て、つまり誤差に確率分布を仮定しない回帰モデル全て、となるかと。')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "()\n",
      "()\n",
      "('非線形回帰は複数の変数を持って表される回帰です。単回帰の複雑版です。\\nノンパラはそもそも母集団の分布が不明の状態で行われる回帰です。',)\n",
      "()\n",
      "('yuji.imuta',)\n",
      "()\n",
      "()\n",
      "('<@US85V53MK> <@UJRAL005U> <@UREUHGVAQ>\\n\\nみなさんありがとうございます！！\\nすこしずつクリアになってきました！！！\\nまたなにかあったらここに投稿させていただきたいと思います。。。すいません。。。',)\n",
      "()\n",
      "('Satoshi ｻﾄｼ',)\n",
      "()\n",
      "()\n",
      "('ノンパラはパラメトリカルな手法が絶対に使えない場合にどうしようか？う〜ん、じゃあ近しいもので近似を推定(分布を仮定しない → 分布関数自体を推定)しよう！というのがそもそもの動機です。',)\n",
      "()\n",
      "('しみずこうじ',)\n",
      "('Yohei Sato',)\n",
      "()\n",
      "('音声解析について学びたいのですが、良いサイト、本、講座などありましたらご教示いただけますと幸いです:man-bowing:',)\n",
      "('ちょっと古いですが、基本を学ぶには良かった気がします。\\n\\n<https://www.amazon.co.jp/dp/4627847114/|https://www.amazon.co.jp/dp/4627847114/>', 'ありがとうございます！:man-bowing:\\n本屋で探してみます！:pray:')\n",
      "('rizumu_tanaka',)\n",
      "('しみずこうじ', 'Katsuya Nagano', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('書籍', '教科書', '入門')\n",
      "('アンケートやインタビューの収集から分析までを勉強できる書籍などご存知の方いらっしゃれば教えてもらえませんでしょうか！\\n技術的なものより、こういう考えに則って質問を作る/分析すべきなどの、入門的なものが欲しいです\\n\\n今まで行動ログの分析が多かったのですが、来週あたりからユーザーにアンケートやインタビューを積極的に行っていくことになりそうなので、心構えとして読んでおきたいと思っています。',)\n",
      "('考え方でしたら\\u3000UXデザインの教科書\\n\\nインタビュー特化ですが\\u3000モデレーター聞き出す技術\\n\\nが良かったです\\n\\n\\n<https://www.amazon.co.jp/UX%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8-%E5%AE%89%E8%97%A4-%E6%98%8C%E4%B9%9F/dp/4621300377/ref=mp_s_a_1_1?_encoding=UTF8&amp;imageClass=hi-res&amp;keywords=ux%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8&amp;phoneCarrier=wifi&amp;phoneType=iPhone&amp;qid=1582445618&amp;rd=1&amp;sprefix=UX%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3&amp;sr=8-1&amp;view=Touch9|https://www.amazon.co.jp/UX%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8-%E5%AE%89%E8%97%A4-%E6%98%8C%E4%B9%9F/dp/4621300377/ref=mp_s_a_1_1?_encoding=UTF8&amp;imageClass=hi-res&amp;keywords=ux%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E3%81%AE%E6%95%99%E7%A7%91%E6%9B%B8&amp;phoneCarrier=wifi&amp;phoneType=iPhone&amp;qid=1582445618&amp;rd=1&amp;sprefix=UX%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3&amp;sr=8-1&amp;view=Touch9>\\n\\n\\n<https://www.amazon.co.jp/%E3%83%9E%E3%83%BC%E3%82%B1%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%BB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%93%E3%83%A5%E3%83%BC%E3%81%AE%E3%83%97%E3%83%AD-%E3%83%A2%E3%83%87%E3%83%AC%E3%83%BC%E3%82%BF%E3%83%BC-%E8%81%9E%E3%81%8D%E5%87%BA%E3%81%99%E6%8A%80%E8%A1%93-%E6%97%A9%E5%B0%BE-%E6%81%AD%E5%AD%90-ebook/dp/B00KWWDO7M/ref=mp_s_a_1_2?_encoding=UTF8&amp;imageClass=hi-res&amp;keywords=%E3%83%A2%E3%83%87%E3%83%AC%E3%83%BC%E3%82%BF%E3%83%BC%E8%81%9E%E3%81%8D%E5%87%BA%E3%81%99&amp;phoneCarrier=wifi&amp;phoneType=iPhone&amp;qid=1582445751&amp;rd=1&amp;sr=8-2&amp;view=Touch9|https://www.amazon.co.jp/%E3%83%9E%E3%83%BC%E3%82%B1%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%83%BB%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%93%E3%83%A5%E3%83%BC%E3%81%AE%E3%83%97%E3%83%AD-%E3%83%A2%E3%83%87%E3%83%AC%E3%83%BC%E3%82%BF%E3%83%BC-%E8%81%9E%E3%81%8D%E5%87%BA%E3%81%99%E6%8A%80%E8%A1%93-%E6%97%A9%E5%B0%BE-%E6%81%AD%E5%AD%90-ebook/dp/B00KWWDO7M/ref=mp_s_a_1_2?_encoding=UTF8&amp;imageClass=hi-res&amp;keywords=%E3%83%A2%E3%83%87%E3%83%AC%E3%83%BC%E3%82%BF%E3%83%BC%E8%81%9E%E3%81%8D%E5%87%BA%E3%81%99&amp;phoneCarrier=wifi&amp;phoneType=iPhone&amp;qid=1582445751&amp;rd=1&amp;sr=8-2&amp;view=Touch9>', '本の紹介ではないですが、アンケートは文章に気をつけないとバイアスを生みやすいのでちゃんとした本読んだ方がいいです。\\n\\n極端な例だと、「hogehogeという思想は過去流行ったが、hogehoge宗派が起こした凶悪事件が目立つようになった。あなたはhogehoge宗派についてどう思いますか？」みたいな質問の仕方だと、ネガティブな情報を与えたあとに質問をしているので、自然状態よりも否定的な回答をしがちになります（マスコミがよくやってるやつですね）。\\nこれはわかりやすい例ですが、結構バイアスかかる落とし穴があるのでそのあたりちゃんと書いてそうなやつ選んだ方がよさそうですね。', '「モデレーター聞き出す技術」気になったので買ってみます！', 'なるほどなるほど・・！確かに、意図せず誘導してしまうことがありそうなので気をつけないとですね。\\n&gt; アンケートは文章に気をつけないとバイアスを生みやすい', 'バイアス生み出さない、はインタビューも同様で、モデレーター聞き出す技術はその辺も書いてあったと記憶してますね。\\n\\nUXデザイン、そういえば著者が概ねの内容書いたスライド公開してますね。\\n\\n<https://www.slideshare.net/mobile/masaya0730/ux-2019|https://www.slideshare.net/mobile/masaya0730/ux-2019>', 'アンケート系の質問結構来るので、2冊ほど書籍買ってみました。\\n\\n良さそうかどうか、内容見て回答しますねー！')\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Satoshi ｻﾄｼ', 'Riita Satsuki')\n",
      "('機械学習', 'データエンジニア', 'クラウド', 'BQ', 'digdag', 'GCP', '前処理')\n",
      "('機械学習エンジニアとして最低限のインフラ知っておこうというところでdockerとlinuxとクラウド（gcp）あたり軽くなぞってあとはCD/CI（おそらくcircleCI）やろうかなって考えているんですけど、この辺って機械学習エンジニアとかデータエンジニアってやる必要性がどの程度あるか教えていただきたいです。',)\n",
      "('機械学習エンジニアなら全部必須で、データエンジニアならCD/CIまではいらないって温度感ですかねー。\\n\\nあと、データエンジニアならワークフローエンジン（cloud composer）などが重要になって来るかとー！', 'Cloudcomposerって初めて聞きました\\n今ら機械学習エンジニア志望ですがちょっと調べてみます！', 'digdag、AirFlow（CloudComposer）辺りはデータパイプライン作る時に大事っすね！', 'ちゃんと言葉くらいは理解するようにします:thinking_face:', 'GCPはあと３年で赤字が回復しなければ大部分のサービスが打ち切られる可能性がで、それを加味した勉強をしたほうがよろしいかと！', 'あんまりやりすぎないようにします笑笑', '<@US85V53MK>\\nそれ知らなかったのですが、ソースとかってどれなのでしょう？\\u3000結構重要なことな気がします。', '勝又さんのyoutubeで見ました', '！', 'なぜGoogleはクラウド分野で2023年までにAmazonとMicrosoftを上回らなければならないのか？ - GIGAZINE\\n<https://gigazine.net/news/20191218-google-cloud-2023-deadline/|https://gigazine.net/news/20191218-google-cloud-2023-deadline/>', '<@UKT5BQD3P> \\n村上さんが仰っているairflowというのは、\\nDataOpsと呼ばれるような分野で用いられているもので、\\n何度も同じ前処理を記述するのは無駄なので、データを3分類し、データを必要とする利用者にいつでもデータを届けようというものです。\\n\\n実際にぼくが作った基盤はこんな感じです。\\n参考にしていただけると\\n\\n<https://pbs.twimg.com/media/EPdqZ3vUEAAzSXQ?format=jpg&amp;name=large|https://pbs.twimg.com/media/EPdqZ3vUEAAzSXQ?format=jpg&amp;name=large>', '<@UNFAV5EDB> \\nDataops、、、初めて聞きました\\n確かにbigqueryでも大きな会社だと人によって使う物分けたほうがやりやすそうですね')\n",
      "('Kom',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'しみずこうじ')\n",
      "('AI', 'データサイエンティスト')\n",
      "('一般的にデータサイエンティストとAIエンジニアって分けられていますがかめさんのこのツイートを見るとAIエンジニアもデータサイエンティストもほとんど違いはないのかなって思うのですがどうなのでしょうか？\\n<https://twitter.com/usdatascientist/status/1230093510394540035>',)\n",
      "('<@USU3HJY20>\\nそこら辺の定義、人によって結構揺れがあるイメージですが、\\n\\n課題設定、モデリング、分析が主\\n→データサイエンティスト\\n\\nAIに関するシステム開発が主\\n→AIエンジニア\\n\\nってイメージかなぁと思います！', '<@UJRAL005U>\\nなるほど！そうなるとここで言ってる画像や音声、テキスト解析のアルゴリズムを作りアプリに組み込める人っていうのはこの文脈だとAIエンジニア寄りの仕事ってことになりますかね？', '関係しそうなメルカリの記事がありました:blush:\\nちょっとアプリ、ウェブ系も含んでるようですが……\\n\\n<https://developers.cyberagent.co.jp/blog/archives/25162/|https://developers.cyberagent.co.jp/blog/archives/25162/>', '読みました！やはりデータサイエンティストでもエンジニアリングに関する知見はかなり有用なんですね。\\nありがとうございます:blush:', '早速読んでいただきありがとうございます！\\n\\nお役に立てましたら何よりですー！')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('K',)\n",
      "('増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'しみずこうじ', 'ﾋﾛﾘｰ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'sho.kumada')\n",
      "('SQL', '書籍', '入門', '初心者', 'GCP', '可視化', '教科書', '入門書', '統計')\n",
      "('まだSQLを触ったことが全くないのですが、勉強するのにおすすめの書籍等はありますか(´・ω・｀)？',)\n",
      "('ミック\\u3000ゼロから\\u3000アルバート\\u3000分析\\u3000黒魔術順ですかね', '前に同じ質問をしていただいた回答をまとめてますので、よろしければご参考ください:blush:\\n\\n<https://scrapbox.io/molt/SQL%E3%81%8A%E3%81%99%E3%81%99%E3%82%81%E5%AD%A6%E7%BF%92%E6%B3%95|https://scrapbox.io/molt/SQL%E3%81%8A%E3%81%99%E3%81%99%E3%82%81%E5%AD%A6%E7%BF%92%E6%B3%95>', '<@UL2TY2ERL> さん、<@US69FTTH6> さん\\n回答ありがとうございます〜！！ミック、、？？アルバート、、？？ってなってましたが通称そう呼ばれる書籍があるのですね！\\n非常に参考になりますありがとうございます〜！！', 'やっていないですけどおそらくググれば上には来るはずです。\\nさらに上だと\\u3000茶色いミック本が最上位となります。', '自分もよく間違えるのでアレなんですが、アルバートじゃなくてアルベルトらしいです:sweat_smile:', 'すみませんw', '私も間違えるたびに怒られます笑\\n\\nアルベルトじゃないですけど、面接でも間違えたことあります笑', 'まだ業務でも趣味でも使う予定はないけれど基礎知識だけは蓄えておこうかなと思った次第です！入門(最初にやるべき！本)ってみんな違う観点からいろんな本をお勧めしているイメージだったので、こちらで皆さんの経験にお伺いしようと思いました🥺\\nムック本から勉強してみようと思います:relaxed:！', 'これはアルバートも正解、、笑', '実務をイメージしながらSQLを理解していきたいならこれ！\\nサイト分析の章は読み飛ばしてもいい\\nグーグルアナリティクスでできるし、そもそもログをエクスポートするのって年間100万円くらいする法人版グーグルアナリティクスじゃないと不可能だしw\\n<https://www.amazon.co.jp/%E3%83%93%E3%83%83%E3%82%B0%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E3%83%BB%E6%B4%BB%E7%94%A8%E3%81%AE%E3%81%9F%E3%82%81%E3%81%AESQL%E3%83%AC%E3%82%B7%E3%83%94-%E5%8A%A0%E5%B5%9C-%E9%95%B7%E9%96%80-ebook/dp/B06XRWPPC9/ref=pd_aw_sbs_351_1/358-2349059-2079266?_encoding=UTF8&amp;pd_rd_i=B06XRWPPC9&amp;pd_rd_r=bf686cfb-4f23-457a-addd-cb8847566a88&amp;pd_rd_w=dTd5G&amp;pd_rd_wg=yQfb4&amp;pf_rd_p=1893a417-ba87-4709-ab4f-0dece788c310&amp;pf_rd_r=PWM4XWNDHKP3QQBFXJ65&amp;psc=1&amp;refRID=PWM4XWNDHKP3QQBFXJ65>', '<@UT5FYCM6D>\\nSQLのコンテンツ作って販売してます！\\n\\n感想は購入者の方々が教えてくれるはず！！\\n\\n個人的には10年戦えるSQLがおススメですね！\\n\\n<https://brain-market.com/u/greenmidori/a/bQO4IzNgoTZsNWa0JXY|https://brain-market.com/u/greenmidori/a/bQO4IzNgoTZsNWa0JXY>', '正式にはアルベルトですが、アインシュタインから取ってるのでニュアンスとしては合ってるかと！', 'だから読みにくいドイツ語読みなんですね笑', 'アインシュタインがネーミングなのか！\\nなんでああいう会社名なのか気になってた！', '<@ULKPET3UK>さん\\n情報ありがとうございます〜！この本書店に並んでいるの見たことあります！\\n実際学ぶときって実務で使うわけではないけれど、実務イメージできるように勉強するほうが身につく知識としてはより良いものになるのですかね:face_with_monocle:？\\n実務ベースの書籍類って結構仮定とかが記載されていない(使う上で最低限コレ覚えてそのまま使えよ感)があるなぁと感じているのですが、、どう考えますか:face_with_monocle:？', '<@UJRAL005U> さん\\nわぁ！教材なんてあったのですね！\\nこちらって一度購入したらずっと使えるものですか？レビューにFree Trialの間に〜との記述があったので時限付きなのかなって、、', 'はい、大丈夫です！\\n\\nトライアルはGCPの方の話ですね！', '大体どれくらいの量になりますか、？？(仮に1日2時間程度取り組むとして)', '1〜2週間程度だと思います！\\n\\n<@UMQ7CDJUR> さんが直近取り組んだはずなので、目安教えて貰えると！', '<@UT5FYCM6D>\\n&gt; 実務イメージできるように勉強するほうが身につく知識としてはより良いものになるのですかね\\nそうですね。SQLは覚えてあと、それを駆使して深掘りしていくときに実務のケースを想定するといいです。\\n僕が紹介したやつだと、DMMのデータ分析組織の方々が書いた本なので、\\nECサイトのアクセスログや購入ログを分析していく流れに沿って、書くクエリが出てきますー', 'ちなみにSQLレシピは、黒魔術書と言われるくらいなので、入門書ではないですねw', 'つい最近、初心者で面談先から出されたSQLの課題をなんとかやった身からしますと、構文を一通り眺めたら、実践あるのみ、が一番効果がありました笑', '<@ULKPET3UK> さん\\nそうなのですね、、理論武装しないと少し不安になる芸人張ってますがやはりその方がいいのですね、、プログラミング言語の習得と同じように実践あるのみですね、、\\nSQLって実際に使用するときもアクセスログでは無いってだけで手法、考え方は同じっていう考えで合ってますかね？', '<@UJRAL005U> さん\\n割と早いですね！一月くらいはかかるかと思ってました！\\n他の方がオススメしてくれた書籍も可能なら本屋等で立ち読みしてみてから検討しようと思います！\\n\\nみんながデスクに置いてると言っていたので僕も魔術書を置きたくなりました、、笑', '<@US69FTTH6> さん\\nそのやり方ってその場しのぎの知識になっちゃったりはしないですか、、？？\\n大きな流れ、仕組みを把握してないとその場その場で調べて進めていく芸人になってしまいそうなのを恐れています、、', '<@UT5FYCM6D> そうはならないと思いますから大丈夫です:man-gesturing-ok:\\nやってみる→わからない→調べる→挙動を見て理解する、の繰り返しで定着してきます:blush:\\n理解を先行させてると、案外手が動かないですし、理解したつもりになりがちです:scream:\\nその後に本を読めば腹落ち感もあります:laughing:', '<@UT5FYCM6D> 村上さんの教材は適度な分量なので、初心者の私も二週間で完了できました。dataportalでサクッと可視化できて楽しいですよ。レビューで無料枠もいただけますし:laughing:', '<@US69FTTH6> さん\\nやはり先に手を動かした方がいいのですね、、\\n理解したつもりになりがち、はすごくわかります笑\\u3000統計の教科書一冊頭に叩き込みましたけど実際に自分がそれを使えている姿をイマイチ想像できない笑\\n手を動かせる教材を探すことにします、！！！', '<@UMQ7CDJUR> そうなのですね！なんやそれは嬉しい！\\nどれくらいまで使えるレベルになりましたか？定着レベル、と言いますか、', '以下でいうところの基礎レベルだと思います！\\n<https://sql.analytics-and-intelligence.net/sql-level/>', '「基礎からのMySQL」を合わせて読みましたが、村上さん資料の方がハイレベルでした。\\n<https://www.amazon.co.jp/%E5%9F%BA%E7%A4%8E%E3%81%8B%E3%82%89%E3%81%AEMySQL-%E7%AC%AC3%E7%89%88-%E5%9F%BA%E7%A4%8E%E3%81%8B%E3%82%89%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-%E8%A5%BF%E6%B2%A2-%E5%A4%A2%E8%B7%AF/dp/4797393114>', '<@UMQ7CDJUR> さん\\nはえーっ！入門レベルじゃ物足りないなぁと思ってレベル表を眺めましたが基礎レベルまでカバーされてるのですね🥳\\n書籍よりも良いとは、、一考の余地ありかもしれませんね、、ありがとうございます！！')\n",
      "('ﾋﾛﾘｰ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人', 'maimai', 'しみずこうじ')\n",
      "('レコメンド',)\n",
      "('チャンネル推薦機能なんて前からありましたっけ？\\nそれとも、DLGの誰かが実装したbotなのかな？',)\n",
      "('slackのレコメンド機能ですかね？？\\n\\n共起行列とか見てみたいですねー！', '公式の機能なんですね！結構便利！特にコミュニティでslack使ってる場合はいいですね', 'たまーに閲覧少ないと辞めます？と聞かれます', '辞めたほうがいいよレコメンドまでw\\n確かにチャンネル多すぎると一覧性下がりますものね', '辞めますかあるのは知りませんでしたｗ', 'slackお節介（褒め言葉）ですね笑')\n",
      "('しみずこうじ',)\n",
      "('はやと-休学中の文系学生',)\n",
      "('BQ', 'TensorFlow', '深層学習')\n",
      "('質問させてください！\\n実務だとお客さんがそれを使ってる以外で、TensorFlow、Keras、Pytorch等の使い分けはどんな感じでしてるんでしょうか？:man-bowing:',)\n",
      "('僕はkerasしか実務では使ったことなく、又聞きの情報も入りますが、、、\\nKerasとpytorchだと\\nKeras→直感的でわかりやすい\\nPytorch→研究論文が実装されたもの（unetとか）をそのまま使えるツールがkerasより入ってる\\nって感じなんで、kerasでできる範囲はkerasでいろんなもの使うときはpytorchっていうイメージでした！', 'tensorflowはあんまり分からないですが、kerasのバックエンドでtfが使われてるんで、kerasとpytorchで十分なのかなと（これは間違ってるかも）', '<@UKT5BQD3P>なるほど、ありがとうございます！ Pytorchは研究でよく使われているというのは何やら読みました！\\nKeras（使ったことないですが。。）使いやすそうですね', 'もし深層学習するなら最初はkerasがおすすめです！', 'ありがとうございます、Keras、手を出してみます！')\n",
      "('はやと-休学中の文系学生',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "('画像をgoogle cloud visionのapiを使って分類しようとしてるんですけど、train部分から何プログラミングじゃなくてapiで実装しようとしてるんですけど実際にやってるいい例が見当たらなくて、もしやったことある方がいたら教えてもらえると嬉しいです！',)\n",
      "('チュートリアルとかヘルプとかは無さそうですかね？\\n\\n新しめの技術は公式ドキュメント頼りにやることになりがちな気がします。', 'チュートリアルはあったんですけど、サンプルはこうやって動くよって感じだったんですよね、、、もうちょっと見てみます。')\n",
      "('西岡健一',)\n",
      "('K', 'Yohei Sato', 'Katsuya Nagano')\n",
      "('機械学習', 'ML')\n",
      "('<!here> 皆様の知見を拝借いたしたく！:sob:\\nやりたいこととしましては、多数の説明変数が用意されたクラス分類を行い、その予測結果を0/1ではなくx%の確率で1っぽい。的な出力をしたいと思います。\\n\\n1つ目のケースは有効(1)である可能性(スコア)が20で、2つ目のケースでは80である\\n\\nのような出力をしたいのですが、このような場合はどうされますか？\\n\\nもしヒントになるような事例や手法がありましたらご教授ください:man-bowing:',)\n",
      "('NNのclassifierはsoftmaxで確率に変換されて出力されますがそういうお話ではないですかね、、', 'NNじゃなくても、それぞれの判別モデル作って、softmaxっぽいロジックを作れば良いような気がしますね。', '<@UT5FYCM6D> <@UTRSFL2LS>\\nご意見ありがとうございます。softmaxについてみてみましたがまさにこれです:man-bowing:\\n\\n@here\\n勉強不足で恐縮なのですが、softmaxの値をpredictメソッドのような感覚で取得することは可能でしょうか？\\nそもそもそういうものではない？', 'predictメソッドというのは、機械学習でのfit~predictの流れのような意味ですかね？\\nそれでしたら、同様に出力可能です。\\n\\n過去にKaggleで使用した、Kerasを使用して作成したモデルですが、真ん中あたりでout_softというところで199このクラス分類をしています。', '（意図せず投稿されちゃった）\\nで、最終的に予測結果としてこのように199このクラスに分類したときの予測結果が帰ってきます（0~1の範囲）', '&gt; predictメソッドというのは、機械学習でのfit~predictの流れのような意味ですかね？\\nはい。その流れです。汲み取っていただいて嬉しいです\\n\\nサンプルでいただいたソースですが、Kerasがわからないせいかイメージがつかないです:sob:\\nsklearnのMLPClassifierなどで実装されているとたすかるのですが。。。orz', '*predict_probaかな？*', 'mlpclassifierを使ったことがなく、、ごめんなさい:sob:\\npredict_probaで出せるっぽいですね！ボクは使ったことないのでなんとも言えませんが試してみる価値はありそうです！', '<@UT5FYCM6D> いえいえ。ありがとうございます。\\nとても参考になりました！色々と試してみます', '既に結論出ていますが、sklearnの場合はpredict_probaで合っているかと。普通の0/1出力はpredict_probaの内容を閾値0.5で吐いている感じですね（厳密には違うらしいですがよくわかってない', '<@UPR6BE9S6> 回答ありがとうございます！まさにこれでした:grinning:')\n",
      "('しみずこうじ',)\n",
      "('K',)\n",
      "('jupyter', 'kaggle')\n",
      "(\"お知恵をお貸しください！:man-bowing:\\n\\n添付のjupyter-notebookのデータを使い、kaggleのタイタニックのデータを使って、覚えたてのブースティングを使って、覚えたての各種モデル ※を回してみました。\\n\\nすると、k-近傍法だけ次のようなエラーが出ました。\\n> *ValueError*: KNeighborsClassifier doesn't support sample_weight.\\n> （訳）k-近傍法はsample-weightをサポートしてません。\\n※ロジスティック回帰、サポートベクターマシン、決定木、k-近傍法、ランダムフォレスト、勾配ブースティング\\n\\n調べるとk-近傍法のライブラリの解説の、score()のパラメーターに sample_weight があるのはわかったのですが、このエラーを回避する策がわかりません:sweat_smile:\\n<https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html>\\n\\n他にも調べると、ロジスティック回帰の記事ですが、\\n> sample_weightオプションは外れ値データを除くために存在する\\nというのも見つけましたが、ピンとこず・・・。\\n<https://medium.com/micin-developers/decipher-github-lr-sw-40e519a13c0a>\\n\\nどうすればこのエラーを回避できるのか、ご教示いただけると助かります:man-bowing:\\nよろしくお願いいたします！\",)\n",
      "('stackoverflowに似た質問がありました。\\nAdaboostingはあくまで弱い識別器に対して使用可能であるため、強い識別器であるSVMや、sample_weightを引数にもたないAdaBoostingには使用できないようです。\\n<https://stackoverflow.com/questions/18306416/adaboostclassifier-with-different-base-learners>\\n\\nAdaboostingはデフォルトのDecisionTreeでのアンサンブル用途以外で使用したことがなかったため僕も勉強になりました、、、', 'なるほど、そもそも向いてないモデルがあるし、k-近傍法はもはやエラーになるくらい向いてない、ということなんですね……ありがとうございます！:pray:', '個人的に、AdaBoostはアンサンブル用途((RandomForest+ExtraTrees+Ada+GradientBoosting+SVC)/5)で使用されていることが多いように感じます（あくまでAdaboosting(base_estimator=None, …)）\\n僕もこの辺りは全然詳しくなく、知見がないので有用な使い方とか発見したらぜひ教えてください！')\n",
      "('shimizu.yohei',)\n",
      "('尾銭泰徳 ﾃﾞｰﾀｻｲｴﾝｽ勉強中', '増田貴志.ｷｬﾘｱ模索ﾃﾞｰﾀ整理人')\n",
      "('DX', '設計')\n",
      "('何かコードレビューの作法などがまとまっているサイトなどがあったら\\n教えて頂きたいです:man-bowing:',)\n",
      "('品質系の業務の知見は私も乏しいのですが、\\nコードレベルであればLinterなどの静的解析に任せっきりです。。。\\n<https://pmd.github.io/pmd-6.21.0/>\\n\\n設計的な部分だと最近だったらDXcriteriaをよく目にするかもです。\\n<https://github.com/cto-a/dxcriteria/blob/master/asset/image/dxcriteria201912.pdf>\\n\\n少しでも参考になれば。。。', 'コードを憎んで人を憎まずなどの精神論とか体制ですか？', 'そうですね！以前無意識に宗教戦争に踏み込んでしまったりして…。\\nレビューするポイントとかがわかればな〜と…')\n",
      "('ｱﾗﾝ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'tomo.h')\n",
      "('Linux', 'Docker', 'MeCab', '形態素解析', 'NLP')\n",
      "('自然言語解析でJanomeであったり、Mecab の比較と用途について教えていただきたいです',)\n",
      "('どちらも基本的には形態素解析に使用するライブラリですね！\\n\\n精度は同じデータセットに基いてるのであまり変わらずで、ザックリ以下の感じかと！\\n\\njanome・・・python環境構築楽だが早い\\nmecab・・・少し手間かかるけど早い\\n\\n迷った場合は基本的にはmecab使っておけば大丈夫なのかなぁという温度感だと思います！', 'Windowsで使うならjanomeってイメージですね。。Windowsでmecabを使うのはいろいろと苦労が。。。わたしはjanomeはほとんど使ったことないです。Windowsを見かけたら、とりあえず仮想環境組もうかと言ってますw', 'なるほど。確かにLinuxベースの環境想定していました・・・\\n\\nWLSとかでもつらい感じですか？', 'WSLでもmecab-pythonがバグった記憶があるんですよね。。ただ、当時素人だったので、私の問題かもしれません。。\\nNLPやるのに不都合が多すぎて、Ubuntuに乗り換えました。', '&gt; Ubuntuに乗り換えました\\nLinuxベースの環境でやるのが良いですよね。colabなどのnotebook環境ならLinuxが裏で動いてるシーンも多いと思いますので、Linuxでやって行くのが良いかと思います。', '最近はMacだろうが、WindowsだろうがDockerの上でやりますね。。IPA辞書がeucなので、ソースからインストールするときとか、システム辞書書き換える時に、LinuxでもMeCabはトラップがありますね。。。\\nわかってしまえばなんてことないですが。。私はだいたい辞書ファイルを全部utf-8に変えてしまいますw\\nそれかaptで入れるか。。')\n",
      "('Hiroki Narita',)\n",
      "('永田ゆかり Yukari Nagata', '吉村政彦ｰ産業ｽﾊﾟｲ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', '戸嶋\\u3000龍哉')\n",
      "('データサイエンティスト', '機械学習', 'kaggle', '可視化', '設計', 'フリーランス', 'マーケティング', '初心者', 'ディープラーニング', '前処理')\n",
      "('長文の質問失礼致します。\\n\\n当方，データサイエンティストを目指しているCS専行学部3年生です。現在、学部でデータサイエンティストとして就職するか、大学院までいくか迷っております。\\n\\n先日、データサイエンティスト向けの長期インターンに参加したところ、採用も考慮にいれたインターンでもあったそうで、企業さんのほうから良いお誘いがありました。\\n新卒の年収や待遇も良く、何よりインターンで大きな成長を感じたこと，プロのデータサイエンティストが多数所属していることなど，とても良い企業さんだと思いました。\\n\\n学部で就職を迷っている理由としては，\\n\\n・大学院の進学を考えていたため、就職活動は全くしていなかったこと\\n・企業さんからは、「学部からでも，修士を出たあとでも良い」と言ってもらえたこと\\n・現在所属している研究室がデータサイエンスや機械学習を専門とする研究室ではないこと\\n・大学院進学のために奨学金を借りる必要があること\\n・社会人修士という道もあること\\n・今後のデータサイエンティストのキャリアとして学部生であることは不利になる可能性があること\\n等\\nが挙げられます（箇条書きで申し訳ありません）\\n\\nこれから研究室の先生や，色々な人に相談をしようと思いますが，\\nデータサイエンティストとして働いているプロの方々や，データサイエンティストのキャリアを考える方々が集まる，このギルドの皆様の意見がほしいと思っております．\\n\\n長文かつ，個人的な質問になりますが，よろしくお願いいたします．',)\n",
      "('Naritaさんこんにちは、永田ゆかりと申します。データに関わるコンサルティングファームの代表をしています。\\n私の個人的なオピニオンとしては、良い企業と良い出会いがあったならば、就職は素敵な選択肢になるものと思いました。\\n理由としては、Naritaさんがどのようなビジョンかによりますが、社会人大学院進学の方が総合的なコスパが良かったりするからです。というのも、私は学部卒でUSのMBAにいこうとしていたのですが、現地では業務経験、実務経験がないとわりとディスられがちであり、ディスられるだけならまだいいのですが、やはり身になるものも異なってくるためです。国内修士と海外MBAはまた異なるものの、何もビジネス的観点で想像できるタネがない、議論材料（発言のもととなる実務材料）がない状態でいくのは、他の生徒とリアルで生々しい議論もできないし、勿体無いなと思い、エッセイやTOEFLなど準備しましたが、その時は進学をやめました。今思うと、それは正解だったと思いますし、まわりにも３０を超えてから楽しく余裕を持ってプランして社会人大学をしている人もいますので、急ぐ必要もないのではないかと思います。\\n\\nまた、経営者的な目線では、業務経験、実務経験＞＞＞＞＞＞＞学歴、資格なので、現在のまま就職してもデメリットはほとんどないように思います。また、採用や仕事がうまくいくためには技術や知識以外の要素も非常にたくさんあるので、まるっと一旦経験しつつまた違った景色でデータサイエンスを俯瞰してみてから大学院にいくのも素敵なことだと思いました。\\nずっと研究自体をしたい、という価値観であればずっとアカデミアというのもありだと思います。\\n\\n大した人間でもないのに偉そうに長文失礼しました！１ミリくらいご参考になればw', '正に金言アドバイス！', '<@UUMB12SGZ>様\\n\\n非常に参考になる回答をありがとうございます．\\n\\n&gt; &gt;大した人間でもないのに偉そうに長文失礼しました！１ミリくらいご参考になればw\\nとんでもございません！\\n永田様自身の御経験，経営者的視点での根拠，論理的かつ納得のできる内容で感銘を受けました．\\n\\n&gt; &gt;社会人大学院進学の方が総合的なコスパが良かったりするからです。というのも、私は学部卒でUSのMBAにいこうとしていたのですが、現地では業務経験、実務経験がないとわりとディスられがちであり、ディスられるだけならまだいいのですが、やはり身になるものも異なってくるためです。国内修士と海外MBAはまた異なるものの、何もビジネス的観点で想像できるタネがない、議論材料（発言のもととなる実務材料）がない状態でいくのは、他の生徒とリアルで生々しい議論もできない\\n&gt; &gt;まるっと一旦経験しつつまた違った景色でデータサイエンスを俯瞰してみてから大学院にいくのも素敵なことだと思いました。\\nこれは，僕の知らなかった事，かつ，とても納得のいく内容だと感じました．\\n\\nこれは，個人的には，普段の勉強で知っている感覚だとおもいました．\\n自分のレベルにあった勉強ができたときは大幅なレベルアップができる，また，立ち返ったときに，「これってこういう意味だったのか！」となったときに，大幅レベルアップができる，こういったことはたしかに経験してきたことでした．\\n\\nやはり，多くを知ってから深堀りをしていく，「知っている」ということはとても大事なことなんですね！\\n\\n&gt; &gt; 経営者的な目線では、業務経験、実務経験＞＞＞＞＞＞＞学歴、資格なので、現在のまま就職してもデメリットはほとんどないように思います。\\nこれを聞いてとても安心しています．\\n専門職は実力重視ということはよく聞いていましたが，データサイエンティストは実際どうなのか，といったことは本当に無知でした．ありがとうございます．\\n\\n&gt; ずっと研究自体をしたい、という価値観であればずっとアカデミアというのもありだと思います。\\n個人的には，研究という行為はあまり好きではないです（笑）\\n「技術を磨く，勉強をする，利益になる，功績を得る，プレゼンをする」ことはすきですが，\\n「論文を書くこと」は非常に難しい上，その間，技術の勉強に手が回せなくなるので鬱になります（担当教官からの真っ赤な添削が戻ってくるたびに絶望します（笑））．\\nまた，「全く不明瞭な問題に挑む」ことは個人的にとても不安になるためです．．．（今後変わるかもしれませんが．．）\\n\\n長文，駄文の感想になりましたが，\\n永田様の意見は本当に，本当に，参考になりました（この言葉が薄っぺらく感じるほど感謝しております）！\\n本当にありがとうございます！', '<@UTP46GURL> さん、ご丁寧にありがとうございます。データ界隈の仕事自体は、ビジネス上の課題をデータの課題に翻訳できる人が勝つので、学歴・大学院云々よりも、マーケット感覚の鋭い人が評価されるものと思います。大学院はおろか弊社には専門卒の人もいますが、めちゃ優秀で顧客のペインポイントをつかむのがうまいです。めちゃ優秀なのですぐ昇給させてます。\\n仕事自体はデータサイエンスの技術や知見のみならず、\\n・顧客のペインポイントを解釈し\\n・それを言語化し\\n・うまくコミュニケーションする\\n・必要な技術をチューニングする（Too muchではいけない）\\nのようなこともおおいにかかわってきます。そもそもこれらができなければデータサイエンスの知識が輝いて見えないからです。\\nアカデミアでの研究・学習が好きで一生そこにいたい人も私は勿論リスペクトしますし、ビジネス側で活用したい人ならばそこで活躍できるスキルを磨く必要があると思っている派です。\\nただ、この領域は論文くらい書いてないと一人前にみない的な人も一部いらっしゃいますので（笑）、そのあたりはNaritaさんの価値観かと思います。\\nよろしければ弊社もインターンたくさんいますので新卒採用もしておりますので面接お受けいただければ嬉しいです（爆）', '<@UTP46GURL>\\n永田さんにかなり良いアドバイスをして頂いているので、コンサル、ビジネスサイドに強いアナリストの方面では、永田さんのおっしゃる意見でほぼ同意です！\\n\\n自分はどちらかというと、機械学習、R&amp;Dモデリング中心の視点から、大学院に行くメリットをお話させて頂きますね。\\n\\n「専門領域のプロフェッショナルとして活動しつつ、かつ、海外も視野に入れているなら、どこかのタイミングで院は言っておいた方が良い」\\n\\nというのが個人的な意見ですね。理由としては、大きく2店あります。\\n\\n1つ目は、ディープラーニングを中心とした機械学習を用いて新規サービスを開発をして行く上で、\\n\\n「既存研究をリサーチして整理した上で、それをビジネス、現場にマッチした形で実装する」\\n\\nということが主な仕事となるのですが、大学院などで、研究のプロセスを一通り経験している人は、ここら辺の理解や慣れが一段深いなぁと感じる部分が多いですね。\\n\\n自分も、論文実装などはあまり得意ではないので、新しい領域に着手するときは毎度大苦戦していますｗ\\n\\nまた2つ目の理由としては、海外では、\\n\\n「コンピュータサイエンスの修士を持ってないと門前払いされることが多い」\\n\\nという理由からです。海外を視野に入れたことがまだないので、具体的な事例は無いのですが、海外の企業ではデータサイエンティストの募集において、コンピュータサイエンスに類する修士号を持っていないと厳しいと聞いたことがあります。\\n\\nなので、目指すべき方向性を考えた上で、スキルセットをどこに寄せるかによって選択肢が変わって来るかと思います。\\n\\nただ、社会人大学院という選択肢もあるので、人生のどこかで大学院は行っておいた方が良いよね。って温度感ですね。', '<@UUMB12SGZ> 様\\n&gt; データ界隈の仕事自体は、ビジネス上の課題をデータの課題に翻訳できる人が勝つ\\nこれは，kaggleで得られない一方で，一番大切な問題設計（課題をkaggle等のような予測モデリング問題に落とし込む）力でしょうか！\\n僕自身，趣味で競馬分析を行おうとしたときに，kaggle等のコンペにはない，非常に難しいものかつ，一番重要なものだと感じました．\\n個人的には，実際の予測モデリングにおいて，コンペのような予測モデリングフェーズは，問題設計と，膨大な前処理を乗り越えたご褒美であると感じております！（笑）\\n\\n&gt; &gt;・顧客のペインポイントを解釈し\\n&gt; ・それを言語化し\\n&gt; ・うまくコミュニケーションする\\n&gt; ・必要な技術をチューニングする（Too muchではいけない）\\n&gt; &gt;アカデミアでの研究・学習が好きで一生そこにいたい人も私は勿論リスペクトしますし、ビジネス側で活用したい人ならばそこで活躍できるスキルを磨く必要があると思っている派です。\\nこれは，とても感じております．\\nこれは同時に僕が，大学院に進んで学んでおいたほうが良いのではないかと思ったスキルです．\\n大学院に進むことで得られるスキルや経験は，専門性はもちろんのことですが，\\n僕が大学院へ進学して，一番会得したいスキル，経験は，\\n・課題を理解する力\\n・表現し，いかにわかりやすく相手に伝えるか（プレゼン力や，わかりやすい図や資料の作成）\\n・学会発表などでボコボコにされた経験と，それを切り抜けられる能力\\nです．\\nこれらの経験やスキルは，学部で就職した場合には得られないもので，この経験をしていないまま就職をするのが，とても不安な要素でもあると思っています．\\n\\n&gt; よろしければ弊社もインターンたくさんいますので新卒採用もしておりますので面接お受けいただければ嬉しいです（爆）\\nありがとうございます！\\n就職を考える際（学部でも修士でも）は，業界全体は見渡しておきたいので，是非ともよろしくお願いいたします！\\n\\nまた，ツイッターほうをフォローさせていただいたのですが，可視化系の本をだされるとのことでとても気になりました！\\n学部か，修士のテーマは可視化にしたいとおもっていたので非常に興味があるので是非読ませていただきます！', '<@UJRAL005U> 様\\n\\n丁寧なアドバイスをありがとうございます！非常に参考になります！\\n\\n&gt; &gt;機械学習、R&amp;Dモデリング中心の視点から、大学院に行くメリットをお話させて頂きますね。\\n多角的な視点は本当に助かります．ありがとうございます．\\n\\n&gt; &gt;「既存研究をリサーチして整理した上で、それをビジネス、現場にマッチした形で実装する」\\nこれは，現在の僕には全く会得できていないスキルだとおもいました．\\n僕は学部３年で研究室に配属され，今年の4月から本格的に研究が開始になります．\\n現在，研究テーマに関連する論文のサーベイや，手法の検討をしています．\\nしかし，研究テーマに関連する論文を見つけるだけでもとても苦労しております．\\nこういったスキルは，研究という行為に長く触れ，沢山経験することで身につくスキルで，それこそ学部だけという短い期間では会得できないスキルだとおもいました．\\n\\n&gt; &gt;「コンピュータサイエンスの修士を持ってないと門前払いされることが多い」\\n海外は，日本よりも学歴社会というのはよく聞いております．\\n海外に絶対に行きたい！とは今はまだおもっていませんが，\\n「選択肢を増やす」という観点においてせめて修士号の取得は今後，必須であると感じております（できれば博士号も取りたいと思っています）．\\n\\n長文かつ駄文の感想になりましたが，本当にありがとうございます．\\n\\n実は，親に相談したところ，「全然就職活動をしていないのにほかを見ずに選択して大丈夫なの？急ぐ必要なくない？」と渋い顔をされました．\\n結局は，僕が選択することになるのですが，\\nこれは，僕自身一番心配していたことでした．\\n\\nしかし，\\n<@UUMB12SGZ>様\\n<@UJRAL005U>様\\nから共通して，むしろ「大学院を急ぐ必要がない」という意見をもらえて，\\nこれが個人的には一番響いております．\\n本当に，本当に，ここで質問してよかったとおもいました．\\n\\n明日，担当教官にも話をして，多くの意見をもらってから選択しようとおもいます！\\n\\n繰り返しになりますが，本当に参考になりました！ありがとうございます！', 'わたし自身は学部文系卒(笑)ですが、いまはUS、シアトルの開発チームと活動しておりますし、海外講演も呼ばれます。イギリスからもインタビュー依頼を受けています。\\n<https://tableaumagic.com/s1e6-a-conversation-with-yukari-nagata/|https://tableaumagic.com/s1e6-a-conversation-with-yukari-nagata/>\\n\\n<https://note.com/datavizlabspath/n/nd38dc0b276bf|https://note.com/datavizlabspath/n/nd38dc0b276bf>\\n\\nデータサイエンス領域だとまたちがうのかも知れませんが、わたしの領域では、修士やPh.Dだからどうだなどの障壁を今まで感じたことは一度もありません。逆に文系が欲しいという会社は国内でも海外でもよくあります。\\nそういう意味では、Naritaさんがどの程度学問としてみっちりやりたいか、というところかもしれませんね。', '<@UUMB12SGZ> 様\\n\\n本当に凄いです…！\\n\\n僕は、大ヤンキー工業高校出身で、大学もお世辞にも賢い大学ではないので、正直コンプレックスではあります。\\n\\n学歴はあるに越したことはないと良く聞きますが、もし大きな障壁になるならば全力で取り除きたいとは思います笑\\n\\nそれがどうということはないのですが、最近は、良い環境で学べれば圧倒的に効率が良いことに気づきつつあります。\\n\\nまた、勉強は好きなので一生続けたいですね！\\nなにも、一生やるのがデータサイエンス領域の勉強かは分かりませんが、これからやりたくなることの障壁が、お金になることは絶対に防ぎたいとはおもっています！\\n\\nなので、今、僕が好きなデータサイエンスという分野をもっと勉強して一線で戦える実力になるまでは今の勉強は続けたいと思ってます！\\nそれが修士を取るまでか、博士を取るまでかは自分の実力と相談して決めようと思っています！', '来年から社会人大学院です。\\n手短に、データサイエンスといってもやりたい分野が明確であれば、大学院に学部から行った方がよいと思いますし、特にビジネス系（数値分析や広告など）に携わりたいのであれば、学部卒でもオファーがあれば受けても良いかと思います。\\n最近はだいぶハードルが落ちましたが、社会人大学院はいろんな面で大変なところがあるので早いに越したことはないです。いつ取ろうがMasterはMasterになります。\\n大きなメリットはよりテーマが明確になることですね。特に実際の社会問題を2～3年ぐらい見越して真似べるのは良い点です。歳をとっても学び直しができることの体験は大きいと思います。（スキルの寿命が短くなるので）\\nデメリットは体力と機会損失も踏まえた収入減です。\\nフリーランスの場合は可動落ちますし、サラリーマンの場合でも基本給のみで年収が200万ぐらい落ちるらしいです。\\n（弟談、兄弟そろって良い歳して大学生）\\n30歳ぐらいがベターかお思います。', '<@UL2TY2ERL> 様\\n\\n貴重なご意見ありがとうございます。\\n社会人大学院にこれから通う、という立場の意見は非常に興味深いです！\\nドメインとしては、現在はあまり明確ではないではないですが、\\n先日経験したインターン先様では、ファイナンス系のデータを扱い、人の行動や心理を考えながら特徴量作りや分析をするのは、とても面白いと思いました！\\nなので、将来的にはファイナンスも面白いですが、広告やマーケティング領域等も良いと思っています(こう書いてみると、だいぶフワフワしているようです)！\\n\\nやはり体力的な問題もあるんですね。。！\\n将来的には家族を持つ、子供を育てるといったことも経験したいため、金銭面は特に考えないといけないかもしれないですね。。', '結構悩ましい点として、このご時世、新規参入者が多くあつまっているため、修士までいったときに初心者層に限定するとデータサイエンティストの供給が実需を超えている可能性があり、その場合現状より更に狭き門になるので、データ分析者にこだわるならば早めに社会人キャリアをスタートさせてしまって先行逃げ切り型を目指すのもありです。\\n\\n逆にCS系の修士であればこの分野の基礎体力はかなりつくので、もし数年後需要が減った場合、多少分野をずらしてしまっても良いならば修士取ったほうが長い目で見るといいかもしれません。', '<@UUAUDBR1N>様\\n\\n貴重なご意見ありがとうございます．\\n本当に頷けるご意見だと思っております．\\n\\nお誘いがあった企業さんでは，データサイエンティストとしての教育コースを最近，本格的にはじめたようで，スタート地点に立っている方々を育成してくれるという下地も整っているように思えました．\\n\\nまた，現在，データサイエンスブームが最高潮にも見える中，これから本当の実力を持っているデータサイエンティストが生き残っていくと思います．\\nだからこそ，データサイエンスに理解のある企業さんのもとに早めに就職し，技術を学び，埋もれないようにすることも，良いと思っております．\\n\\n&gt; 逆にCS系の修士であればこの分野の基礎体力はかなりつくので、もし数年後需要が減った場合、多少分野をずらしてしまっても良いならば修士取ったほうが長い目で見るといいかもしれません。\\n現在の僕としては，こんなにも楽しそうな職業はないとおもっておりまして，分野は，データサイエンス，機械学習の領域からは離れたくないと思っております．\\n\\n\\n繰り返しになりますが，とても参考になるご意見をありがとうございます！', '<@UTP46GURL> <@UUMB12SGZ> <@UUAUDBR1N> <@UL2TY2ERL> \\n\\nこのやり取り、相当有意義なので、SNSに投稿できればと思うのですが、Twitterでキャプチャ取って投稿しても大丈夫ですか？？', 'いいですよ〜', '良いですよ。\\n（雑に書きすぎましたw）', 'わたくしめの発言など、恐縮です。', 'いえ、めちゃくちゃ有意義です！！\\n\\nありがとうございます！！', 'twitterだと流れちゃうので、twitterで拡散しつつ弊メディアの記事にしてもいいですよ', 'それは願ってもない申し出です！！\\n\\n記事執筆など、是非ご協力させて下さい！！', '素敵な記事になりそうですね:blush:', '少し修正しました。\\nあと、子供ができるといろいろ大変だそうです。\\nその辺もキャリアプラン考えないとですね。\\n女性の場合は出産のタイミングなどもあるのでさらにタイミングが大変らしいですね。', '<@UJRAL005U> \\n僕も全て大丈夫です！\\n同じ境遇の方は沢山いると思うので(調べても情報がなくて大変でした)\\nまた、このギルドにとって利益になれば幸いに思います！(自分は教えてもらう立場だったので、こんなこというのも恐縮ですが)', '<@UL2TY2ERL> \\n\\nありがとうございます。\\n\\n将来、家族を持つことは僕の楽しみでもあり、子供を育てる楽しみも人生で一度は味わいたいとは思っています(まだ相手はいないですが笑)。\\n先日、担当教官にも相談させていただいたのですが、やはり、家族を持つとお金はいくらあっても足りないと聞きました。\\n大学院に社会人で行くとしたら、家族を持ったらどうなるのか、\\nいくらお金が必要なのか、\\n時間はあるのか、\\n沢山考えることがありそうですね。\\nそれらも念頭に考える必要がありそうです。\\n\\n非常に参考になります。ありがとうございます。')\n",
      "('sho.kumada',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Yuta Kita')\n",
      "('時系列', 'AR', '教科書')\n",
      "('COVID-19の\\n国別（または都市別）の日ごとの発症者数を取れるソースがあれば教えていただきたいです。\\n\\n以下のWHOが作成したdashboardの左下のグラフに該当するデータです。数値で取りたいのですが、、\\n<https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd>\\n\\n今、時系列解析のVARモデルとグレンジャー因果を勉強しており、\\nホットなデータで色々考察してみたいと思った次第です。\\n輪読の教科書（時系列解析: 自己回帰型モデル・状態空間モデル・異常検知 )のP66-P78にあたる内容です。\\nよろしくお願いいたします。',)\n",
      "('これですかね？\\n\\n<https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports>', 'PDFからの変換大変そう・・・', 'クローリングの練習には良さそうですねｗ', 'これが良さげです\\n<https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases>', '<@UJRAL005U>\\n<@UQXUSE316>\\nありがとうございます！\\n１つ上のリンクから欲しかったデータが取れました。\\n何か知見があれば報告します。\\n時系列分析不慣れなんで、トンチンかんなこと言うかも\\nしれませんが笑\\u3000\\nまず、じっくりデータを見てみます。')\n",
      "('ｱﾗﾝ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '永田ゆかり Yukari Nagata', 'はやと-休学中の文系学生', '戸嶋\\u3000龍哉')\n",
      "('ダッシュボード', 'BI', '形態素解析', '時系列', '設計', '前処理')\n",
      "('院進と就職に関する会話を拝見させてもらい、質問させていただきたいと思いました。\\n働きながら磨くものを他の方法で磨くこと、学部生や院生でもそのような機会に挑戦させてもらえるものはインターンだと思いますが、長期でやっているもので就職世代（B3やM1）でなくてもできるデータサイエンス系のインターンはございますか？',)\n",
      "('各社結構やっている印象を受けますね！\\n\\nインターンをやってる他の学生などに、どうやってインターンを受けるに至ったか教えて欲しいところですね！！', 'アランさん、こんにちは。\\nデータに関するコンサルティングファームの代表をしております永田と申します。\\n一般的にも多く募集しているものと思いますし、弊社でももちろん募集しています。弊社インターンの一橋大学生はもう１年くらいやっててもらっています。（興味・関心に応じて前処理、前整形部分、ダッシュボード構築などをしてもらっています）\\nデータサイエンス系の方がビジネス領域で仕事をする典型的なハードルとして、とても勉強熱心な方が多いので、例えば時系列解析にしても、自分の技術や精度に納得がいかないので自分はこの仕事を受けれない、となりがちなところかもしれません。とても勉強されているからこそ、謙虚さもあいまって全てに対して門外漢のような感覚になっている人は多い印象があります。\\nしかしビジネス側のプロジェクトフェーズの要求ではざっくりでよかったり、ゆるふわで良い段階もあったりします。顧客にとってはWHATの追求よりも、見せ方としてのHOWに意識があるときもあります。そんなときに機動的に柔軟に判断できる人は重宝される気がしています。\\n\\nまた、データサイエンスといっても焦点領域は会社ごとに結構異なりますよね。私の会社では、下記のような形で融合させています。\\n一つは、分析過程においてリアルタイム連携をする。\\xa0\\n例：データ→BIでのダッシュボード⇆アルゴリズム\\nもう一つの例として分析プロセスに埋め込む。\\nデータ→アルゴリズム⇆ BIでのダッシュボード\\n\\n分析企画設計からやっています。\\n\\n形態素解析からのビジュアライゼーションなんかもやっています。\\n例：\\n<https://public.tableau.com/profile/yukari.nagata0623#!/vizhome/TwitterAnalysis_15595641262440/sheet0>\\n\\nこちらはシアトルから選ばれ、海外カンファ、海外記事に使用されました。\\n\\nなので、わらわらと長くなってしまいましたが、データサイエンスといっても現れ方使われ方として本当に様々ですが、いろんなことができると思いますし、新しいことを追求していきたい方であれば、たくさんあると思います！\\nもしご興味あれば弊社もインターン先候補にいれていただけると嬉しいです：）', '自分は学生でインターンしてるんですけど、wantedlyとか見ればとてもたくさんありました！とにかく数応募してみるっていうのがいいのではないかなと思います。', 'また、行きたいところが決まってるようでしたら、直接ダイレクトアタックかけると取ってもらえたりもします。', 'じつは100人以下ぐらいの会社であれば、特に大々的に募集かけてなくての公式HPのフォームからダイレクトアタックかけると拾ってもらえたりする場合あります！（前職はそこから拾った人いました）', 'そういえば、自分もAlbertは問い合わせフォーム直撃でしたね。\\n\\n一応インターンの求人的なのはサイトに載ってましたが。')\n",
      "('Gento Sunoda',)\n",
      "('戸嶋\\u3000龍哉',)\n",
      "('ML', 'pandas', 'Python')\n",
      "('S3上のXMLファイルをPythonで読み込んで\\nParse処理した後にテーブルに格納したいんですが参考サイトがほとんどなく手詰まっております。ご存知の方いらっしゃいましたらご教示お願いします。boto3と他のデータフレームを合わせるというところまではイメージつくんですが経験不足でして...',)\n",
      "('XMLファイルの容量がわからないので、一旦ファイルの全部のデータがメモリに乗る前提で。\\n\\n1. S3から boto3 でファイルをそのまま巨大な文字列として読み込み\\n2. ElementTree を使って１行単位 or 1列単位のデータとして dict or list に変換\\n3. dict or list をデータフレームに変換\\nでいけるはずです（最近も ElementTree でいいのかな？）', '<https://qiita.com/nomurasan/items/78d0174977bb61a52808>', '<https://gokhanatil.com/2017/11/python-for-data-science-importing-xml-to-pandas-dataframe.html>', '返信ありがとうございます！\\n教えていただいた流れで書いてみます。')\n",
      "('K',)\n",
      "('永田ゆかり Yukari Nagata',)\n",
      "('AI', '書籍', '統計', '入門')\n",
      "('すっごい初歩的な質問いいですか。。。\\n最小二乗法ってあるじゃないですか、某有名な。\\nあれって\\nOrdinary least square\\nOrdinary least squares\\nMethod of least squares\\nとか色々英称があるのですが、データサイエンス界隈ではどれがスタンダードなのでしょう、、',)\n",
      "('外国人と普段のコミュニケーション（口語/書き言葉）で最も聞くのはOrdinary least squares ですね..\\u3000method of least squaresはthe method of least squares とかいったりしますがあまり聞きません。堅い本とかちょっとかたっぽい感じのときはいうのかもしれません。あとはthe least square method とかもありますね。\\nOrdinary least squares は外国人もOLSとか言ったりします。', 'データサイエンス界隈でのスタンダードな言い方というよりその外国人の出身地での違いが結構ありそうな言葉です。私の上記例はカナダ人とUS人（NY）ですね。', 'なるほど、ネイティブの方々はordinary least squaresと称することが多いのですね！これまで論文ではmethod of ~としか書いたことがなかったので目から鱗の気分です:flushed:\\n\\nそして外国の方もOLSと略すのですね！略称の方が使いやすい場面も多々来ると思うのでボクもordinary least squares; OLSをこれからbasicに使ってみることにします！(これで気分はニューヨーカー)\\n\\n地域性があったら面白そうですね！今度フランス人の友達に会ったときにでも聞いてみます！\\n\\n素朴な疑問でしたがすごくスッキリになりました！ありがとうございました:blush:！', '逆に論文だからじゃないですかね！：）\\nかたっぽい書き言葉だとmethod of--ありえるとおもいました。\\n口語ではあまりきいたことがありませんでした。これから私もニューヨーカーっぽく、OLSって言ってみます。', 'あぁ、そゆことなのかもしれないですね！\\n東大の統計学入門ではmethod of~表記で、それ以外(丁寧語で書かれているような)の書籍だとOLSだったのでそれが学術的にフォーマル文書かどうかっていうのは判断基準になりそうです！ ;D\\n\\n海外の方は口語でもOLS(オーエルエス)というのですか、、？？', '言ったりするのではないかと思いますが、なんの脈絡もなく言い出すのは唐突すぎてDAIGOみたいになりますので、最初にちゃんと名称を言ってあげてますけどね。笑\\n（FAをファイナンシャルアドバイザリーだとわからない人にFAとは言わないのと同じ感じですかね）', 'ちゃんと文脈ありきであることには変わりないのですね、DAIGOがまだ米国で通じないのが辛いです:cry:(日本でも通じてない)\\n\\n確かに！FAって言われるとボクは最初にフリーエージェントを思い浮かべてしまいます🥺何の話をしているのかハッキリさせてから使わないといけないのは日本も米国も(カナダも)変わらないですね！\\n\\nご丁寧にありがとうございます🥺！')\n",
      "('増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('BI', 'Tableau')\n",
      "('ゆる募集\\nTableauやBIツールのバージョン、リリース管理。\\nGoogleDataPortalとかロールバック不可は結構困る。\\n（だいぶ魔改造で細かい設定をBIツールに入れるのは危険。私以外触れなくなるｗ）',)\n",
      "('tableauだとリビジョン履歴ありますが、文脈違いますかね？\\n\\n<https://help.tableau.com/current/pro/desktop/ja-jp/qs_revision_history.htm>', '変更箇所をgit的に見た意図かそういったニュアンスです？', 'gitとかですね。Versionがあっても何を変えたのかわからなかったりするので、結局どう変更したのか履歴が残らないという点で悩みどころです。')\n",
      "('ﾔｴﾘ_営業ｱｯﾌﾟﾃﾞｰﾄ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Yohei Sato', '戸嶋\\u3000龍哉')\n",
      "('機械学習', 'データサイエンティスト')\n",
      "('分析業務に携わっている方に質問です。\\n\\n現場部門やお客様から「機械学習には不向きなテーマ」の依頼を受けた時、どのようにいなしていますか？\\n\\n例）地震予測や事故の予測など、ランダムウォークor正例がほとんど無いような問題\\n\\n私は企業に提案をする立場なのですが、既に機械学習の需要が一巡して上記を期待するような柔らかいお客様が増えてきており、さてどうしたものかと・・・。',)\n",
      "('・めちゃくちゃ高い値段を提案してする（断ってくれそうなクライアントさんなら）\\n\\n・事前に上手くいかないことを伝え、納品ベースではなく、準委任契約で短い契約期間で受けて早めに撤退して出来るようにする\\n\\nなどですかね。「とりあえずミニマムでやってみましょうか！」って、PoCの中でも出来る限り少ないコストでやる感じですかね。', 'もしくは、その領域のリサーチをする所まででを案件として受けて、どの程度の難易度かをお伝えするなども有効そうです。\\n\\n実際何かやらないと気づかない場合も結構ある（分析官側も確信を持って出来ないと言いにくい）ので、何かはやって、「あー、これは難しそうだねー」となって別の課題に移ることを期待しますw', 'ありがとうございます！大変参考になりました。\\n\\n・高い値段で回避\\n・準委任でライトに受けて早めに撤退\\n・前段のリサーチ部分のみ受け難易度チェック\\n\\n他案件に影響しないように（信頼を落とさないように）するのと、ライトに受けるにも社内データサイエンティストの工数が勿体ないなぁ・・・というジレンマがありますよね。。\\n\\n※他の皆様はそれ程お困りじゃない感じでしょうか？？\\n実務系よりアカデミアの方が多いのですかね。', 'メンバーの構成で言うと、プレイヤー寄りが多いので、クライアントと折衝してバランス取るような方はあまりいない印象ですかね？', '<@UTRSFL2LS>さん、\\u3000<@UUAUDBR1N> さん辺りは受託分析のフロントなどもやってらっしゃったと思うので、\\n\\nそういったシーンには結構出くわしてたりするのかなと思うのですが、いかがでしょう？', 'この辺、良く相談されるんですが結構難しくて、\\n自分の場合は、商談の中で、いろんな事例を交えながら、\\n実際にデータで出来そうな課題に落とし込んでいくイメージなんですよね。\\nなので、本当にケースバイケースになってしまいます。。。\\n\\nケースバイケースだと何のアドバイスにもならないので、一応参考になるかも知れない話としては、\\n「誰か社内で、何となくでも、その予測が出来る人はいますか？」\\nという質問を投げかけるというやり方があります。\\n\\nいるのであれば、その人が何を見て予測してるのかをヒアリングすることで、チャレンジする価値がありそう〜\\nいないのであれば、正直筋が悪い。何を検証すると良さそうかを一緒に考えてみましょう〜\\n\\nみたいな感じで、 話を聞きながら整理していく感じです。\\nうまく言語化出来てなくてすみません。', '実際案件始まってしまった状態だと、無理矢理機械学習で解くパターンと、通常とる最適であろう手法（古典的な方法や機械学習全く関係ない方法）両方で解いてしまって、「こちらの方がいいですね」とオーソドックスな方法見せてしまうことが多いですね。実際一度はやってみせないと納得してくれないことがほとんどなので。\\n\\n（私個人としては目の前の問題が最適な形で解ければ、極論データ分析しなくてもいいと考えてるタイプなので、それデータ分析者としてどーなの？というのはありますが…）', 'あとは契約面で可能な限り即撤退しやすく調整したりですかね', '契約巻くところも自分でコントロール必須ですね', '<@UTRSFL2LS> \\n確かに、クライアントの手動運用が無ければかなり難しそうですし、有効そうですね！！\\n\\n一緒に考えるスタンスを取れば突き放す感じもなくて良さそうですね！\\n\\n<@UUAUDBR1N> \\nやはり、失敗する前提で小さく失敗するのがいい感じですね。\\n\\n失敗した時の自社、クライアントどちらもダメージが少ないように進められるかが肝な感じですね。\\n\\n<@URSAAN0J3> \\nかなり現場に寄ったご意見頂けたかと思いますので、ご参考にして頂ければと思います！！', '皆様、ありがとうございます！\\nどちらかというと「案件の断り方」をお聞きしたかった感じでして、<@UUAUDBR1N> さんの\\n「実際一度はやってみせないと納得してくれないことがほとんどなので」は確かにそうだな～と思いました！\\nまた、「目の前の問題が最適な形で解ければ、極論データ分析しなくてもいい」これは私も同じです:blush:\\n分析のための分析、機械学習のための機械学習になっちゃっているお客様がホント増えてる感があります。')\n",
      "('Kom',)\n",
      "('K', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa', 'Riita Satsuki')\n",
      "('機械学習', '教科書')\n",
      "('数学について質問お願いします。\\n行列式って一般に正方行列について定義されてますが普通の縦長だったり横長の行列には定義されないのでしょうか？\\nまた実際にデータサイエンスをやっていくときにそういった計算(正方行列ではない行列の行列式を求める)をすることはあるのでしょうか？',)\n",
      "('行列式は正方行列に対するものであることがそもそもの定義であると認識してました、小行列式なら部分的に適用できるかもしれませんが(記憶が曖昧ですみません)', 'いえいえ:blush:\\n数学のテキストに正方行列ではない行列の定義式っぽいものが出てきたのでちょっと気になって質問してみました。ありがとうございます！', '逆にそれ気になります、どんな定義式ですか:thinking_face:？(昔の記憶すぎて忘れてる)', 'Fっていうのが行列式の特徴である多重線型性と交代性を持っているとするとFはこう定義できるっていう文脈なんですけど、どうも縦長の行列(m=>n)だけにみたいで横長の行列については言及されてないですね。。', '行列式って、確か、「連立方程式が解けるか？」という話で、横長な行列なら解が必ず出せるので興味がないとか、そんな感じなんじゃないかなぁと。', 'データサイエンスにおいて、厳密な解を求めることはほぼなく、\\n\\n確率的な誤差を伴って観測される分布から、連立方程式でいう所の解のような物を求めるので、行列式はあまり使うイメージないですね。', '機械学習に関してはそんな感じですが、最適化のロジック周りは使うことあるかもしれないです！', '理解するのに時間かかりそうなので、一旦回答すると、自分の場合は実務上意識したことはほぼないって感じですね！', 'なるほど！確かに行列式をそう見ると横長でわざわざ行列式を定義する必要はありませんもんね。実務上はそこまで厳密に意識しなくてもいいとのことなので安心しました。ちょっと気になると深く追求したくなりますが深追いしすぎると本末転倒になってしまうのである程度の理解で進めて行こうと思います！', 'あ、ミスってますね。\\n\\n必ず解がある→解が一つに定まらない。ですね。', '一応、一般逆行列というものがあって次元圧縮のアルゴリズムなんかで使われてたりしますよ。とはいえ、手で計算することはありませんが。', '大学生という立場から回答するので、実務で使うかは知らないです。\\n\\n行列式そのものは、正方行列に対してただ一つに定まる量です。\\n教科書が言っているのは、行列式に対して多重線形性が成り立つということで、\\n多重線形性って何かと言うと、和の行列式を行列式の和に変形できるってことです。\\nググッたらわかりやすい例が出てくると思います。', 'あ、すません。逆行列じゃなくて行列式でしたね。なんか読み違えてました。行列式は正方ではない行列からはもとまらないですね。ごめんなさい。', '<@UREUHGVAQ>\\nやはりそうですよね。自分も行列式はそういう認識だったので不思議に思いました。ありがとうございます！', '<@UNFAV5EDB>\\nなるほど、そういうことを言ってるんですね。てっきり縦長の行列式が定義されているのかと思ってました。。')\n",
      "('shinji',)\n",
      "('増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('データサイエンティスト', '設計', 'jupyter', '機械学習', 'Python', '前処理', 'GCP', 'SQL', 'データエンジニア', 'ML', 'EDA')\n",
      "('予測モデルを開発してシステムを運用に乗せる流れで、\\nデータサイエンティストとエンジニアの役割分担について、\\n皆さんの持っている感覚を知りたいです。\\n\\n■背景\\n社内の開発環境を整備しようとという動きがあって、\\nPoCから開発(システムとしてのリリース)までなるべく同じ環境にしたら\\n効率が上がるんじゃないかという意見があったりします。\\n\\n■僕の感覚\\nウォーターフォール的にフェーズを分けると、\\n1.要件定義(予測モデルのPoCはここに含まれるとしてください)\\n2.基本設計・.詳細設計\\n3.コーディング\\n4.各種テスト\\n\\n個人的な感覚を言うと、データサイエンティストとエンジニアではスキルセットを統一するのは難しいので、\\n要件定義(PoC)までは、データサイエンティストが担当して、\\n基本設計以降は、エンジニア担当するのが現実的かなと思っています。\\n→ただし、PoCで作ったモデルのコードをエンジニアに引き継ぐ時間は確保しておく。\\n\\u3000引き継ぎ項目はだいたいこれくらい\\n\\u3000\\u3000使ったデータセットはこれで、\\n\\u3000\\u3000使っライブラリ＆パッケージはこれで、\\n\\u3000\\u3000作った説明変数で実際に意味があったのはこれで、\\n\\u3000\\u3000精度検証で使ったコードはこれ\\n\\n両刀使いもありだとは思いますが、、志向性、専門性を考えると\\nデータサイエンティストとエンジニアはやっぱり別の職種だと思っています。\\n→両方追いかけるのはものすごく大変、僕はちょっとできないですorz',)\n",
      "('俗によるMLOps問題ですね。\\n切り分けとしては、python code まではデータサイエンティスト、実装についてはデータエンジニアという形ですね。\\njupyterの再現性などの問題はちょっと悩みどころです。', '<@URLV35G8M>\\nモデリングする人と、機械学習用のシステムを構築する人は別の方が良いと思います！\\n\\nビジネス要件整理（ビジネスサイド）\\n↓\\nデータの前処理・PoC（データサイエンス）\\n↓\\n機械学習システムの開発（機械学習エンジニア）\\n↓\\nオペレーションへの組込（ビジネスサイド）\\n\\nみたいな役割分担で、小さな組織であれば兼業などもありえますが、基本的には分けた方が良いのかなぁと思います！\\n\\n環境でいうと、言語が同じであれば比較的大丈夫かなぁと思います！\\n\\n&gt; 使ったデータセットはこれで、\\n&gt; 使っライブラリ＆パッケージはこれで、\\n&gt; 作った説明変数で実際に意味があったのはこれで\\n&gt; 精度検証で使ったコードはこれ\\nここまでやって、エンジニアに渡してシステムに耐えうるコードに書き直して貰うのがベターなんじゃないかなぁと思います。\\n\\n自分も簡単なサービスは作れますが、負荷対策とか、アーキテクチャの設計構築とかまではそこまで詳しくないので、エンジニアの人に引き継ぐことが多いですね。', '<@UL2TY2ERL> <@UJRAL005U>\\nありがとうございます。\\n概ね同じ感覚です。\\n\\n逆に、システムの構築でエンジニアチームが、\\n仮にバッチ処理でGCPのDataflowとかをしばらく使い続けようとしているとします。\\nそれをPoCの段階から使うとモデリングの速度が落ちるので、データサイエンティストとしては\\n引き継ぎをした後にエンジニアがシステム開発するところで\\n対応するのがベターでしょうか？\\n→エンジニアからすると楽ですが、\\nデータサイエンティストのキャッチアップコストが\\n純粋に増えるので、そこまで推せないなあと思っています。\\n\\nまた、例が思いつかないですが、\\nデータサイエンティストとして、これをエンジニアにも\\n共通して使ってもらいたいものとかはありますか？\\n→PoCでは主にPythonを使っていてエンジニアもPythonは読めるので、\\n引き継ぎで説明があれば基本的にわかります。\\n(jupyter notebookで上からズラズラ書いている\\nコードがちょっと読みにくい時はあるものの、\\n読めないことはないですwww)', '<@URLV35G8M>\\n&gt; 引き継ぎをした後にエンジニアがシステム開発するところで対応するのがベターでしょうか？\\nこちらのイメージが近いですね。そもそもPoCの時点でボツになる可能性もありますし、EDAだったり、前処理、基礎分析などもカバーすることになると思うので、最初からバッチ処理に乗せて分析することはかなり困難かと思います。（学習と予測の所だけ切り出してという形ならありかもですが、あんまりイメージが持てないです）\\n\\n&gt; データサイエンティストとして、これをエンジニアにも共通して使ってもらいたいものとかはありますか？\\nSQL、pythonあたりは基本スキルになるので、共通して使って貰えた方が助かりますね。あと、できればシェルスクリプト、cronとかの、バッチ処理の基礎になるような処理に関しては知っておいてもらった方がスムーズに連携できるので良いのかなと思います。\\n\\n&gt; (jupyter notebookで上からズラズラ書いている\\n&gt; コードがちょっと読みにくい時はあるものの、\\n&gt; 読めないことはないですwww)\\nこれは、分析プロセス上仕方ない部分がありますね。エンジニアリングできる方でも、アドホックの分析用コードをリファクタリングして開発用にするようなプロセスは必要だと思いますので。', 'エンジニアサイド、データサイエンティストサイド共にですが、お互いの領域のプログラミングスクール卒業レベルの知識を持ってると圧倒的にコミュニケーションが楽になるんじゃないかなぁと思いますね。\\n\\nガチで開発しなくていいですが、コミュニケーションは取れた方がスムーズなので。', '<@UJRAL005U>\\nありがとうございます。\\n経験のある方の意見をいただけて、大変参考になりました。', 'いえいえー！参考になったようで何よりです！')\n",
      "('shimizu.yohei',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Riita Satsuki', 'asuki.u')\n",
      "('jupyter', 'Docker', 'Linux')\n",
      "('Dockerでjupyter環境を作ったんですが、ターミナルを開くとログインシェル？\\nで入ってしまうためエイリアスやタブ補完ができなくて不便です…。\\n一応bashコマンドを打つとインタラクティブモードになるのですが面倒なので、\\n起動するごとに自動にインタラクティブモードなってほしいのですが、\\nやり方わかる方がいらっしゃったら教えていただきたいです…',)\n",
      "('その課題を感じたこと無いですね・・・\\n\\njupyter環境とか立てたときは、jupyterからシェル使うことが比較的多いのですが、Docker側のシェルですかね？', 'jupyterlab内でのシェルについてですね…。', '今だけかもしれませんが、ファイル操作で\\njupyterlab内のターミナルを使う必要があったのですが、タブで開くたびにbashコマンドを打ってます。', 'なるほど、比較的レアケースなので、自分の場合は多少不便でも気にせず使ってるかもです。', 'そうなんですね！\\n引き続き調査してだめだったら気にせず使おうと思います:man-bowing:', 'あまり概要を理解していないんですが、\\njupyterのconfigにパスワードのハッシュのファイルが必要とかなら、基本はDockerのvolumeマウントでファイルを渡してあげるか、dockerfile内でaddか、copyコマンドで持っていってあげましょう。\\n起動時にどうしてもコマンドが必要なら、\\ndocker内のLinuxのsystemdってデーモンに起動時に走るようなUnitを作ってあげて、\\nsystemctl enable ${Unit}\\nってした状態でコンテナをコミットしておけばいいんじゃないですかね？(あまり綺麗な手段ではないですが)', 'macとかでターミナルを開いたときに自動でbashなどにログインをするのを\\njupyter(要するにubuntu?)環境でやりたかったんですよね〜', 'docker run -it jupyter /bin/bash\\nってするだけではないのですか？', '<@UR7A5CJNA>', 'その場合だと、自分のマシンのターミナルで入るという感じでしょうか？\\nすみません、画像でお見せした方が早かったですね:man-bowing:\\nこの画面のターミナルですね！', 'なるほど....\\nそもそもサーバー側にアクセス権がないけれど、Jupyterのターミナルだけ触れるという状態なのでしょうか？\\nそしたら、都度コマンドでログインするしかなさそうですね...\\nお役に立てず、すみません、', 'いえいえ！こんなにアドバイスたくさんくださってありがとうございます！:man-bowing:\\n変な悩みだったのかもしれませんね（笑）\\n引き続き調べてみます！ありがとうございました！:blush:', 'これ気になって調べてみたのですが、日本語圏内にはあまり見つからず、英語圏内では同じような質問をされている方はいたようです。\\n\\n<https://stackoverflow.com/questions/33467098/how-can-the-terminal-in-jupyter-automatically-run-bash-instead-of-sh>\\n\\nざっとみて2通りは やり方がありそうですが、試せてません。\\n\\nコンテナ内 環境変数 $SHELL の値を /bin/bash に変更することで 解決できるかも。。\\n\\n参考になれば幸いです:memo:', 'ご返信遅くなってしまい申し訳ありません！:man-bowing:\\n情報ありがとうございます！試してみます！')\n",
      "('Hiroki Narita',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '永田ゆかり Yukari Nagata')\n",
      "('可視化', '前処理', 'jupyter', 'データマート', 'ポートフォリオ', '形態素解析')\n",
      "('質問失礼致します。\\n\\npythonのjupyter notebook上で、可視化を行う際、\\nmatlabのように\\n手軽に動的なグラフ（例えば、heatmapで相関マトリックスを可視化する際に、カーソルを合わせるとどの変数同士の相関係数かをインタラクティブに表示してくれるような）\\nを作れるようなライブラリを探しています。\\n\\npythonの動的グラフ作成ライブラリだと、plotlyや、bokehなどがあるとおもうのですが、\\n学習コストが高く、作成する際に調べないといけなかったり、コード量が多くなってしまうので、\\n結局いつもcsv出力してmatlabで可視化しちゃったりしまうので、大変だなと思いました。\\n\\nまた、皆さんは動的グラフがほしい際は、どういったツールをつかっているでしょうか。\\npython外でも、簡単に見やすい動的グラフを作れる手段があれば、活用したいと思っています！',)\n",
      "('自分はデータマート作ってtableau使っちゃいますね・・・\\n\\n年10万円かかりますが、確か学生は無料だったはずなので、使ってみても良いかも！', '<@UJRAL005U> 様\\n\\n無料ですか！いいですね！\\nちょっと確認してみます！\\nありがとうございます！', '多分、tableauがフィットするものと思います！', '<@UUMB12SGZ>様\\nさっそく学生証写真を送ってstudent版を使おうとしてます！笑\\n綺麗なグラフはまさに芸術なので、使うのが楽しみです:laughing:', 'わたしのポートフォリオ、こちらです。雰囲気掴めるかもです\\n', '<https://public.tableau.com/profile/yukari.nagata0623#!/|https://public.tableau.com/profile/yukari.nagata0623#!/>', '地球:earth_asia:のビジュアライズもしています:heavy_heart_exclamation_mark_ornament:', '<@UUMB12SGZ>様\\nうおおおーーー！！すごいです！！！\\nまさに美術館ですね！\\n見てるとむっちゃ楽しくなります！:laughing:', 'そんなこと言ってくれて、嬉しみです。あまり、人にほめられないので、うれしいです。笑', 'pythonとtableau融合は無限です。やばいです。', '<@UUMB12SGZ>様\\n\\nいまむっちゃ見てるんですがほんとに楽しいです！\\n\\n実用面でも可視化ってむっちゃ大事だと思うんですが、\\n美しさを追求したデータビジュアライゼーションのコンテストとかってあったりするんですかね:thinking_face:？\\n\\n永田様の作品見ててそんなことを考えたりしました！', 'なんか個人的にデータビジュアライゼーション美術館みたいなのがあったら行きたいなーなんて思いました笑', 'あります！\\nわたしの作品、恐縮ながら海外でも選出されました〜\\nこれは海外記事やメディアでも引用されまくてる作品です。\\n', '<https://public.tableau.com/profile/yukari.nagata0623#!/vizhome/TwitterAnalysis_15595641262440/sheet0|https://public.tableau.com/profile/yukari.nagata0623#!/vizhome/TwitterAnalysis_15595641262440/sheet0>', '<@UUMB12SGZ>\\nうおーーーすごいです！！！\\nむっちゃ調べてみたくなりました！:laughing:', '形態素解析をつかった作品です❤︎', 'あと、世界コンペ作品、アメリカの農業のはなしなどです。', '<https://public.tableau.com/profile/yukari.nagata0623#!/vizhome/TowardsSustainableAgricultureIronViz/Dashboard|https://public.tableau.com/profile/yukari.nagata0623#!/vizhome/TowardsSustainableAgricultureIronViz/Dashboard>', '<@UUMB12SGZ>様\\nまさに圧巻ですね...！\\n本当にみてて面白いです...!', '褒められました❤︎', 'ぱいそん前処理してくださったら、わたしが茶目っ気とセクシーみを入れて、ビジュアライズします。', '<@UUMB12SGZ>様\\n\\nなんかうまく言えないですが、\\n実務の中にアートと画家がいるのってすばらしいですね...!\\n\\n画材を持っていくと画家が美しい絵を書いてくれるみたいな...!\\n新しい世界がみえました！！', 'わたしは、tableauにデータが入る前のことに詳しくないので、その部分をやってくれる人と一緒にやっています。わたしは、いわゆる基盤や前処理よわいんです。', '美しいものが好きなんです❤︎', 'エンジニアの人のはっかそんui担当の仕事もしましたww', '<@UUMB12SGZ> 様\\n\\nなるほど！\\nすばらしいですね...!\\n\\n可視化技術って、作る側もデータを見るために使ったりしますが、\\nやっぱり顧客へのプレゼン資料を作る上でむっちゃ大事になりそうな気がしてます（学校の教授には、図をたくさんつかえ、スライドは読ませないように、と口を酸っぱくして言われているので）。\\n\\n今はデータサイエンスでひと括りにされていますが、さらにデータビジュアライゼーション部門なんてものがこれからできてきそうな予感がします...!（もしかしたらもうあったりしそうですがw）', '4/22にそんな本がでたりするそうです！', '<https://www.amazon.co.jp/dp/4815604053/ref=sr_1_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&amp;keywords=%E3%83%87%E3%83%BC%E3%82%BF%E8%A6%96%E8%A6%9A%E5%8C%96&amp;qid=1582891766&amp;s=books&amp;sr=1-1|https://www.amazon.co.jp/dp/4815604053/ref=sr_1_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&amp;keywords=%E3%83%87%E3%83%BC%E3%82%BF%E8%A6%96%E8%A6%9A%E5%8C%96&amp;qid=1582891766&amp;s=books&amp;sr=1-1>', '<@UUMB12SGZ> 様\\n\\n可視化の本ってなかなかないイメージで、貴重なきがしてます。。。！\\n買わせていただきます！:joy:')\n",
      "('永田ゆかり Yukari Nagata',)\n",
      "('しみずこうじ', 'Fukushima-M1-gameAI-DP', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('AI', '初心者')\n",
      "('なぜ最近の頭のいい人はみんなポーカーをやるのでしょうか？\\nゴルフやテニスの代替として最近のスマート系の方のトレンドなのでしょうか。わたしはそういう頭のいいことができないので、困っています。:golf:️\\n',)\n",
      "('こんな記事がありました……\\n\\n<https://www.news-postseven.com/archives/20180903_754195.html?DETAIL|https://www.news-postseven.com/archives/20180903_754195.html?DETAIL>\\n\\n\\n&gt; 「ポーカーが強い人は、『もし今勝負に行ったら』なんていう感覚的な思考に頼りません。私が見てきた優秀なビジネスマンも、希望的観測に任せず、事実から合理的に思考を組み立てる人が多かったです。ポーカーはこの思考法をスピーディーに訓練することができるのです」', '苦手なものを始めなきゃなのかな？と思うと心が重いですよね:scream:', 'しみずさんありがとうございます！なるほど〜とても勉強になります。頭のいい人たちのご趣味な印象があります。周りにはいないのですが、Twitter始めて知りました。わたしには無理そうな世界ですが試してみるの好きなので、はじめてみようかなあと思いました！:blush:', '私予定が重なって参加できなかったのですが:sob:、先日勉強会やってました:blush:\\n\\n<https://data-learning-guild.slack.com/archives/CJNKJ8JKW/p1580788478108700|https://data-learning-guild.slack.com/archives/CJNKJ8JKW/p1580788478108700>', '参加してみたいです！こちらのクラブのみなさんは韓国ツアーまで行かれているのですね！すごい・・・。完全初心者ですが楽しみたいです！笑', '是非！！\\nしばらくは実際には集まれそうにないですが:sweat_drops:\\nちなみに韓国にはまだ行ってませんw', '心理学とゲーム理論と確率論はビジネスにめちゃくちゃ使えるので、絶対学んだ方が良いです！！\\n\\nあと、ギャンブルを結構やりこむと、\\n\\n・期待値が高く、分散が少ないものに対して手数を打つ\\n\\n・理不尽なことやベストを尽くしても偶然上手く行かないことも結構ある\\n\\nというビジネスや社会で大事な感覚を直観的に身に付けることができます！\\n\\n実社会だとここら辺の感覚を得るまでのサイクルが回らないので。サイバーエージェントの藤田さんも麻雀強いので、多分に似たような感じなんじゃないかなと！', 'ビジネスマンがポーカーを学ぶべき理由みたいなYoutube撮るかなｗ')\n",
      "('さくさく',)\n",
      "('Hiroyuki.Tachikawa', '塩田 佳明', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('データサイエンティスト', '深層学習')\n",
      "('現在、大学四年生でインターン先を探している者なんですけど、\\nキャリアについての相談で、データサイエンティストになろうと思って色々勉強してきたんですが、最近になってiosアプリ開発にも興味を持ってきたんですが、iosエンジニア兼データサイエンティストになるっていうのは、可能なんでしょうか？\\nあるいは、どちらか一方の職業を選んだ方がいいんでしょうか？\\nよろしくお願いします',)\n",
      "('こんばんは〜！可能です！私のみじかな人でエンジニアとして最も尊敬する方は、フルスタックのエンジニアでありつつ、データサイエンティストとしても超一流です。勿論やろうと思うことが増えれば難しくなるし時間もかかりますが、だからこそ人より人生楽しめるし人より価値が提供できるはずなので、なんでもやっちゃいましょう！笑', '返信ありがとうございます\\nその場合は、最初のキャリアとして、ios エンジニアかデータサイエンティストどちらを選んだ方がいいとかあるんでしょうか？\\n今、iosアプリ開発のインターンかデータサイエンティストのインターンのどちらに行こうか悩んでいるので、', '解答ではないんですが、エンジニア兼データサイエンティストっていう道筋っていいですよね！！とても共感します！\\n私も現役エンジニアですが、こちらでデータサイエンス学ばせていただいてます。\\n一緒にがんばりましょう！', '正直あんまり変わらないと思うので、やっている事業が魅力的かどうかとか、一緒に働く人が魅力的かとか、iOS,データサイエンス以外の要素で選んでもいいと思いますよ。特にキャリアの初期はいい師匠に巡りあることがめっちゃ重要なので、そこを重視してもいいかもしれません。あ、ただどちらのスペシャリストも在籍している会社の方がいいですね。例えばiOSエンジニアとして入社しているけど、他の部署や先輩にデータサイエンスの強い人がいる。またはその逆。とか。', '<@UR2D23J4T> \\nメッセージありがとうございます‼️\\n一緒に頑張りましょう‼️\\n<@UREUHGVAQ> \\nなるほど\\nそうなんですね\\nアドバイスありがとうございます‼️\\n大変助かりました:exclamation:', '<@US5SR0VFD> いえいえ！お役に立てたようで幸いです！因みにさっき伝え忘れたんですが、深層学習については重たいモデルでもフロントエンドで推論を実装できる仕組みが最近になって実現可能になってきたばかりなので、できると結構需要ありますよ。ご存知かもしれませんが、一番有名なのはTensorflow.jsとかでしょうか。最先端の分野なのでできると強いと思いますよ。iOSだとpytorch mobileとかですね。<https://pytorch.org/mobile/ios/>', '<@UREUHGVAQ> \\nはじめて聞きました。\\nアドバイスありがとうございます\\n勉強してみます‼️', 'おお！頑張ってください！本当に最新の分野なので何か学びがあったら是非シェアしてください！', '<@UREUHGVAQ> \\nはい\\n是非シェアしたいと思います‼️\\n色々ありがとうございました。', 'ありだと思いますが、個人的には、どちらかの領域で突き抜けてからもう一つの領域やった方がキャリア戦略的には楽かなぁと思います！', 'どっちつかずの中途半端なスキルだとなかなかのチャレンジングな仕事を獲得しにくいので、片方のスキルで突き抜けて、引く手数多になっておくことをオススメしますー！', 'なるほど\\nアドバイスありがとうございます‼️')\n",
      "('ｱﾗﾝ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa')\n",
      "('AWS', 'Word2vec', '可視化')\n",
      "(\"```ValueError: 'c' argument has 63 elements, which is not acceptable for use with 'x' with size 62, 'y' with size 62.このエラーの意味がよくわからないのですが、どなたか教えていただけないでしょうか？Word2vecの可視化をしています。```\",)\n",
      "('arrayの要素数が合ってない感じしますね。', '何行目とか分かります？？', '33 行目です', 'c（colors）と,x,yのサイズ確認したらどうなります？？', 'そこの要素数が違う的なエラーに見えます。', '質問する際には、どこまで調査して、どういう当たりを付けてるかを説明出来ると良いですよー！\\n\\nどういう意図で、何をやりたいのかとか、「コード読んで下さい！」だとしんどいので！！', '暇だったのでコード読みました。散布図を書いているコードの中の色指定がリストで与えているのが原因だと思いますよ〜', 'plt.scatter(Y[:, 0], Y[:,1], color=colors)それぞれのデータ数があってないというエラーですな', 'でも村上さんのいう通りで、デバッグする場合には意志を教えてもらえない場合だと、原因がわかってもここだよ！って言いにくいんです。なんでかっていうと、「いや、やりたいのはこうなんで...」と言われると悲しいのです...。', '技術的な質問に関しては、AWSのガイドラインが非常によく纏まってますので、是非参考にして頂ければ！！\\n\\n<https://aws.amazon.com/jp/premiumsupport/tech-support-guidelines/|https://aws.amazon.com/jp/premiumsupport/tech-support-guidelines/>', 'かしこまりました。ありがとうございます。', 'とはいえ、質問せずに学習止まっちゃう方が問題なので、困った際は最大限頑張って質問文作って頂ければと思います！！\\n\\n都度質問の仕方に関してはフィードバックさせて貰うことになると思いますが、良い質問が出来る技術を身につけられると、色々スムーズに進められるようになるので、めげずに頑張ってくださいね♪')\n",
      "('ｸﾛ\\u3000京大医学部3年',)\n",
      "('shinji', '増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', 'K', 'しみずこうじ', 'SHIMADA', 'Yan')\n",
      "('可視化', 'kaggle', 'Python', '書籍', 'EDA')\n",
      "('現在kaggleのnotebookを読んでいるのですが、EDAの部分でかなりデータの可視化がされていました。\\n中にはヒートマップなどの見慣れないものもあり、その都度調べながら読んでいます\\n\\nもしなにかpythonによるデータの可視化について、体系的にまとめた書籍やサイトがあれば教えていただきたいです\\n\\nそのようなものがなくても、その都度調べていったほうが良いなどのアドバイスがあればお願いします',)\n",
      "('<https://www.udemy.com/course/python-jp/>\\n可視化はあんまり専門ではないのですが、↑の\\nコースの中で、データの可視化の項目があります。\\n\\nちなみに、このコースは80%offとかで売っていることが多いので、\\nもし、そうなっていないなら、2週間位待つと\\nキャンペーンが始まる可能性大ですwww', 'このコース持っていますがもう3年は前なので中身古いって感じかもしれません。', '受講生コメントにもありますよね。', '質問に質問で返してしまいますが、\\n可視化したことで人がどのような印象を持つのかというところを知りたいのか、\\nそれとも、Pythonでビジュアライズするというところにフォーカスしているのかを書いておくと答えやすいかもです。\\n\\n前者なら、主にビジネスサイドの人に答えてもらったほうが役に立ちやすいですし、\\n<https://www.amazon.co.jp/dp/4492555226>\\n<https://www.amazon.co.jp/dp/B075WRLPGV> あたり？\\n後者なら、Python 円グラフ\\u3000ライブラリ\\u3000とかで ググったほうが良さげです。', '個人的には、kaggleであれば共有されているnotebookを眺めるのがかなり有効な勉強法かと思います、英語ではありますが(vote稼ぎで)ビジュアライズしかしていないnotebookも多数存在するので、このデータに対して何をどう思ったのか、その時ドメインをどう考慮していたのかについてはかなり理解が深まると思います(ё)', 'まぁ都度調べることにはなってしまうかもしれないけど、、笑\\nそれでも、この関数はこういう意味なんだってことは調べてみないと分からないので調べまくるのが個人的には正解だと思っています(あくまで個人的です)', '意図されているところが、こちらの方でなければ申し訳ないですが:sweat_drops:\\n&gt; 可視化したことで人がどのような印象を持つのかというところを知りたい\\nマッキンゼー式図解の技術 もよかったです\\n<https://amzn.to/2Wya2NX>', 'どんなグラフがあって、どうpythonで描くかという意図でしたら<https://qiita.com/4m1t0/items/76b0033edb545a78cef5|https://qiita.com/4m1t0/items/76b0033edb545a78cef5>', 'とか眺めてて楽しいです', 'すごく・・・体系的です。\\u3000めっちゃ参考になります。', '皆さんありがとうございます\\n\\nぼくの質問の意図は嶋田さんの回答に沿うものでした、説明不足ですみません\\n嶋田さん、ありがとうございます\\n\\nしみずさんのマッキンゼー式図解の技術も面白そうなので読んでみようと思います\\n\\nkaggleのnotebookは引き続き自分なりに読み進めていきます', '見るたびに”このコード書くのめんどいなぁ”と思ってしまうのは...向いてないんだろうか。', 'むしろ多分エンジニア向きらしいですよ笑、マシンにやらせて楽したいのが人類の進化につながります笑\\n\\nコピペ用のテンプレ用意しておけば大丈夫です:man-gesturing-ok:', 'コードテンプレの管理が下手くそなんですよね。もはや身体に叩き込めということか...。', 'まさにこれじゃないですか？\\n<https://qiita.com/coffiego/items/dfabde5f8588723b32d6>')\n",
      "('Kom',)\n",
      "('Hiroyuki.Tachikawa', 'こ ろ ん', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Katsuya Nagano')\n",
      "('機械学習', 'PRML', 'ML', '統計', '入門', 'データマイニング', 'ベイズ', '教科書')\n",
      "('PRMLを読み通せるようになりたいと思っています。しかしもともと文系なので数学の素養があまりないためそこから基礎を積んでいこうと思っています。一般的に機械学習で必要とされている線形代数、微積、確率統計は一通りやったのですがPRMLを読むために必要な数学として測度論や関数解析の分野は必要でしょうか？',)\n",
      "('PRMLをちゃんと読み込めてないし、測度論も関数解析も曖昧なので、ちょっと参考にならないかもしれないんですけども、少なくとも測度論は確かPRML上巻では範囲外だと書かれてたような気がします。\\n関数解析はどうだったなかぁ。誰かわかる人いるかなぁ。\\n私も文系からという事もあり、部分部分で必要に応じてマイペースに勉強してきたので、どの部品がどの分野にまたがっているのかよくわからないままやってきてしまって...。', '少なくとも関数解析は間違いなく必要です', 'お！そうなんですか。', '<@UREUHGVAQ>\\nご返信ありがとうございます！\\n文系から専門的な数学をやるのはかなり重労働ですよね:sweat_smile:\\nとりあえず必要に応じてやっていくしかないですね。', '<@UQSRC415Y>\\n関数解析必要なんですね。。バナッハ空間とか聞くだけで耳が痛いです。。笑', 'どの程度のレベルの理解をしたいのか明確にした方がいいです、でないとたぶん逸れていきます', 'おそらく数学の理解は通過点？のようなので本来の機械学習を進めることを忘れずにやっていけばいいかと', '<@UQSRC415Y>\\nそうですね。数学を専門的にやるつもりはなくて機械学習のエンジニアとして(とは言ってもまだただのエンジニアですが)困らないくらいでいいです。最低限抑えたら機械学習の勉強する中で都度身につけていったほうが良さそうですね！', '<@USU3HJY20>\\nちゃぶ台返し的な感じで申し訳ないですが、\\n\\nPRMLは一回挫折してまだリベンジできてないですが普通に仕事ができてるので、機械学習エンジニアがゴールならもう少し平易な物から始めても良さそうな気がします！\\n\\nゴールとしてはPRMLの理解というより、機械学習エンジニアとして働き始める所なんですよね？', '<@UJRAL005U>\\nそうですね！ただまだ一年くらいは普通のソフトウェアエンジニアとして働いていこうと思っているのでその間にPRMLまで行かないまでも出来るだけ土台を作って置きたいということで数学などの基礎的な部分の質問をさせていただきました！', 'データ解析のための統計モデリング入門\\n\\n実践Data Scienceシリーズ RとStanではじめる ベイズ統計モデリングによるデータ分析入門\\n\\n辺りがその次のステップとして良いのかなぁと思ったりするのですが、どうなんでしょう？\\n\\n皆さんのオススメなども聞いてみたいです！', 'あとは、一回実践やってみて理論に戻るとかでも良いかもですね！\\n\\n機械学習の振舞いを理解してから理論深めた方が負に落ちやすい気がしますので！\\n\\n一年あれば何周かできると思います！', '最初の本はamazonでも評価高かったので気になってました！\\nそうですね。自分も機械学習の実装の経験があまりないまま理論書を読んでも実感が湧かないのではないかと思っていたので手始めにオンラインコースを色々受講してみようと思います！', 'はい、それが良いかと思います！\\n\\nPRMLはラスボス的な位置づけで良いかと！！', 'ありがとうございます！自分なりのロードマップ作ってやっていこうと思います！', 'まだデータサイエンスブームになる前のバイブルなので、今だともっと今風だったり、アップデートされたり、同じ内容でもわかりやすい数式の本があるからマストかというと微妙みたいな話は時々聞きますね。じゃあなにがいいかまでは知らないですけど。\\n網羅しつつ数学的にちゃんとやってる本だとこれとか？\\n\\n<https://www.amazon.co.jp/%E7%B5%B1%E8%A8%88%E7%9A%84%E5%AD%A6%E7%BF%92%E3%81%AE%E5%9F%BA%E7%A4%8E-%E2%80%95%E3%83%87%E3%83%BC%E3%82%BF%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0%E3%83%BB%E6%8E%A8%E8%AB%96%E3%83%BB%E4%BA%88%E6%B8%AC%E2%80%95-Trevor-Hastie/dp/432012362X|https://www.amazon.co.jp/統計的学習の基礎-―データマイニング・推論・予測―-Trevor-Hastie/dp/432012362X>\\n\\n英語版は無料公開されてたはずなので一回覗いてみるとよいかもです', '人によっては、自分が挙げた後者の本が代替の本として使えるって言ってた気もしますね。', 'レベル感としては、仕事で機械学習使うなら抑えておいた方が良いかなーという感じでまとまってます。', '内容は教科書っぽいですね。', '<@UPR6BE9S6>\\nおぉ、カステラ本と言われてるやつですね。一回書店で手に取ってみたことありますがすごい重厚な本でしたねw\\n英語読めるので触りだけ見てみようと思います！', '<@UJRAL005U>\\nなるほど。どれをやればとりあえず仕事ができるレベルなのかわからなかったのでそういった本を探してました。実務に入る前に一回やってみようと思います！')\n",
      "('Hiroyuki.Tachikawa',)\n",
      "('こ ろ ん',)\n",
      "('PRML', 'ML')\n",
      "('あ、カーネル法出てくるから関数解析も入るか。',)\n",
      "('カーネル法もそうですがノルムですね', 'え！ノルムって関数解析の範囲なんですか。。。知らんかった。PRMLの範囲だとl1、l2が正則化項で出てくるぐらいの認識なんですけど、ノルム自体は距離をより広義の一般概念で扱うためのものなんです？', 'めちゃめちゃ雑にいえばその認識で大丈夫です')\n",
      "('ﾋﾛﾘｰ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('API', 'BQ', 'Slack', 'ダッシュボード')\n",
      "('Slack現在活発なチャンネルで自分が入っていないチャンネルってどうやって探せばいいでしょうか…?',)\n",
      "('この前渡したBQのログ使って、ダッシュボード化とかして貰えるとめちゃ嬉しいです！w', 'なるほど！\\nユーザーが参加しているチャンネルリストとかもありますかね', '発言数は見れたはずですが、ユーザーの参加リストは無かった気がしますね', '管理画面のアナリティクスページにそれっぽいのありましたね。', '閲覧権限は残してるはずなので、こちからも確認できるかと！！', 'チャンネルごとの参加者マスタはありそうだから、ユーザー単位のものはそこかView作らねば見れないっぽそうですね\\n了解ですー！', '&gt; チャンネルごとの参加者マスタはありそうだから、ユーザー単位のものはそこかView作らねば見れないっぽそうですね\\nAPIがあることは把握しているのですが、今回は取ってないですねー！', 'なるほど！')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('ﾋﾛﾘｰ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "()\n",
      "('質問失礼します。\\nサンキー図の代替になるような図は、何かございますでしょうか。',)\n",
      "('最初の切り口は一つになりますが、決定木はどうでしょう？', 'ありがとうございます決定木ですと、量的な流れを表現することができず、不可能なんですよね', 'グラフ理論で使われるような、ネットワークのグラフとかですかね？', 'ツリーマップか、ヒートマップのようなものを想定しています！\\nそしてそれでなんとかできました。（グラフ理論については明るくなく。。:sweat_drops:）')\n",
      "('りお',)\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ', '増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', 'ﾋﾛﾘｰ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '戸嶋\\u3000龍哉', 'Hiroyuki.Tachikawa')\n",
      "('SQL', 'データサイエンティスト', '転職', 'Slack', '統計', '統計検定')\n",
      "('質問させてください。\\n村上さんとTwitterでやりとりさせて頂いて、ITパスポートの優先順位高めと伺ったのですが、基本情報処理技術者とかまで目指した方がいいのでしょうか。\\nITパスポートに関しては足切り回避的に取った方がいいと言って頂いていて、受けようと思って色々調べているところなのですが、データ分析系の業務に就きたい！と思った場合、どこまで必要なのかなと…統計検定準1級を受けたいのでそれとの兼ね合いもありまして:sweat_drops:\\n長くなりましたが、お答え頂けると大変ありがたいです:woman-bowing:',)\n",
      "('りおさん初めまして。\\n\\nITパスポートの優先順位との事ですが、恐らく村上さんから勧められたと云う事であれば、そのやりとりから判断されたと思いますので、先ずは素直にチャレンジしてみては如何でしょうか？(*^_^*）\\n\\n\\nここのグループのメンバーで、特にslackに投稿されてるような方々はそもそもITパスポートどころか何の資格も取得していない方も多いかとお見受けしますが、それはその方々がそもそもそれら資格を取得・提示しなくとも十分仕事に成っている＆その実力を認められているからであり、りおさんが村上さんから勧められたと云う事は、データサイエンティストとしての学びの前にITパスポートの資格を取得するのに必要な知識が欠けているとそのやりとりで感じられたからお勧めされたのだと思います。\\n\\nチャレンジ報告、お待ちしてます！', '<@UN0HCK74M> \\nはじめまして。アドバイスくださりありがとうございます！\\n日本語下手で申し訳ないです…ITパスポートは早速受けようと動き出しているのですが、その上位資格もあることから、どこまで目指すのがいいのかなと考えてしまった次第です。\\nでも、本当に仰る通りですので、まずは目先のITパスポートに注力したいと思います。\\n\\nこのSlackの皆さんはそれぞれとても専門性が高いプロフェッショナル（またはそうなる学生さん）ばかりでいつもとても尊敬しております:sparkles:\\n\\nまたこちらで質問させて頂くこともあるかと思いますが、その際はどうぞよろしくお願いいたします〜！', '皆応援してますよ！( ´ ▽ ` )ﾉ', '資格は学習過程の方が意味あるのと資格は最終的に意味をなすことが正直少ない業界なので目的に合わせて資格勉強するぐらいでいいと思います。', '<@UL2TY2ERL> \\nありがとうございます！\\nITパスポートはIT関連の知識が圧倒的に足りないために受ける感じなので、その先は目的に応じて考えたいと思いました。\\nアドバイスありがとうございます:woman-bowing:', '未経験からエンジニアに転職した時はITパスポート取得しました。\\n幅広く基礎知識付けれるので体系的に勉強しておくのがおすすめです。\\nデータサイエンティストに興味持ったとしても、違う職種にもっと適性があるかもしれないですし！', '皆さんがおっしゃっているように、資格を持っていても特に評価することは無いですが、\\n\\nITパスポートで勉強するような基礎的知識を抑えてない方と一緒に仕事をしたり、教えたりするのはなかなか厳しいなーというが本音ですので、\\n\\nそういった背景から勉強するのをオススメしました！', '業界未経験からの転職や、転職した後、職務経歴として２年くらい経験積むまでは\\n資格は超有効なので、ぜひトライしてみて欲しいですね！\\nそれ以降は、業務経験の方が資格よりもエビデンスになるという業界長い人がいうポジショントークですねw', '資格そのものの有用性はおいておいて、基本情報以上の知識持ってると、一応大学の学部で情報系の知識を一通り学んだ人と同程度の基礎知識はある前提で諸々話せるので、体系的な知識の確認のためにも勉強して損はないかと思います。\\n\\n前職だと新卒の人には基礎知識つけてもらうために勉強してもらってました。\\n\\nITパスポートだと専門外の人が取るイメージのほうが強いので、ある程度プログラム書く前提のデータサイエンティストだとちょっと内容不足のイメージです。', '<@ULKPET3UK>\\nありがとうございます！\\n職歴がほとんどないうえに知識もないので、現状から目を背けずにチャレンジしようと思います！\\n業界歴が長いことが有益になる人というのは相当すごい人なイメージがあります…縁遠い世界なのでまずは自分の勉強を頑張ります！', '<@UJRAL005U> \\nありがとうございます！\\n意図を教えて頂けてありがたいです…同時に己の無知がとても恥ずかしくなりました。\\nとにかく頑張ろうと思います！', '<@UUAUDBR1N> \\nありがとうございます！\\nITパスポートと基本情報の境目というか、アプローチの違いってなんだろうと思っていたので、詳しく教えて頂いてとてもありがたいです。\\nまずはITパスポートから頑張ってみようと思います！', '何だ皆優しいじゃ無いか！・・・俺の時は塩対応なのに！(*￣m￣)ﾌﾟｯ', 'ちなみにデータ分析系の業務とはどのようなものを考えていらっしゃるんですか？', '<@UREUHGVAQ> \\nイメージしているのは、pythonやSQLなどを使ってデータ集計やレポート作成などです。\\n具体的には、（村上さんに教えて頂いたのですが）SQLによる集計業務はそれなりに需要があるとのことでしたので、まずはそこからと考えております。', 'なるほど。いいですね。確かに大きいデータの集計は結構大変で、企業にもよりますが、データベース操作ができる人が限られているせいで、事業部から延々と集計依頼が来る、、、というのはそこそこ進んでいる会社でもあるあるですね。', '&gt; SQLによる集計業務はそれなりに需要がある\\n確かにこういう業務は体系化されていて、ある程度手順書もあったりしているので、第一歩目にはいいと思います。\\n未経験としての窓口は最近ここがいいって話聞いたことあります\\n<https://www.green-japan.com/job/59907>', '私が同じ状況だとしたら、あくまで私ならですが、働きたい業界や企業の課題をリサーチしてレポートを書くことを最優先して、資格を取る前に仕事に就くことを考えると思います。特にレポーティングは知識や理論よりも、考える力が重要と考えているからです。もし働くために不足している技能があるなら、直接採用に何が不足しているか聞いちゃいますね。', '<@UREUHGVAQ>\\nあるあるなのですね…！実態を伺えてとてもありがたいです。\\nまた、アドバイスくださりありがとうございます。「考える力が重要」とのこと、よくよく肝に命じます。', '<@ULKPET3UK>\\nアドバイスくださりありがとうございます！\\nurlお送り頂いてありがたいです。会員登録してみようと思います。', '呼ばれた気がしたSQLおじさん(お兄さん)\\n分析する手前の仕事が多い', '<@UL2TY2ERL>\\nSQLお兄さんでいらしたのですか…！\\n分析する手前のお仕事が多いのですね……')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('しみずこうじ',)\n",
      "('ﾋﾛﾘｰ', 'Riita Satsuki')\n",
      "('クラウド', 'AWS', 'GCP', 'GPU', 'Azure', 'AutoML', 'ML')\n",
      "('クリーンエネルギーで動くデータサイエンス用のサーバー（正式な表現がわからない。。GCPで使えるAutoMLとかみたいなやつ）を用意したとして、どういう工夫をすれば使ってもらえるか？みたいな議論をしていまして、質問させてください:man-bowing:\\n\\u3000どうすればAWSやGCPじゃなくてこっち使おうかしら、という気持ちになりますでしょうか？\\n\\nクリーンエネルギーのメリット\\n\\u3000・エコ\\n\\u3000・あまり普及していないものを採用することの話題性\\nクリーンエネルギーのデメリット\\n\\u3000・電力供給が不安定（致命的:scream:）',)\n",
      "('<@US69FTTH6>\\n<https://www.gpueater.com/>\\nを参考にしてみるといいかもです！\\nここはマイニングファームで使われなくなったGPUを大量の払い下げで安く調達し、クラウドに載せたそうです。\\nそれで、ハード費用がおさえられているので、\\n価格をAWSやGCPに比べて格段に安く設定していますが、まだ軌道には載っていないようですね….\\n競争優位性を価格でやるにはGPUイーターの事例を分析してみると参考になるかもです！', '現実的な路線なら\\n<https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja>\\nみたいなJupyternotebookのホスティングがいいと思います。\\n中立であること活かし、デフォルトでAWSやAzureへもつなぎこみやすくした形で提供するとか！', '電力供給が不安定って分は、スケーリング在庫の部分で調整し、\\n電力量が低迷している時は在庫切れにして、小スペックで動く、\\n電力量が多い時はスケーリング在庫追加し、n時間スペックアップできるようにするとか', '<@ULKPET3UK>\\n&gt; GPUイーター\\nこんなものがあるんですね・・・ありがとうございます！\\n特化型はよさそうです！\\n&gt; グーグルコラボ\\nたしかに・・・中立型はいいですよね！\\n仕事でgoogle系使ってないんじゃ！とか、お客さんが○○を使っているから、いう方はいそうです！', '色々組み合わせて使いたいって流れがありますし、中立タイプは必要とされるはず！', 'ここも参考になりそう 簡単デプロイ！\\nエンジニアは怠惰であるから環境構築やデプロイが簡単なサービスは食いつきいいと思いますw\\n\\n&gt; <https://aws.amazon.com/sagemaker/|Amazon SageMaker>に似ていることを彼も認めているが、同社は、すべての主要なクラウドに対応させることを長期目標にしている。SageMakerは、当然のことながらAmazonのクラウドでしか使えない。それに対してCortexは、事実上すべてのクラウドで使える。実際、この点において、最も多い機能上の要求が、Google Cloudへの対応だとスプリンガー氏は言う。またロードマップには、Microsoft Azureへの対応もあると彼は話していた。\\n<https://jp.techcrunch.com/2020/01/25/2020-01-23-cortex-labs-helps-data-scientists-deploy-machine-learning-models-in-the-cloud/>\\n<https://jp.techcrunch.com/2020/01/25/2020-01-23-cortex-labs-helps-data-scientists-deploy-machine-learning-models-in-the-cloud/>', 'たしかに・・・楽であれば楽であるほどうれしみが増しますね！w\\nありがとうございます！', 'どんなものでも、新しいサービスを始めるときは、\\nニッチでも構わないので独占できる市場を生み出すことが重要だと思います。\\n\\nクリーンエネルギー(やそのPR)に関心のある企業から営業をかけてフィードバックもらっていくのはどうでしょうか')\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "('しみずこうじ', 'ﾋﾛﾘｰ')\n",
      "('GPU', 'BI', 'ディープラーニング', 'AI')\n",
      "('そりゃあもう「使用料」じゃない？(^m^)\\nあと禁断の「一人一台」とか(笑',)\n",
      "('超大規模の経済ほこる巨人にコストで挑むとプチっと潰されそうです笑\\n\\n1人一台笑', '個人的には、何気にブームが去った（もう割に合わなくなった）高級ビデオカードタップリ積んだマイニングマシンが手頃な値段で出てこないかなぁなんて思ってます(*￣m￣)ﾌﾟｯ', '確かに安く手に入りそうですね！\\n社内の人も今はマイニングでGPU使うより高性能な特化型があるといわれてました笑\\nこれのことかしら？\\n<https://pc.watch.impress.co.jp/docs/column/semicon/1193897.html>', 'マイニングブームだった頃人気だったのは\\nGTX1050tiとかGTX1080tiだったので\\nこれらはかなり安く大量に放出されてると思いますよー！\\nGPUモデルによって\\u30001Wあたりハッシュ演算量(マイニング効率)が全然違っていて\\n機体差あってそれをいかにあげるかなんてことを研究してましたw', '<@US69FTTH6>\\nASICですね！\\n先日お伝えしたnicehashの試算画面で出てくるこれらは\\n全部ASICの機種名です', 'BITMAIN とか\\u3000Canannがメーカー名\\nその後に続くのはモデル番号です', 'BITMAINがシェア90%以上ですね\\n機械の信頼性(故障しにくさ、ハッシュレートの安定性)も一番です', 'なるほど、マシンも日進月歩ですね！', '1Qごとに新機種が出てきて情報追うのが大変でしたw', 'それは早すぎますね笑', 'NVIDIA、ディープラーニング専用にJetsonのデカい奴とか出してきたらウケる(笑\\n\\nこれまで支えてきたCUDA勢にフルボッコ必至w', 'Jetson！初耳です調べてみます', '自動運転とかに使うエッジ処理専用のGPUなんですね！\\n&gt; ディープラーニング専用\\n→これは\\u3000Tesla\\xa0*P100*とかですね\\u3000最初出た時は一個100万くらいしてましたw', '不思議なことに、P100をマイニングに使っても、10万円のGTX1080tiから少しくらいしかマイニング性能は上回らないのですー', 'なんで悪いコスパ……:scream:')\n",
      "('Hiroki Narita',)\n",
      "('戸嶋\\u3000龍哉', '吉村政彦ｰ産業ｽﾊﾟｲ')\n",
      "('自然言語処理', '機械学習', '統計', 'Python', '書籍')\n",
      "('質問させていただきます．\\n\\n学部４年の研究で，自然言語処理関連のこと（日本語の処理）をすることになったのですが，\\n日本語の自然言語処理関連の論文や自分がやりたいことに関係する論文を調査するのに苦労しています．体系的に学べる本やサイト，関連論文があれば教えて下さい．\\n\\n「日本語における科学技術論文の添削補助や自動化、それによる文章の可読性向上」といったことが大まかな研究テーマです．\\n\\n自然言語処理と聞くと，機械学習や，統計学のワードが沢山でてくるのですが，僕が知りたいのは，\\n「どういった文がわかりやすいか」，「どのように修正すると文章の可読性は上がるのか」といった言語学に関連するようなものな気がしています．\\nなので，関連研究（言語学，ルールベース，機械学習，統計などの手法は問わず）の情報があればご教授いただけると幸いです．\\n\\nよろしくお願いいたします．',)\n",
      "('道具として使う上でまず読んでおいたほうが良いのは\\n<https://www.oreilly.co.jp/books/9784873114705/>\\nですね（12章以外は基本英語のお話ですが）。\\n一通り Python のコード付きなので、何がどんな感じでできるか、が専門外から入る場合でもイメージつくかなと思います（私も最初に読みました）。', 'あとは「論文」をターゲットにしている場合は多少ずれるかなと思うのですが、例えば外国人向けに日本語のテキストを簡略化してわかりやすく伝えるためのタスクとして「やさしい日本語」というものがあるので、参考になるかもしれません。<http://www4414uj.sakura.ne.jp/Yasanichi/>', '想定する「わかりづらい」のパターン化がまず必要で、パターン化できればそれぞれに対して対応するタスクが自然言語処理の分野になんらかあるはずです。', '<@UUAUDBR1N> 様\\n\\n非常に参考になりそうな文献が沢山で助かります．．．！\\n\\n&gt; 想定する「わかりづらい」のパターン化がまず必要で、パターン化できればそれぞれに対して対応するタスクが自然言語処理の分野になんらかあるはずです。\\nなるほどとおもいました．．．！\\n\\n個人的には，評価指標のようなものを作って定量的に「わかりやすさ」を表現できるような手法を考案する必要があるとおもっています．\\n\\nこの研究をもともとやっていた先輩は，「文章の結束性」というものに着目，定量化し，結束性を上げることで可読性を改善するというアプローチをとっていました．\\n\\nしかし，「結束性を考慮した可読性の向上」は，可読性を向上させるための，一つの手段であって，すべてがこれで解決するわけではないとおっしゃっていたので，\\n異なるアプローチを取る必要があるとおもっています．\\n\\nその点で，「やさしい日本語」の文献は読み漁ってみようと思います．\\nまた，自然言語処理について体系的に学べる本も並列で進めようと思います！\\nありがとうございます！', '成田さんが仰っているのは、詰まるところ、「話がちゃんとモデル化出来ているか否か」の領域かと。\\n\\n\\nこの手の話をする時、よく電動ドリルを例えに出すのですが、\\n\\n【モデル化無し】かつて無い○○wのハイパワー！トルクもクラス最強！最新の工作機械に依る高精度仕上げで超静音＆クラス最小の心ブレ！\\n\\n【モデル化あり】とっても静かなのにキレイな穴がサクサク開けられる最新式の電動ドリルです！\\n\\n・・・という事では無いかと(*^_^*）', '<@UN0HCK74M> 様\\n\\nありがとうございます！\\n\\n&gt; 「話がちゃんとモデル化出来ているか否か」の領域\\nこちらについて少し詳しく知りたいのですがなにか参考になるようなサイト等はございますでしょうか．', 'ん～・・・私自身が別段サイトや書籍で学んだわけでは無いのでちょっとオススメ出来るコンテンツは無いのです(^_^；\\n\\n\\n\\nただ、先程の電動ドリルの話をよく観察して貰うと判るのですが、モデル化出来て居ない方の話は「理由の説明に終始」しているのに対し、モデル化出来て居る方の話は「結果の報告に終始」している点に気付かれると思います。\\n\\nAppleがiPod～iPhoneで成功したのは正にこの「結果の報告に終始」していたからであり、その時他社は「高スペックである理由の説明に終始」していた事は、皆さんご存じの通りです。', '<@UN0HCK74M>\\nなるほど！\\n文章を書いていると伝えるべき本質を見失っていくことはありがちなことですね．．．\\nありがとうございます！')\n",
      "('sho.kumada',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('時系列', '教科書', '書籍', '正規分布')\n",
      "('時系列分析について質問させていただきたいです。\\n「定常過程のデータに対して差分を取ってしまった場合、利用可能な情報を大幅に失う」という記述を\\n書籍で見かけました（「経済・ファイナンスデータの計量時系列分析\\u3000沖本竜義」（P128）。\\n差分を取ってしまった時の不具合事例（誤って〇〇という結論を導いてしまったとか、結論が出なかったとか ）\\nをご存知でしたら、教えていただきたいです。\\n書籍に書いてあるように不必要に情報が削がれることはイメージできるのですが、どのくらいまずいことになるのかイメージ\\nできず。。\\n\\nps\\nコロナの感染者数の時系列データから中国、韓国、日本の感染者数の因果性の有無（グレンジャー因果）を調べたいのですが、\\nデータを定常にする段階で行き詰まりました。',)\n",
      "('階差取るかどうかは結構毎回悩むのですが、失敗談みたいなのはあんまりないかもですね・・・\\n\\n少し考えてみます！', 'ありがとうございます。私も継続調査します。教科書のデータはすんなり分析できるのですが、実データとなると難点が多く笑', '実データだと、そんなにきれいじゃないですよねｗ', 'はい、教科書のデータは上手くいくデータを選んでいる気がします笑\\u3000skleranのチートシートの時系列分析版が欲しい\\n\\n<https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html|https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html>', '<@UMQ7CDJUR> \\n例えば定常過程が平均μ、分散σの正規分布に従うとした場合、定常過程なら平均値、分散の推定値から信頼区間を出せるけど、差分を取っちゃうと出すのが困難になるとかって感じですかね。', '<@UJRAL005U>\\n回答ありがとうございます！\\n確かに、予測時の信頼区間の計算にガッツリ標準正規分布使っています（沖本本）\\n下手に差分を取るとそれが使えなくなりそうですね。時系列の場合、ピンポイント予測はあまり意味がない（あたる気がしない）と思うので、信頼区間を計算できないのは致命的ですね。\\n時系列はある程度理解できるまでまだ時間かかりそうです。。')\n",
      "('sho.kumada',)\n",
      "('しみずこうじ',)\n",
      "()\n",
      "('すみません、、追加で質問させていただきたいのですが、\\n中国の1日の感染者数（累積感染者数の1階差分（2番目のグラフ））で2/12あたりに巨大なピークがあるのですが、、\\n事情をご存知の方がいたら教えていただきたいです。\\nデータはこちらから拝借しました。\\n<https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases>',)\n",
      "('春節が延期されたことと関係ありそうですね。', 'これっぽいですね\\n\\n<https://ja.m.wikipedia.org/wiki/%E6%96%B0%E5%9E%8B%E3%82%B3%E3%83%AD%E3%83%8A%E3%82%A6%E3%82%A4%E3%83%AB%E3%82%B9%E6%84%9F%E6%9F%93%E7%97%87%E3%81%AE%E6%B5%81%E8%A1%8C_(2019%E5%B9%B4-)|https://ja.m.wikipedia.org/wiki/%E6%96%B0%E5%9E%8B%E3%82%B3%E3%83%AD%E3%83%8A%E3%82%A6%E3%82%A4%E3%83%AB%E3%82%B9%E6%84%9F%E6%9F%93%E7%97%87%E3%81%AE%E6%B5%81%E8%A1%8C_(2019%E5%B9%B4-)>', '<@US69FTTH6>\\nありがとうございます！なるほど、、基準が変更されたんですね。そういう場合どうデータを扱うか悩みます。')\n",
      "('ﾋﾛﾘｰ hirory',)\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "()\n",
      "('今、このコミュニティは158人となっていますが、有識者のゲスト参加もあると思います。\\nそれを除くと、スタンダードなギルドメンバーは何人いるのでしょうか？\\n今月のアクティブランキングみててふと思いました\\n<https://data-learning-guild.slack.com/archives/CJNKJ8JKW/p1585228286000400>',)\n",
      "('さて、私の偽名、幾つ見破れるかな？と揺さぶってみるテスト(笑', '自分でも把握出来て無いのですが、（データの人としてどうなのという質問は受け付けないw）\\n\\n100人は超えてる感じですかね！協業の検討で招待して、そのままアカウントだけ残ってるような方も結構いますね。', '講座経由で入ってるメンバーもいたりすので、あんまりスタンダードという概念は無いかもです。', '「私の偽名」←ここ笑うとこだぞ！', '自作自演！？', 'レスありがとうございます！\\n\\n&gt; 100人は超えてる感じですかね！\\n→意外と(いい意味で)多いんですね！\\n見かける人がほぼトップ１０に入ってるので、気になりました！', '<@UN0HCK74M>\\n&gt; 私の偽名\\nもしそうだとしたら、\\n複垢有料課金で、一方で無料枠獲得し、\\nもう一方のアカは普通に課金払ってるすごい人ってことになりますwww', '<@UJRAL005U>\\n&gt; 講座経由で入ってるメンバーも\\nそうなのですね！\\n講座修了者は終了後もDLG永年無料という特典なのですか？', 'そのメンバーは1年間無料って感じですねー！', '今後の講座では、プランによっては永年無料のも出す予定ですー！', '<@UJRAL005U>\\nなるほど！だんだんギルド構成理解できてきました！\\n数十万する講座だと思うので、一定期間無料枠や永年無料もあっていいと思います！')\n",
      "('こ ろ ん',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Satoru Mikami')\n",
      "()\n",
      "('ギルド内にセキュリティ診断のお仕事されてる人っていますか？webでもアプリでもなんでもいいです。\\n\\n質問の経緯としてはセキュリティ診断士の方の業務内容とかツールとかを知りたいなと思いました。',)\n",
      "('<@UKY4VFB5E> \\nセキュリティ周り結構強いかと思うんですけど、セキュリティ診断士ってご存知です？', 'IPAの情報処理安全確保支援士のことだと思ってます', '<https://www.lac.co.jp/service/education/comptia_pentest.html|https://www.lac.co.jp/service/education/comptia_pentest.html>', '企業の脆弱性診断を受託して仕事するひとですね。\\nペネトレーションテストで調べるといろいろとツール出てきますよー', '<https://www.lac.co.jp/service/consulting/penetration_test.html|https://www.lac.co.jp/service/consulting/penetration_test.html>', 'ツール自体はもちろん知っているのですが具体的に業務ってどーなんだろうって思っていました、試験と出ることと同じことをする認識でよさそうですね', 'ありがとうございます')\n",
      "('K',)\n",
      "('masso', 'しみずこうじ', 'yuji.imuta', '吉村政彦ｰ産業ｽﾊﾟｲ', 'Yan', 'ﾋﾛﾘｰ hirory')\n",
      "('書籍', 'OCR', 'DX')\n",
      "('電子書籍の方が安くて、学術的な参考書でなければ紙じゃなくてもいいかな、、と思い始めてる今日この頃なのですが、Kindle等を使用している方の中で、オススメはありますか(´・ω・｀)？悩んでるのは、\\n\\n・カラーも対応してると嬉しい(グラフとかイラストの都合上)\\n・広告の有無ってどうなのよ\\n・ディスプレイサイズって携帯の面と可読性の面の両方向から考えた時どれくらいがベストなんさ(15inchラップトップはデカすぎ、とかそういう感覚的な指標)\\n\\nネットで検索しても広告収入しか興味ない人たちが書いた記事ばっかりなのでここで質問させてください:joy:(おひねり、、)\\n',)\n",
      "('私のおすすめはiPad miniです。\\nただし、以下前提\\n・kindle以外の用途もあり\\n（メモ、動画（PrimeVideo, Udemy, Youtubeなど））\\n・一度買ったFireHD8が壊れた経験あり\\n・iPhoneユーザー、MacBookユーザー\\n\\nってところは注意していただきたいとして、iPad miniのメリットは\\n\\n・サイズ重さがちょうど良い（移動時間に読んでても手が疲れない）\\n・スペックの割りにやすい（2019年モデルですがiPhoneX?と同じチップで２〜３万ぐらいやすい）\\n・他のApple製品との連携が良い（まあ、当然ですね）\\n\\n冒頭にも書いたように、最初は「本を読む＋PrimeVideoをみる」だけを目的にFireHDを書いましたが、以下の問題点がありまして、今はあまり購入したいと思いません。\\n・特に何もしてないのに３ヶ月ぐらいで壊れた（充電できなくなりました）\\n・iPad miniに比べてサクサク感がない\\n・他のアプリをしようと思っても、ストアになかったり、スペックが足りなくて使い物にならない可能性が高く、拡張性がない\\n\\n長くなりましたw', 'カラーで読めますし、Kindle HD8を使ってます。\\nナイトモードと節電モードを併用すれば目にも優しいです。\\n\\n電子ペーパータイプのKindleは、若干画面が小さいので、専門書や技術書は文字を変更できないものが多いので、個人的に変更できないヤツが見辛かったです\\nカラーに対応してないですし。\\nその代わり電池の持ちがハンパないです\\n\\nお風呂で読みたい派でしたら、白黒しかないですが、最新のKindle Paperwhiteが防水仕様でした。', '僕もipadが良いですね。\\n本何冊もカバンに入れずにipadだけで済むっていうのが大きな魅力ですね！\\n\\napple pencil対応だとノートにもなったりしますし、ただ、紙との大きな違いは自分が知りたい情報にピンポイントでアクセスできるかはあります。kindleだと文字検索できますけど、紙の場合、あそこらへんにあったなあで調べ物ができるのは大きな魅力ですね！', 'iPad miniを初めとしてタブレット5枚使いの俺が来ますたよ！(笑\\n\\nそれぞれの善し悪し、書きますね(^m^)\\n\\n【最強】iPad miniシリーズ\\n特に4～5ならもう文句なし。但しmicroSDが使えないので必然的に大容量モデルを選択する事に。また殆ど安売りしていないのでコスパはけして良くは無いが、満足度は多分ベスト。\\n\\n【Kindle Fireシリーズ】\\nHD8とHD10x2枚使ってます。オススメはHD10をAmazonのセールの時に購入（1万円位で買える）です。\\n少々重いのが難点ですが、コスパは現行全てのタブレット中最強だと思います。脱獄は比較的簡単なので、脱獄してドロイドタブとして使うのがオススメ。\\nウィークポイントは「純正カバー（結構優秀）が絶対安売りしない」ところですｗ\\n\\n【HUAWEI MediaPad M3 Lite】\\n物理的にはかなり優秀。\\n但し情報抜いてるのがバレてからGoogle八分にされている（俺の機種はセフセフ）ので幾ら物理的に優れててもオススメ出来ない。', '個人的にはでかいほうがいいので林檎教だとiPadpro12.9一択ですが、持ち運び気にしない人限定かも。', 'そういやMediaPadがありましたね！\\n穴場だなぁ\\u3000検討してみます！', 'Kindle Oasisを数回使って放置してしまってる….\\n流し見みたいにバババッとページめくりできないのが、僕に合わなかった….\\n昨年3万円くらいの最上級モデルだから、そんなに値下がりしてなければ手放そうかなぁ', 'iPad、高いのが欠点ですかね笑', '<@US69FTTH6> 間違いない。', '皆さん、ご回答ありがとうございます！！\\nいろいろみなさんが実際に使用した際の所感を教えていただき、大変参考になります(๑╹ω╹๑ )！\\nKindleの拡張性に関しては、調べていてもよくわからなかった（結構皆さんレビューでは満足されている方が多い）のですごくびっくりです、、\\nだがしかし、やはり林檎製品は高いですね、、、華為は（）\\n\\niPad mini 4 (型落ち)を買うのもありなのでは？と少し考え始めました、、iPadを持っている方々は、本を読む以外に何に使用していますか？（iPhone11Proあるし、MacbookProもある、iPadは何ができる/何をしたくなる、、？？）', 'どれだけのコストをかけるべきか迷いますよね〜\\n私はiPad miniで以下の使い方をしますね\\n\\n・メモ：学会とか電話での打ち合わせとか。メモ→macbook との同期が迅速なのが良い。絵を描かない限り、Apple pencil1の書き心地に問題はない印象。追記として、私はベーパーライクなフィルム使ってます\\n\\n・kindle：kindleストアの書籍はもちろん、無料配布されてるpdf資料のviewerとしても使ってます。iPadの場合、safari→kindleにファイル転送までの流れが使いやすい\\n\\n・primevideo(iPadじゃなくても別に…)\\n\\n・youtube(iPadじゃなくても別に…)\\n\\n・udemy→移動時間などで使うことが多いので重宝してます。そうでない場合はmacbook で良さそう。\\n\\nって感じですかね', '中古も視野に入れるのもありかと。', '<@URDDX224S> さん\\n確かにメモとしては非常に重宝しそうですね！学会でmacbookでメモしてて、確かにメモは取りやすいけれど持ち運びが重いって言うのは少し気にしてました！笑\\nudemyは使用していないのでアレですが、やはり他のapple製品との同期っていう観点からシームレスに扱えるっていうのが最たる利点なのですかね？\\n\\n<@UMC518ER0> さん\\n確かに中古はありですね！WiFiモデルであれば、正常に動作するのであれば中古でも問題なさそうです！ざっとMercariを眺めていましたが、みんなiPad miniとしか書いていない（世代不明）なのが多すぎて諦めましたが、、笑\\n実店舗で探すのはアリかもしれませんね！ありがとうございます！', 'そうですね、シームレスに扱える点は重宝します。\\nあと、Kさんも言われてる通り、持ち運びですね\\nポスターセッションでメモを取るときによく感じます\\nあとは、有料アプリ入れればPDFにメモ直書き、OCRでメモのテキスト化なんてのもできます(自分はそこまでやってないですがw)', 'なるほどねぇ、、、実際に一度シームレスの状態で使用してしまったが最後、他のタブレット端末には戻れなくなりそうですね、、怖い、、笑\\n使用頻度によっては、確かにiPadは利点が多そうですね！Appで拡張できるのも何より嬉しいですね！', 'そうですねー\\nそれがAppleの戦略ですねーw\\n少しでも参考になれば幸いですー')\n",
      "('masso',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('Slack', '前処理')\n",
      "('二つ質問です。\\n（１）\\ntf-idfのidfにおける全文書ってどのようなデータにすればいいのでしょうか？idfの値は、「どの文書にも出てくる単語は一つの文書特有の単語ではない」というものをスコア化すると理解しているのですが、\\n\\n全文書をどのようなものに設定するかで何が「どこにでも出てくる特徴的な意味を持たない単語」になるかが変わってくると思うんです\\n\\n（２）\\n（関連： <#CRYJLV9JP|07-12-ユーザー検索プロジェクト> ）\\nDLGのSlackにおける発言をメンバーごとに集約して、WordCloudを作ろうとしています\\nその際に重要な単語のみを使いたいのでtf-idfを計算しようとしています。\\n\\n今考えているのは、\\n「メンバー一人の発言の集合（前処理済み、分かち書き済み）を１つの文書」と定義し、「メンバー全員の発言の集合を全文書」と定義するやりかたです。\\n\\nこのやり方に問題があるか、あるいはどういう視点で考えればよいかなどアドバイスいただけると嬉しいです。',)\n",
      "('（1）\\nちょっと認識間違ってるかもしれないですが、「コーパス」と言われる物で、\\n\\n・一般的に準備されているものを使う\\n\\n・メディアにある全記事をコーパスとする\\n\\nなどがあるかなぁと思います。どこと比較きて特徴を出したいのかで決める感じかなと。\\n\\n例えば、メディア内での特徴を抽出したいのか、メディアも跨いだ上で特徴を抽出したいのかでコーパスが変わって来るかなと！\\n\\nslack 分析においては、\\n\\n文書→ユーザーの発言\\n全文書（コーパス）→slackの全ユーザーの全発言\\n\\nなどとしてあげると比較的上手く行きそうな気がします。\\n\\n例えば、「データ」みたいな単語は使ってても特徴的では無いよねと判定されると思うので。\\n\\n一般人と比べた際の特徴を取って来たいなら他のslackのデータも合わせたコーパスを作れるとベストって感じじゃないでしょうか。', '（2）\\n全く同じアドバイスになってましたねw\\n\\n良いと思います！', 'アドバイスありがとうございます！\\nモヤっとしてたものがスッキリしました！')\n",
      "('りお',)\n",
      "('しみずこうじ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', 'Yan')\n",
      "('前処理', 'SQL', 'データ加工', '可視化', '自然言語処理', 'AI', '転職', '統計', '統計検定')\n",
      "('私事都合により週３程度のアルバイトをしたく、ぜひデータ分析系（前処理とかも）の業務ができればと考えております。\\nしかし、自分でGoogle検索などしてもなかなかヒットせず、皆さんのお知恵をお借りできればと思います。おすすめの案件や転職サービスをご教示頂けますと幸いです。\\n開発できる言語はpython（実務１年）、C（学生時代）、SQL（村上さん講座）あと言語といえるかわかりませんがシェルスクリプト（実務１年）です。\\nどうぞ宜しくお願いいたします。',)\n",
      "('紹介受けつつも、面談前に別のとこが決まったので利用出来なかったのですが、ここは案件多そうでした\\n\\n<https://www.team-ai.com/|https://www.team-ai.com/>', '少し補足させて頂くと、\\n\\n・アクチュアリーの経験あり（アクチュアリー系の資格も保有）\\n\\n・直近ではpythonを使って自然言語処理のデータ加工と可視化\\n\\n・統計検定2級\\n\\n・淡々と地味な前処理などをやることに対して抵抗が無い\\n\\nという感じなので、前処理系の所をバイトとしてはかなり良い感じなのかなと思いますので、もし仕事依頼したい方や会社さんなどがいらしゃったら、是非ご紹介頂ければと思います～♪\\n\\nアルバイトの探し方的なキャリア的な方向性の相談でも全然OKです！！', 'うち行けるかもだけどちょっと採用凍結なんで聞くだけ聞いてきます', 'つよそう', '<@US69FTTH6> ありがとうございます！勉強会みたいなのに参加してそこからチャンス掴む形式なのかなと思いつつ、まずはよく拝見いたします:woman-bowing:', '<@UJRAL005U> \\n補足ありがとうございます:woman-bowing:大変ありがたいです。\\nと同時に、自分の売り込み方勉強になります…！:sweat_drops:', '<@UL2TY2ERL> \\nありがとうございます！\\nもしご入用でしたら、履歴書と職務経歴書はお送りできます…！', '<@UMC518ER0> \\n強く見えてたならとても嬉しいです:blush:', '良い流れすね', '<@UQP32MM6K> \\nteam AIの石井さんとさっきwebで面談してたので、何か案件とかないか聞いてみましょうかー！', 'バイトというか業務委託枠で増やせるかの確認する感じですね。\\n時給どれぐらい欲しいかによりますけど。', '<@UJRAL005U> ありがとうございます！どうぞよろしくお願いいたします！:woman-bowing:', '<@UQP32MM6K>\\n多分2000円貰えたら大満足とかって感じだと思いますが、どうなんでしょ？\\n\\n最低賃金で検討してましたよねw', '優先度は時間とプレッシャーが少なめって感じですよね？', '余裕です。', 'それは大丈夫ですね。納期がほぼない仕事なので。ただ現状でおそらく、GWあけまでは面接など難しいかもです。出社停止までいっているので', 'なるほど・・・\\n\\nなかなか厳しいですね・・・', '<@UJRAL005U> <@UL2TY2ERL> \\nはい、村上さんのおっしゃる通り、時間とプレッシャーが少なめで、できれば自分が仕事させて頂く際に要件がかっちり定まっているとありがたいです。\\nお給料は2000円頂けたらとても嬉しいです！\\nGW明けまで面接など難しい件承知いたしました。早くコロナが収束すること願っております。')\n",
      "('尾銭泰徳 ﾃﾞｰﾀｻｲｴﾝｽ勉強中',)\n",
      "('しみずこうじ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'masso')\n",
      "('AI', '機械学習')\n",
      "('いろんなメディアやキュレーションサイトがある中で、\\n皆さんはAI、DS関連のニュースってどのようにキャッチアップされてますでしょうか？\\n\\n私は主にtwitterで情報を知ることが多いのですが、更新を追っかけたいメディアとかも最近増えてきたので、情報の取得方法を整理してみようと思いまして、、、\\n\\n私が思いつく感じでは以下の4つぐらいなのですが、皆さんの日々のルーティーン的なものを共有していただけると助かります！\\n1. twitterで専用タイムライン整備\\n2. RSS登録\\n3. ブックマークしたニュースサイトを毎日巡回\\n4. googleアラートにキーワード登録\\n',)\n",
      "('facebookのAI系グループの投稿も見てます！', '大体Twitterとニュースサイトとかですかね', 'ツイッター強い！\\nやっぱりpull型で勝手に情報が流れてくる仕組みの方が有効そうですね', '機械学習エンジニアになるための本に書かれていたサイトをキュレーションツールに登録、Twitterをフォローって感じですね', 'なるほど、メディアのTwitterをフォローするの良さそうですね！', 'ですねー！')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('はやと-復学しました', 'Hiroyuki.Tachikawa', 'K')\n",
      "('numpy',)\n",
      "(\"質問をしてもよろしいでしょうか？\\n\\nlightgbmで目的変数yが[0,1,2,3,4]の５つのクラス分けをする際に、 予測値y_predが０〜１の範囲の値になってしまうのですが、これはどうしてでしょうか？\\n昨日今日いろいろためしましたが、わからないので質問させくてください。:man-bowing:\\n\\nちなみに、他の説明変数Xは５列ほどですべてintです。\\n\\n```lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\\n\\nparams = {\\n    'objective': 'multiclass',\\n    'metric':'multi_logloss',\\n#     'metric':'multi_error',\\n    'num_class': 5,\\n    'max_bin': 800,\\n    'learning_rate': 0.01,\\n    'num_leaves': 100\\n}\\n\\nmodel = lgb.train(\\n    params,\\n    lgb_train,\\n    valid_sets=[lgb_train, lgb_eval],\\n    verbose_eval=10,\\n    num_boost_round=1000,\\n    early_stopping_rounds=100\\n)\\n\\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)```\\n\",)\n",
      "('y_trainを[0,1,0,0,0]みたいに5個出力を出す感じにしてます？それだとしたら5つの値がこれだと0か1（1は一つだけ）って感じで出ると思います！\\n出力がmalticlassで分類になってるんで、', 'もし0から5で出すならregression扱いのモデルを作る（この場合2.5とか小数点でも出てくるので0、1の方がいいと思いますが）にするべきかなと思います〜', 'もしどうしてもできない場合はsklearnのapiで使えるタイプもlightgbmはあってそちらの方が個人的には使いやすいんでそっちも試してみるのもありかなと思います', 'ありがとうございます。\\nonehotだともちろんできるんですよね。\\nでも、LGBMではあまり推奨されていません。\\n\\nregressionにすることも可能ですが、なぜできないのかな。という思いです。\\n\\nそうなんですよね。skleanでやりたいんですけど、optunaが使いたくて。。。\\n\\nすいません。', 'Onehot推奨されてないんですね、知らなかった:thinking_face:\\nsklearnでもoptunaは使えますよ！', 'え、そうだったんですね！ありがとうございます。', '確かにpredictの引数見ましたが、一定の閾値以上のラベルを予測値とするような仕組みがなさそうですね。\\nまぁclassificationなら\\nnumpyを使って以下とかでしょうか。（やりたいことはこれであってるかな...。）\\nnp.argmax(y_pred, axis=1)', 'lightGBMもNNも分類では最後にsoftmaxを噛ませているためですかね（一概にそうじゃないかもしれませんが）\\n今使っているlgbもnnも出力としては同じように確率になりますね、、 <@UREUHGVAQ> さんのいう通り、最大のものを結果とするもいいですし、アンサンブルするときにその確率をそのまま合わせちゃうのもアリなのでやりたいことに依存しそうです、、', '<@UT5FYCM6D> 詳しくは見てないんですが、predictの関数にraw_score、という引数があったので、出力関数はsoftmaxっぽいすね。', 'もしかしたら、\\n```\"objective\"=\"multiclass_ova\"```\\nで出力が意図したものになるかも？？使ったことないのと、ネット上にデータが少ないのでどうなるかは不明ですが、、', 'みなさま、ご返答ありがとうございました。\\nそして返信が遅れ申し訳ございません。\\nnp.argmax(y_pred, axis=1)\\n\\nで目的を達成することができました。\\n\\nソフトマックス関数が噛んでしまっているのは避けられないんですね（むしろこちらのほうが丁寧かもしれませんね）')\n",
      "('ｸﾛ\\u3000京大医学部3年',)\n",
      "('はやと-復学しました', 'K', 'Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'chan', 'Hiroki Narita')\n",
      "('kaggle', 'pandas', '前処理', 'DataRobot', 'AutoML', 'BigQuery', 'GCP', 'GPU', 'jupyter', 'SQL', 'ML')\n",
      "('現在kaggleのコンペに参加しています\\n\\nコードはgoogle colabで実行しているのですが、クラッシュが起きてしまい、最後のデータまでたどり着けないということが、頻繁に起きます\\n\\n対策として、公開されているnotebookに倣って、データをその都度消して詰めたり、メモリ節約方法は取っています。\\n\\nしかし、公開されているnotebookをそのままコピーしたものさえも、google colabでは実行できないことがあります\\n\\nkaggleはメモリ量との戦いでもあるという話を聞いていたので覚悟はしていたのですが、これほどまでとは思っていませんでした\\n\\nkaggleで戦ってきた皆さんにメモリに関する所感を聞いてみたいです。また、よい節約方法があれば教えてください\\n\\n',)\n",
      "('正直delとgc_collectとメモリ削減してるならあんまりないですね、、、\\n強いて言えばLocal で回すと少しメモリはまだエラーになりにくいイメージです。\\nあと、もし提出まで作るのではなく特徴試すだけなら特徴作ってテストで回すのを一部のデータだけでやるとかやればメモリ削減になるかなって感じです！（僕はやらないですが）', 'あまりないのですね...コンペによっても違うのかもしれませんね\\nlocalでやってみます\\n\\nありがとうございます', \"基本localでやっているのですが、やはりメモリは問題になります（今kaggleで使っているデータセットは特徴量諸々でtrain, test共に2GB超）\\nなので、データが大きくないときには気にしなくていいのですが、大きいときにはデータの型を変換しています。\\nfloat64-&gt;float16とかになるだけで75%近くメモリ解放できるのでおすすめです\\n\\n`def reduce_mem_usage(df: pd.DataFrame,`\\n                     `verbose: bool = True) -&gt; pd.DataFrame:`\\n    \\n    `numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']`\\n    `start_mem = df.memory_usage().sum() / 1024**2`\\n\\n    `for col in df.columns:`\\n        `col_type = df[col].dtypes`\\n\\n        `if col_type in numerics:`\\n            `c_min = df[col].min()`\\n            `c_max = df[col].max()`\\n\\n            `if str(col_type)[:3] == 'int':`\\n\\n                `if (c_min &gt; np.iinfo(np.int32).min`\\n                      `and c_max &lt; np.iinfo(np.int32).max):`\\n                    `df[col] = df[col].astype(np.int32)`\\n                `elif (c_min &gt; np.iinfo(np.int64).min`\\n                      `and c_max &lt; np.iinfo(np.int64).max):`\\n                    `df[col] = df[col].astype(np.int64)`\\n            `else:`\\n                `if (c_min &gt; np.finfo(np.float16).min`\\n                        `and c_max &lt; np.finfo(np.float16).max):`\\n                    `df[col] = df[col].astype(np.float16)`\\n                `elif (c_min &gt; np.finfo(np.float32).min`\\n                      `and c_max &lt; np.finfo(np.float32).max):`\\n                    `df[col] = df[col].astype(np.float32)`\\n                `else:`\\n                    `df[col] = df[col].astype(np.float64)`\\n\\n    `end_mem = df.memory_usage().sum() / 1024**2`\\n    `reduction = (start_mem - end_mem) / start_mem`\\n\\n    `msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'`\\n    `if verbose:`\\n        `print(msg)`\\n\\n    `return df`\", '（あれ、うまく貼れない、みんなどうやってコード貼ってるの焦）', \"こうかな?\\n```def reduce_mem_usage(df: pd.DataFrame,\\n                     verbose: bool = True) -&gt; pd.DataFrame:\\n    \\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\\n    start_mem = df.memory_usage().sum() / 1024**2\\n\\n    for col in df.columns:\\n        col_type = df[col].dtypes\\n\\n        if col_type in numerics:\\n            c_min = df[col].min()\\n            c_max = df[col].max()\\n\\n            if str(col_type)[:3] == 'int':\\n\\n                if (c_min &gt; np.iinfo(np.int32).min\\n                      and c_max &lt; np.iinfo(np.int32).max):\\n                    df[col] = df[col].astype(np.int32)\\n                elif (c_min &gt; np.iinfo(np.int64).min\\n                      and c_max &lt; np.iinfo(np.int64).max):\\n                    df[col] = df[col].astype(np.int64)\\n            else:\\n                if (c_min &gt; np.finfo(np.float16).min\\n                        and c_max &lt; np.finfo(np.float16).max):\\n                    df[col] = df[col].astype(np.float16)\\n                elif (c_min &gt; np.finfo(np.float32).min\\n                      and c_max &lt; np.finfo(np.float32).max):\\n                    df[col] = df[col].astype(np.float32)\\n                else:\\n                    df[col] = df[col].astype(np.float64)\\n\\n    end_mem = df.memory_usage().sum() / 1024**2\\n    reduction = (start_mem - end_mem) / start_mem\\n\\n    msg = f'Mem. usage decreased to {end_mem:5.2f} MB ({reduction * 100:.1f} % reduction)'\\n    if verbose:\\n        print(msg)\\n\\n    return df```\", 'この記号 ` を3つでできた！', 'そうです！！！Markdown記法なんですね！笑\\n編集タブに「コード」があったのでこれを使用してみたのですが、、ありがとうございます！！\\nHello hello hell', 'ありがとうございます！\\nデータ型変換もやっているのですが、それでもきついんですよね...笑', '私はあんまりKaggleはやってないので参考にならないかもしれないんですけど、\\n実務ででかいデータをpythonで処理した時は\\n1.↑みたいにデータ型を軽いのにする\\n2.メモリがでかい演算は代替手段を考える\\n3.例えば pandas の chunksize 的なもので少しずつ読んで少しずつ前処理する\\n4.諦めてスワップ空間使う\\nみたいなことを気をつけて地道にやってました。\\nすでに使ってるかもですが、jupyter notebookの拡張ツールで生きている変数のメモリサイズを表示できる機能があったのでそういうのはよく使ってましたね。\\nただ、大前提で出来るだけSQLで前処理するように心がけてました。', 'メモリの扱いについてはみんなのやり方をぜひシェアして欲しいですよね。', '上位のNNモデルなんかは有料のGPU使って進めたりもするらしいですからね、、データセットが大きいコンペには参加しないようにしてます笑\\n\\nみなさんのメモリ周りは是非に聞きたいですね！', '自分は、学習がクソ重い感じの処理はあんまやったことないんですよね・・・\\n\\nkaggleみたいなコンマ数％の精度の差を競う場合はあれですが、特徴量を減らしてシンプルにするというのは結構有効かと思います。', 'げ〜やっぱ札束で殴る感じなんですね....', '最近やった比較的重いのはDataRobotとかだったので、バックエンドで放置しておけば複数モデルを勝手に作ってくれましたねｗ', 'DataRobot...やはり札束が必要なのか...', '実践的には、札束で殴るが有効ですねｗ', 'メモリ周りってお金かかるんですよね、、16GBにすればよかったと思いつつ8GBが予算的には、、っていう葛藤です笑\\n特徴量削れるなら削りたいですね！', 'あとは、最近だとBigQueryでデータ作ってAutoMLとかも試してみたいですね～！\\n\\n完全に富豪プログラミングですが、世の中の潮流的にブラックボックスでよしなにやってくれる世界になると思うので、メモリ削減系のスキルは捨ててますね・・・', '&gt; 特徴量削れるなら削りたいですね！\\n実務では減らしても差し支えのない特徴量でも、kaggleだとダメージでかそうｗ', '昔の低スぺ時代のアプローチだと\\n\\n・サンプリングして効いてる特徴量を見つける\\n・ある程度使うモデルと特徴量決める\\n・特徴量を減らす\\n\\nみたいな感じでやることが多かったですかね？\\u3000全部の変数を思考停止して入れるみたいなことをやらずに、小さく回して効果が出そうな所に当たりをつけていくなどが結構メモリ効率は良いかなと。', 'kaggleでみんながやっているメモリ削減をすでにやっているということは、notebook上でできる工夫はもうやりつくしてるんじゃないかと思います。\\nそれでも足りないのであれば単純にデータサイズが大きいのだと思うので、GCPとかうまく使うしかないかなと。\\n友人は停止し忘れでけっこうな請求来て落ち込んでましたw', '効いてる特徴量探すのがすごい大切ですけどすごくつまらない部分でもあるんですよね、、笑\\nバリデーションスコアが信用できるなら、全パターンセットして放置で数日かけて全特徴量全組み合わせを試せたらいいんですけど、、笑', 'もしかしたらご存知かもしれませんが，\\nいわゆる，out-of-coreで処理ができる，\\nDaskやVaexといったライブラリを使用すると大幅なメモリ削減になるかもしれません！\\n\\n僕は，ノートPCで大きいデータを扱いたい場合は，Daskで解析をしています！\\nただし，特有の処理が必要になってきたりして結構めんどくさいです．\\n\\n今回のkaggleコンペにいたっては，out of memoryになった瞬間にAmazonでメモリをポチって\\n16GB-&gt;32GBに増設しましたが笑', '<@UTP46GURL> \\nこれですかね？知らなかったです使ったことなかったです、！！！もうちと調べてみます！\\n<https://dask.org|https://dask.org>', '<@UT5FYCM6D>\\nそうですね！\\n難点として，Documentが充実している分，\\n日本語の情報が少なかったりとかしますが，結構pandasライクに使えると思います！\\n調べると一番上ぐらいにでてくるqiitaの記事とかですが，こちらもわかりやすいです！\\n<https://qiita.com/kodai_sudo/items/c2ff1e85da18eaf13b65>\\n\\nvaexに関しては，比較的新しくて，情報が少なそうだったので使うのをやめましたが，\\n<https://blog.ikedaosushi.com/entry/2019/04/14/173307>\\nこのサイトの記事がわかりやすかったです！')\n",
      "('はやと-復学しました',)\n",
      "('Kanai', 'Satoshi ｻﾄｼ')\n",
      "('BQ',)\n",
      "('google colabで実行環境をある環境に揃えたいんですけど１日後に開いたりするとすぐ元のバージョンに戻っちゃっているんですけど調べても見つからなくて、何かバージョンを固定するいい方法知っている方いませんか？',)\n",
      "('<@UKT5BQD3P>\\n回避策となるかわからず、かつColaboratoryではやったことないのですが、`pip freeze` で現環境をreqirements.txtに出力して、再度使うときに`pip install -r` で読みこむとかどうでしょうか？', '具体的には\\n1. `!pip freeze &gt; requirements.txt` で出力\\n2. 「1.」をダウンロードしておく\\n3. 再度使うときに「2.」をアップロード\\n4. `!pip install -r requirements.txt` で読み込んでインストール', '金井さんありがとうございます！\\n再度読み込むときにpipコマンドを打たずにやりたいっていう感じなんですよね、、、', 'なるほど、毎回pipコマンド実行してたら面倒ですもんね。。。すみません、その方法はわからないです…', '確かそれ同僚も腐心していて結局無理だった記憶があります。、2ヶ月前の話ですが', '<@US85V53MK> \\nそうなんですね、、、諦めるしか無さそうです、ありがとうございます:sob:')\n",
      "('Takuma Yoshioka あっと ﾊﾞﾝｺｸ',)\n",
      "('増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('クラウド', 'データサイエンティスト', '機械学習', '転職', '統計')\n",
      "('キャリア/スキル選択について皆様の意見・経験を伺いたいのですが、\\n・皆様ご存知のようにデータサイエンティストには幅広いスキルセットが求められています（例：機械学習/統計/数学/プログラミング/システム開発/クラウド/各領域のドメイン知識 等々…）\\n・しかし１人の人間ですべてを完全にマスターすることは不可能で、自分の武器をいくつかを選択することを迫られているのではないかと\\n・その場合に自分の磨くべき武器をどのように選択して行くのが良いと思われますか？または、どのように選択されてきましたか？（例：なりゆき/環境/もともとの業務内容/興味/得意分野/必要だと信じて）\\n\\n自分には必要なスキルだと思って、エンジニア職から非エンジニア職に転職したものの、この選択で良かったのだろうかという感覚が取れずにいて、、、',)\n",
      "('好き嫌いでいいんじゃないですかね。\\n結局、ほぼ永遠の学習が必要なので', 'ありがとうございます！たしかに、そうやって割り切って考えてしまうのも方法ですね', '自分の場合だと、\\n\\n高校：情報科でプログラミングの基礎を学ぶ\\n大学：理工学部で情報系の勉強と、必要な数学周りを学ぶ\\n分析受託会社：データサイエンスの基礎を2年程度\\nスタートアップ：Webエンジニアとして開発を2年程度\\n分析受託会社：客先常駐でPM、コンサルを2年程度\\n\\nというキャリアで進んで来ましたが、まだまだ足りないこともいっぱいあるなぁという感じですね。\\n\\nただ、全体的に6割程度をカバーしているのと、比較的キャッチアップ速度は速いのとで、結構小回りが利いて重宝されるような印象があります。\\n\\n目指すべき方向性としては、2～3のスキルで実務レベルに達する必要があるのかなぁと思います。\\n\\nエンジニア×ビジネスというスキルができるのであれば、\\n\\n・データサイエンス×エンジニアリング\\n・データサイエンス×ビジネス\\n\\nといったスキルを持ったメンバーとチームを組めば比較的プロジェクトは円滑に進むと思います（共通言語を持っているため）\\n\\nなので、複数スキルの習得は必要なのかと思いますが、\\n\\n・市場の人材状況\\n・どんな人材のチーム構成が今後考えられるか\\n\\nという所を意識しながらやって行く必要があるのかなと思います。幅広い知識が必要ではありますが、経験年数が長い方も増えて来るので、一定数、「全領域カバーしている」という人が出てきて、そうっいった方がPMとしてバランスを取りながら進めて行くんだろうなぁというのが自分の読みですね。（自分がそこを目指しています。）', '例えば、この前お話に上がったオペレーションズリサーチなどであれば、\\n\\n• 組み合わせ最適化問題、線形計画問題、凸計画問題、非凸計画問題などの種類がある\\n• 凸計画問題までは解析的に解くことができる\\n• 解放には、線形計画法などの理論的解を求めるアプローチと、メタヒューリスティクスなアプローチがある\\n• 計算量との闘いが結構しんどい\\n• 非凸計画問題は現実的に解くことは非常に難しい\\nなどの情報を知っていれば、分析プロジェクトをやる上で適切な方に適切な質問をしつつ、しっかりとプロジェクト推進をできるのかなぁと思います。\\n\\n実際にプロジェクト開始したら、6割程度の理解なので大体大変な思いをしますが、完全に地雷を踏み抜くということはかなり少なくなりますね。\\n\\nなので、挙げて頂いたような領域に関して、全部とは言わないまでも半分くらいの領域で6割程度の理解を目指すと良いのかなぁというのが、個人的な見解ですね。', 'これまでお話した内容をもとにありがとうございます！確かに知っている人とは共通言語として会話ができ、知らない人とは地雷を踏まない程度にリードできるのが6割というラインなのかもしれないですね。後は、その場その場でのチーム構成によっても自分の役割が変わってくるでしょうし、ある程度は戦略的に蓄えながらも、臨機応変に得られる経験を得ていくことを地道に続けていくことが結果的に近道なのだと理解しました！\\n\\n皆様のおかげで少しもやもやした感じがスッキリしました、ありがとうございます！', '方向性少し見えたようで良かったです！世の中の状況か刻々と変わっていくので、都度方向性見直せると良いですよね～！')\n",
      "('吉村政彦ｰ産業ｽﾊﾟｲ',)\n",
      "('Takuma Yoshioka あっと ﾊﾞﾝｺｸ',)\n",
      "('データサイエンティスト', '統計')\n",
      "('<@U010Y77JA2W> さん\\n\\n\\n「しかし１人の人間ですべてを完全にマスターすることは不可能で」\\n\\n完全では無いにせよ、7〜8割がたはマスターしてるからデータサイエンティストは報酬が高額なのではないですかね？\\n\\n私も未だ学習中の身ですが、全部必要だと思っているので全部勉強してます。\\n\\n一度に全部それなりにってのは絶対モノに成りませんから、非力な者は非力成りの戦略＝得意なものから一つづつやっつけて行くしか、戦略は無いと思います。\\n\\n私の場合は、野良ストラテジストだったので、ギルドの皆とは真逆のアプローチ＝データサイエンティストに仕事を振る立場の資格を先に取得しましたが、それは自分のスキルを考慮して「最短で最大の効果を狙った結果」です。なのでコンサルの仕事をメインとしても、自分でも環境を含めたモデル構築まで出来る様に成るつもりで、今月から統計教室に通っています。\\n\\n高額報酬にはちゃんと理由があります。効率の良い方法はありますが、近道は無いと思います。',)\n",
      "('「完全では無いにせよ、7〜8割がたはマスターしてるからデータサイエンティストは報酬が高額なのではないですかね？」\\nなるほど、たしかに非常に納得できました。ありがとうございます！\\n\\nやはり永久に学び続けることは共通していて、自分にあったプロセスを見つけて、それを確実に実践できるか、という点に集約されるということだと認識しました。',)\n",
      "('永田ゆかり Yukari Nagata',)\n",
      "('しみずこうじ', '増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', 'Hiroyuki.Tachikawa', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '吉村政彦ｰ産業ｽﾊﾟｲ', 'Takuma Yoshioka あっと ﾊﾞﾝｺｸ', 'はやと-復学しました', 'ﾋﾛﾘｰ hirory')\n",
      "('BQ', 'Tableau')\n",
      "('質問させていただきます。\\n香港からの講演依頼があり、このWEBサイトの内容を話そうかと思っており、これをざっくりでいいので翻訳したいのですが、みなさんはこのような場合、どのようなツールや方法を使っていらっしゃいますでしょうか？\\n<https://data-viz-lab.com/data-utilization-strategy>',)\n",
      "('講演のための訳はやったことなくて恐縮ですが:sweat_drops:\\n王道ですが、Google翻訳でしょうか・・・', 'なるほど、やはりそうですよね！\\nGoogle翻訳も、以前よりだいぶ精度あがったみたいですしね。\\nコメント、どうもありがとうございます:smiley:', '翻訳とは関係ないのですが、ちょうど社内のデータ民主化プロジェクト推進なので参考にさせていただきます。', '<https://www.deepl.com/ja/translator>\\n結構いいらしいですが使ったことないので、もし使ったら感想教えてくださ〜い\\n使った雰囲気は以下\\n<https://twitter.com/search?q=%23DeepL&amp;src=typeahead_click>', '<@UKT5BQD3P> さんが中国語行けるはずなので、翻訳がどの程度妥当かの感覚はつかめるかもしれないですね！！', '今ならGoogle翻訳よりDeepLでしょうねぇ・・・。', 'DeepLだと張り付けるのが手間かな・・・と思いましたがどうなんでしょｗ', '手間より精度の法が重要なのでは？(^_^；', '日英は良い感じっぽいですが、アウトプットは香港なので中国語ですかね？', '翻訳における精度の評価指標を知りたくなってきましたｗ', '量と精度のバランスな気がしてきましたｗ', '講演するのは永田さん＝永田さんの顔に泥を塗らない事が最優先かと。\\n\\nコピペが云々という事であれば、社員も抱えていらっしゃる様ですし、「この程度のボリュームなら、手分けすれば小一時間」だと思いました。', 'コピペレベルなら精度優先でしょうねｗ', 'ざっくり翻訳して、それを私がチェック・確認するので、いずにれしろ最後は自分のステップが入るのですが、最初のざっくりだけでもある程度の精度で何かでできたらなあ、というところでした。', 'であれば、DeepLが良さそうな気がしますね！', 'みなさん色々教えてくださり、どうもありがとうございます！', 'てか誰も言及しないけど、香港から講演依頼ってどういうチャネルなんですか？すごいっすね。', '自分が以前にイギリスからインタビューを受けたこちらの記事を、Linkedinで見つけてくれた元PwC香港の人がいまして、その人が香港のTableauユーザー会のリーダーをしていたんですよね。私は日本のユーザー会の会長なので、昨年ラスベガスでのカンファレンスがあったときに会いたいといわれて、ラスベガスでも会いました。\\n来月は別件でインド人からの依頼の講演ですw\\n\\n<https://tableaumagic.com/s1e6-a-conversation-with-yukari-nagata/>', 'あとはこの動画ですねw\\u3000ちょっと恥ずかしいですが・・笑\\u3000これはUKから、ジャパンの活動を教えろと依頼されて作りました。\\n<https://www.youtube.com/watch?v=Ma0eUv_UyHA&amp;feature=emb_logo>', 'すげ〜。あざます。ちょっと調べましたが、TablueauのUGって結構規模でかいんですね。恥ずかしながら知りませんでした。そしてとりあえずYouTubeは高評価しておきましたw', 'ちょうど今日たまたまですが、DeepLの評判を聞きつけて、日→英についてGoogle翻訳と比較しながら使ってみました。まだ少ないケースでしか試せていないので、個人的な感覚での評価で恐縮ですが、\\n・短文だとDeepL（スライドやメモ等イメージ）\\n・長文だとGoogle翻訳（ちゃんとした文章）\\nのほうが精度が良い印象でした。', '機械翻訳について疑問だったのですが、いつからかGoogle翻訳は単語単位での別翻訳の選択肢は選べず、文単位でしか他の選択肢が選べなくなっていると思います。これは技術的には、翻訳を単語単位で行わず・文章の前後を見ながら翻訳しているから単語ごとに変えられなくなったという認識であっているのでしょうか？\\n\\nちなみに、DeepLは単語単位で別の選択肢を選ぶことができました。', '<@UJRAL005U>\\n\\n僕は英検で言うと2級マイナスくらいの実力\\nなんでふんわりとした意味は理解できますがそこまで当てにならないです笑笑', '&gt; DeepLは単語単位で別の選択肢\\nこれは知らなかった！手を加える時に便利ですね〜\\n\\ndeeplの翻訳好きだから、ブラウザ拡張でグーグル翻訳みたいなのgが出てきて欲しいなぁ', '<@UREUHGVAQ> さん、先日はDeepLを教えてくださり、ありがとうございました！めちゃくちゃ精度よくて世の中はここまできたのかと驚いております。こなれている感がすごいですね。\\n文章を刻んで秘書の子に作業してもらいました。\\n自分がレビューするのがためらうくらいです。こういう表現って自分は知らないけどあるのかな。。。と自信がなくなり、DeepLに自分が英語を教えてもらっているくらいです。笑', '<@UUMB12SGZ> アイコンが！！！変わりましたか？？？\\nすごい良いですね！自分で書いたんですか？\\nDeepL評判通りでしたか。感想ありがとうございます。私は外国語は全然わからないので評価しようがなかったんですが、使ってみようかな', 'アイコン変えました！笑\\u3000以前グラレコデザイナーの方が入った講演で講演したんですが、その時グラレコボードに描いてくださった私です！ありがたいことに少し盛って下さってます。アイス食べ過ぎて太って顔が変わってきたので、これならいくら太っても大丈夫かなと思ってます。', 'これから暖かくなるのでいいタイミングでしたね！')\n",
      "('ﾔｴﾘ_営業ｱｯﾌﾟﾃﾞｰﾄ',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'K')\n",
      "('前処理', 'Git')\n",
      "('モデルの版管理について質問させて下さい。\\n\\nある教師データにについて、\\n\\n・仮説1のために、前処理＆モデリング\\n・仮説2のために、前処理＆モデリング\\n・仮説3のために、前処理＆モデリング\\n\\n・・・\\n\\nと順に実証を行っていく中で、ふと「過去に行った仮説2をforkしたい」という際、皆さんはどのようにされていますでしょうか？\\n\\n私はExcelでindexを作り管理しているのですが（過去データのforkの際はそれを参照するのですが）、もっとスマートな方法があれば・・・と思い。\\n\\n※意味が伝わっているか自信がありませんが・・どうぞよろしくお願い致します。',)\n",
      "('それぞれが独立の分析ではなく、\\n\\n・大元のデータセットは同じ\\n・仮説2を深堀して別の分析に応用したい\\n・仮説1、仮説3と被る部分もある\\n\\nといった感じなのでしょうか？\\u3000独立していない部分があるからこそ、何か問題が起こるのかなと思いまして。', 'Gitとはまた違うんですかね？', '<@UJRAL005U> さん、<@UT5FYCM6D> さん、ありがとうございます！\\n\\n・・・申し訳ございません、一旦質問を取り下げさせてください。\\n※私の業務というか、弊社業務特有の部分があり、もう少し整理してから再度質問させて頂きます:man-bowing:', '承知しました！お待ちしてます♪\\n\\n業務内容を抽象化して質問するの難しいですよねｗ')\n",
      "('masso',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'K')\n",
      "('統計', '入門', 'PRML', 'ML', '書籍')\n",
      "('質問させてください。\\n\\n以下のような書籍を探しています、お心当たりありましたら教えていただきたいです🥺\\n\\n・高校数学、大学初等数学(線形代数、確率論、統計学、微積)が分かってる読者を対象としている※\\n・データ分析の手法を広い範囲で扱っている、理論的な解説本\\n・参考ソースやダウンロード可能なサンプルがあればなお良い\\n\\n※「高校数学の解説ゼロ、大学初等数学の解説少し」ぐらいの温度感',)\n",
      "('PRMLとかですかね？\\n\\n難しすぎます？', '物理出身の人からすると結構読みやすいとの話です', 'やはりPRMLはおススメなんですね。\\n\\n&gt; 物理出身の人からすると結構読みやすいとの話です\\nそれは出来る物理出身者かとｗ\\n私の場合は、「かなり集中したら、ギリ読める」ぐらいなので、ハードルが高いことは確かです。ですが、頑張って読んでみようと思います。', 'あとは、データ解析のための統計モデリング入門とかですかね', 'いわゆる緑本', '分類問題だとはじパタなど？', '「データ解析のための統計モデリング入門」\\n「はじパタ」承知しました。\\n買います！', '統計モデリング入門、は今読んでますがボクもおすすめします！\\nただ、データ分析ってやりたい範囲絞らないと結局薄く広い情報になっちゃう(統計学入門のように)ので、一単元ごとに絞る方がいいかなってボクは思います(数式が欲しい場合ですね、実用特化で使い方知りたいのであれば薄く広くで十分かなって)', 'はじぱたは輪読書籍になってますよ！\\n<#CT1S314AG|07-13-輪読会-初級> ')\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('ちょっと話が来たのですが、Androidの開発ができる方とかっていますか？？',)\n",
      "()\n",
      "('shinji',)\n",
      "()\n",
      "()\n",
      "('技術書の翻訳本の出版について質問させて頂きます。\\n\\n今年(2020年)の終わり頃に出版予定の技術書(英語)があり、\\n個人的に気になっているトピックなので、翻訳本に関われないかと思っています。\\nこういう場合、どこ(誰？)にアプローチするのが適切かご存知でしたら教えていただけないでしょうか。\\n著者と出版社はわかっている状態です。\\nただ、翻訳本は原著と同じ出版社とは限らないので、どういうルートが有るのか選択肢を検討したい次第です。',)\n",
      "()\n",
      "('永田ゆかり Yukari Nagata',)\n",
      "()\n",
      "()\n",
      "('基本的に個人指名で依頼が来るのが大半かと思います。私は現在イギリスから来ており、ちょうどはなしているところでした。\\n（もう翻訳本がでるのは前提で、）原著の著者などど知人友人でしたら個人に連絡がくるものと思いますが、著者出版社がわかっている状態でしたら、翻訳本つくりたいからやらせてほしいと連絡・営業するのもありかもしれません。',)\n",
      "()\n",
      "('shinji',)\n",
      "()\n",
      "()\n",
      "('ありがとうございます。\\n出版社の方に一度連絡を取ってみます。',)\n",
      "()\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "()\n",
      "()\n",
      "('<@URVQKNPDH> さんも翻訳される側だったかと思いますが、どういう形で翻訳プロジェクトが開始されたのでしょう？？',)\n",
      "()\n",
      "('なないち',)\n",
      "('Katsuya Nagano', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', '戸嶋\\u3000龍哉')\n",
      "('データサイエンティスト', 'kaggle', 'Python', '可視化', '機械学習', 'PDCA', 'マーケティング', '画像処理', 'ML', 'AI', '統計')\n",
      "('質問です。\\n\\n現在大学4年生です。\\n大学院に進学しようと頑張っています。\\n\\n質問の内容は機械学習やデータサイエンティストを夢見てますが具体的に何からすればいいかわかりません。\\n\\n私のスペックに合わせて解答してくださるとありがたいです。\\n\\n私のスペック\\n(1)線形代数や微積の知識はあります。\\n(2)統計学の知識はあります。(ロジスティック回帰などはわかります。)\\n(3)C言語は大学でやっていたのでfor文やif文はわかります。',)\n",
      "('はじめまして。\\n実務を積みながらそのとき必要なものを都度学習が一番効率が良いんじゃないかなと思います。\\n研究室にもよりますが、学生ならば多少時間があると思うので理論とかちゃんと勉強しやすいですし。\\n肝心の実務は、ギルドの<#CJT6G95EJ|10-1-募集> でインターンしたり、kaggleやってみるとかですかね。\\nkaggleは<#CQMLJ4H2L|07-11-kaggle>\\n\\nデータサイエンス系だとPythonとRでやることが多く、人のコードを読んだり共有することを考えるとどちらか(機械学習だとPythonかな？)は基礎くらいは先に学んだ方がよいと思うのでpaizaとかで学んどくって感じでしょうか。\\n\\nPython含む、勉強系は<@UJRAL005U> さんがnoteにあげてたやつとか参考にするとよさそう\\n\\n<https://note.com/green_midori/n/n6bed07efe1bb|https://note.com/green_midori/n/n6bed07efe1bb>', '恐らくですが、「データサイエンティスト」像を明確にするのが第一歩かなと思います！\\n\\nデータサイエンティストと言っても色んな方向性があるので、過去ログでどんなディスカッションがされているのかを見てみると参考になるかと思います♪\\n\\n理論、数学寄り、ビジネス寄り、エンジニア寄りなど色々と役割がありますので、どんなデータサイエンティストになりたいかが明確になればそれに伴ってやるべきことも明確になって来るのかなと。', '返信ありがとうございます。\\n私はボードゲームやポーカーが好きなのでAIやCPUを自分で開発をするのも興味があります。\\n\\nまた、マーケティングやデータ分析に関するインターンもやったことがあり、こちらも興味があります。\\n\\n現在はライターのインターンをやっていますが、頃合いをみてデータサイエンティストのインターンに参加してみるのもいいと思っています。', 'とりあえず募集をみて、興味があるものに関して担当者にDMをしました。', '&gt; データサイエンティストのインターンに参加してみるのもいいと思っています。\\nこの方向性は良いかなと思いますね！\\n\\nお話を聞いた感じだと、恐らくデータサイエンティストに必要な技術としては既に最低限持っていると思うので、データサイエンティストに何が求められているのかを知るのが良いかと！\\n\\nその方法として、インターンを受けられるならインターンは選択肢として良さそうです。あとは、データサイエンティストの方が参加するイベントに参加したりして、現場の生の声を聞くのも良さそうです。\\n\\n今ならオンラインで参加できるものも多いので、connpassで探したりしてみて、色々参加してみてはいかがでしょうか？', '<@U011MBS7Y7P> 実践的で将来やくに立つのは、身の回りのデータを自分で集めて、分析、可視化までして生活レベルでなにか実践してみる、とかがおすすめです。個人レベルでも実際に PDCA ガンガン回す練習しておくと習慣化しますし、現実世界のぐちゃぐちゃなデータに対する耐性、データベースやWebアプリ開発などの付随するスキルも色々身につきますよ。\\n\\n例えば\\n(1) Twitter で趣味に関係しているような情報をテキスト処理や画像処理などをおこなって手自動抽出、DBに蓄積、Webのツール化して生活に活かす\\n(2) 携帯やAppleWatchなどで自分の生活のログを取り、自分にとって役立つ情報を抽出する。\\n(3) 家計簿データをちゃんとつけて、分析し、節約＆効率の良いお金の消費をする', '最近だとコロナ関連であれこれプロの方がデータを集めて可視化しているので、真似してみるところからやるのもおすすめです')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('はやと-復学しました',)\n",
      "('chan', '戸嶋\\u3000龍哉')\n",
      "('OpenCV', 'Python', '前処理')\n",
      "('opencvについて質問です。\\n職場で顔写真判定をrailsに埋め込むためにrubyでopencvを使用したいのですが、その内容が、どのような精度かをpythonで検討しようと思っています。調べても出てこなかったので、pythonとrubyでopencvの動きの内容自体に違いがないかどうか知りたいのですが、知っている方は教えてもらえると嬉しいです。',)\n",
      "('Pythonで精度など検討してrubyで実装しようとしてるけど、そのふたつが同じ動作するかどうか確認したいってことでしょうか？\\nrubyのOpenCVは使ったことがないですが、大事なのは顔検出モデルと思います。同じモデルを使っていれば同じ精度になるはずです。', '<@US2HKDVSL> さん、そういうことです！\\nってことはpythonもrubyも同じものと考えて大丈夫でしょうか？', '同じ学習済みモデルを使っていれば精度は同じはずです。\\nどんな言語であれ、顔検出については縦*横*RGB3チャネルのデータにしてモデルに入力するだけなのでそこの結果は変わらないはずです。\\n言語によって処理速度や使いやすさ？とかは変わる部分はあるかもしれません！', 'OpenCV側の出力には差はないですね。\\n\\n前処理部分で言語側の速度差とかは出る可能性ありますが（Python と C++ を比較するとループ処理などは少なくとも実行時間一桁程度は変わるとか）\\n同じスクリプト系言語の2つだとそこまでおおきく変わらないかと思います。', '<@US2HKDVSL> \\nOpencvってモデル使ってるんですね、、、知らなかったです、回答ありがとうございます！', '<@UUAUDBR1N> \\nそんな実行速度2つだと違うんですね、、、\\n出力差がなくて安心です、ありがとうございます！', 'いえいえ〜、うまく実装できて満足行く精度がでるといいですね〜。')\n",
      "('chan',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('AWS', 'Python', 'Redshift', '可視化', '初心者')\n",
      "('AWSのデータ分析基盤についてご質問です。\\n\\nシステムからAWS RDSへ1回/日の頻度でデータが更新されます。\\nデータの形としては下記のような構成で、各観測点におけるデータが横持ちになっているイメージです。\\n```（例のためのダミーデータです）\\n場所, 年月日, 0時, 1時, 2時, …, 23時 \\n東京, 2020-04-01, 0, 1, 2, …, 1\\n大阪, 2020-04-01, 0, 3, 2, …, 3\\n福岡, 2020-04-01, 1, 2, 4, …, 4\\n東京, 2020-04-02, 0, 1, 1, …, 2\\n大阪, 2020-04-02, 1, 1, 1, …, 3\\n福岡, 2020-04-02, 1, 6, 4, …, 9```\\nデータは毎日数ギガ単位で追加されます。\\n分析は毎日頻繁にやるというより、要望に応じて可視化したり、まとめて出力したりで頻度はあまり高くないです。\\nやりたいこととしては、データが追加されると整然データに加工し、分析用として別テーブルデータとして保存するということです。\\n\\n&lt;質問&gt;分析するサービスとパイプラインについて\\nコスト的に、整形したcsvをS3にためていって、Athenaで分析するのがいいかなと考えました。\\nその際、整然データへ加工するにはAWS glueを使うのか？（DataPipelineのほうがいいのか？使ったことなくあまり理解できてません:sweat: ）\\nそれともまずはRDSの構造のまま丸ごとエクスポートして、エクスポート先で縦持ちへ変換するほうがよいのか？\\n\\nはたまたこの場合は別のこのサービス使えばよい、などのアドバイスがありましたらお聞きしたいです。\\n当方、Bqを使ったことある程度で、データ基盤系のマネージドサービスは初心者です。\\nよろしくお願いします。',)\n",
      "('・アドホックな分析などで頻繁に集計をする\\n→Redshift\\n\\n・日次バッチなで定型の処理を走らせる\\n→Athena\\n\\n今は改善してるかもですが、Athenaが出始めの頃は機能が結構限定的だったので、複雑な集計しようと思うとRedshiftを使わざるを得ないという感じでしょうか。\\n\\n結構環境依存なところもありますが、以下のような形で立て持ち横持ち変換なども可能ではあるので、上記のレベルのデータであれば、ETLの処理もデータベースに持たせちゃうというのもありかなと思います。\\n\\n<https://dev.classmethod.jp/articles/sql-data-horizontal-vertical/>\\n\\nglueを使ったことがなく知見が無いのですが、\\n\\n・やれることをやれるか？（使ってみると必要な機能が抜けてることは結構あるのでｗ）\\n・初期の実装コストはどの程度か？\\n・マネジメントコストはどの程度かかりそうか？\\n\\nという感じで比較検証してみるのが良いのかなというイメージですね。\\n\\nパッと見た感じだと、AWS Glueめちゃくちゃ良さそうですね！！ Pythonコード発行されて、それを元にコーディング自体もできるって感じなのですかね？', '想定しているアーキテクチャのアーキテクト図とかがあると、フィードバックしやすくなるような気がします！', '長々とした質問でしたがアドバイスありがとうございます。（アイコンが変わっていて一瞬どなたかわからなかったです）\\n&gt; ・アドホックな分析などで頻繁に集計をする\\n&gt; →Redshift\\n&gt; ・日次バッチなで定型の処理を走らせる\\n&gt; →Athena\\n頻繁ではない、かつGroupbyするぐらいなので私はAthenaがよいかなと考えてました！\\n\\n&gt; 上記のレベルのデータであれば、ETLの処理もデータベースに持たせちゃうというのもありかなと思います。\\nそうですよね、これくらいならデータベースで作ってもいいかなとも思ってました。\\n\\n&gt; パッと見た感じだと、AWS Glueめちゃくちゃ良さそうですね！！ Pythonコード発行されて、それを元にコーディング自体もできるって感じなのですかね？\\n私も気になっていて使ってみたいなとの思いで触ってみました。\\nRDS -&gt; データカタログ -&gt; スキーマ加工してS3へParquert保存 -&gt; Athena分析\\nまでは設定できました。加工するところでPythonも挟めるので割と自由に加工できて便利そうではあります。\\nなぜかジョブが失敗したりと躓く部分もあって初期の学習が必要なのが難点です。\\n\\n今回は切迫した状況でもないので上記の方法でやってみます。\\n無理だったらS3エクスポートしてAthenaで加工します。\\nありがとうございます。', 'Glueの使用所感とか教えて頂けると嬉しいです！')\n",
      "('Satoshi ｻﾄｼ',)\n",
      "('masso',)\n",
      "('GCP', 'AWS', 'ML', 'BQ')\n",
      "('すっごい素人の質問で申し訳なさすぎてどのくらい申し訳ないかというと無視してしまって構わないのですが、今から取るならGCP資格とAWS資格どちらのほうが良いと思われますか？\\n\\n実務でAWSは使用しているのですが、BQとMLの親和性高いGCPに興味津々です。',)\n",
      "('GCPとAWS迷いますよねー、わかります！\\n「どちらの方が良い」かは\\n何を目的に資格取得したいか、に尽きると思うのですが、どういった目的なんでしょーか？', 'うーん、AWSの他にGCPってどうなん？って聴かれることが多いのと、MLとBQとの親和性が高いという認識があるからですかね。また将来性も勝手ながらAWSよりはあるのかなとおもっております。\\n（これは妄想です）', 'サトシさんの話をまとめると……\\n\\nよく質問される→AWS, GCP\\nMLとの親和性→GCP\\n将来性→GCP(と思う)\\n\\nって感じだと思うんですが\\n多数決でGCPでいいんじゃないですか？笑')\n",
      "('尾銭泰徳 ﾃﾞｰﾀｻｲｴﾝｽ勉強中',)\n",
      "('増田貴志.大学院で考えるﾋﾞｯｸﾃﾞｰﾀﾏﾈｼﾞﾒﾝﾄ', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "('可視化', 'GCP')\n",
      "('GCPのデータポータルで可視化した集計結果をサイトに埋め込みたいのですが、集計結果のクエリを動的に制御ってできるものでしょうか。\\n\\nこちらのデモページ検証して、フィルタ条件程度はURLで指定できそうだったのですが、エンコーディングされてるせいで、スクリプトとかでwhere句が設定できない。。。\\n`<https://datastudio.google.com/embed/reporting/1ZstfLOwJIm3nbp_h9LYubIDi8euhjVZZ/page/iGbMB>`',)\n",
      "('外部表示ってあまりやったことがないのですが、基本的にクエリ埋め込めてデータベースに定期的に実行かける仕組みです。\\n12時間ごと、６時間ごと4時間ごとあたりで設定できたはず。', 'レスありがとうございます！\\n定期実行というより、where句のユーザIDを外部から操作したいという感じです。\\n\\nデータポータルのレポートをユーザーごとのページに埋め込んで分析結果を表示したいのですが、全ユーザー分のレポートを用意するのが厳しいので、ユーザID渡すとそのユーザのレポートに切り替わる感じにしたく、、', 'こちら解決しました！以下の記事のように定義したパラメータを外部からいじれるようにしたらできるみたいです。\\n<https://developers.google.com/datastudio/connector/data-source-parameters?hl=ja>\\n引き渡すパラメータは以下のコードみたいにJSONをエンコーディングしてURLに追加してやればOK\\n```var params = {\"ds0.fullVisitorId\": \"5517402221903589894\"};\\nvar paramsAsString = JSON.stringify(params);\\nvar encodedParams = encodeURIComponent(paramsAsString);```\\nこれでいろんな画面にデータポータル埋め込んでデータ可視化画面作る工数削減できるぜ！', 'この使い方知らなかったので、助かります！！\\n\\nこのやり方ができるなら、ユーザーのプロフィールページに発言数のグラフ埋め込むとかもできるようになる感じなのですかね？', 'そうですね！\\nwhere句を外部から自由に設定できるのでユーザ検索プロジェクトにも使えるかもです！', 'それは朗報！！', 'ユーザーページの実装なかなか大変そうなので、パラメータにユーザーIDを渡して、のサマリを表示させるだけのページとか作るのサクッと作ると案外面白そうですかね？', 'そうですね！ほとんどコード書かなくて済むので保守性もピカイチです')\n",
      "('sota_sakuma',)\n",
      "()\n",
      "()\n",
      "('私のリモートワーク環境。\\nノートPC+モバイルモニター\\nVPNで社内にアクセス\\n毎日数件内部、外部打合せがある為、ヘッドセント常備\\n\\n皆さんはどんな感じですか？',)\n",
      "()\n",
      "('なないち',)\n",
      "('K', '村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析')\n",
      "()\n",
      "('質問です。\\n\\nサンプリングによる期待値の近似計算において、以下の式が成立する理由が知りたいです。',)\n",
      "('サイコロを例にして、p(x)=1/6、f(x)=xで、\\n本来の期待値はΣpf\\nサンプリング(数回サイコロを振る)とき、期待値(標本平均)はΣf/L\\nってことかな、、？？母平均と標本平均の関係のような気がします(気がします)', '<@UT5FYCM6D> さんのおっしゃっている通りかなと！\\n\\nサイコロゲームを考えた時（xが1～6）のときに、1～4は負け（0）、5, 6は勝ち（1）として、サンプルを十分に獲得できる状況化では、サンプルを十分に取れれば\\n\\nf(x) = 1/3\\n\\nに収束するとかってことなのではないでしょうか？')\n",
      "('なないち',)\n",
      "()\n",
      "('教科書',)\n",
      "('教科書に書いてあるとはいえ、なぜこの式になるのかが気になります。',)\n",
      "()\n",
      "('K',)\n",
      "('Hiroyuki.Tachikawa',)\n",
      "('教科書',)\n",
      "('単純(?)な数学に躓いたので、知っている方いたらご教授願います(´・ω・｀)\\n\\n線形回帰モデルにおいて、回帰係数(ここではβ1、β2)を導出する際、正規方程式とβ1_hatの導出までは難無く進められるのですが、β2_hatが教科書の記述と一致しません(添付写真中、真ん中付近のβ2:教科書、下のβ2:手計算導出)。\\n簡単な例で回帰係数を算出すると、どちらの式を使用しても正しい(同じ)値が求まるので式自体は間違えておらず、最後の数式変形の問題だと思うのですが、、\\nこちらの教科書の形の式を導出する方法を知っている方がいましたら教えてください。。',)\n",
      "('この式はどちらも、分母が分散で分子が共分散になってます。\\n分散の公式は\\nE[x^2] - E[x]^2\\nなので、これを使うと一致します。\\n共分散は\\nE[xy] - E[x]E[y]\\nとなるのでやはり一致しますね', 'あんまり細かく見れて無いですが、これとかどうでしょう\\n\\n<https://ytake2.github.io/Rsite/_site/lec3.html|https://ytake2.github.io/Rsite/_site/lec3.html>', '<@UREUHGVAQ> \\n回答ありがとうございます！\\nそっかこれCov/Vの形なんですね、、もうそうなると分散導出時のΣ計算の変形を追わない限りは公式として変形した方がよっぽど楽ですね、、\\nありがとうございます！共分散/分散になっていることに全然気が回りませんでした！助かりました！', '因みにですが、多変量の場合は正規方程式で求めますが、式を見てみると同じ構造になってて面白いですよ。', '分散共分散行列ですね！これらを鑑みるとなるほど確かに、単回帰でも分散と共分散が出てくることは納得しますね、、(最初から行列で考えた方が分かりやすかった)\\n\\n重回帰を手計算でやることはさすがにしない(気がする)ですが、すごく参考になりました！ありがとうございます！')\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "('SQL', 'データ加工', '可視化')\n",
      "('SQLから加工プロセスを可視化したものを出力する方法ってどなたかご存知ないですか？\\nイメージとしてはETLにあるようなGUIでのデータ加工プロセスをqueryとして出力するのの逆バージョンみたいな感じです。',)\n",
      "()\n",
      "('usadamasa',)\n",
      "('Hiroyuki.Tachikawa',)\n",
      "()\n",
      "('<@UREUHGVAQ>\\n単純に見たいだけなら <https://gudusoft.com/sqlflow/#/> というwebappがあります。\\nシステムに組み込むなら、\\n<http://www.sqlparser.com/> ↑のバックエンドのやつ(有償)\\n<https://eng.uber.com/queryparser/> (Haskell製)\\n<https://pypi.org/project/sqllineage/> (python製)\\nなどがあります。',)\n",
      "('<@U012GC35KUZ> うわぁ！やばい！まさにこういうのでした！あざます！',)\n",
      "('usadamasa',)\n",
      "()\n",
      "()\n",
      "('googleも出してた。 <https://github.com/google/zetasql>',)\n",
      "()\n",
      "('尾銭泰徳 ﾃﾞｰﾀｻｲｴﾝｽ勉強中',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析', 'Hiroyuki.Tachikawa', 'K', 'chan ﾁｬﾝ', 'sho.kumada')\n",
      "('統計', '正規分布', '統計検定', '入門')\n",
      "('こちらのツイートですがどなたか解説いただけますでしょうか？\\nなぜ1.7%～14.6%になるのか、1.7〜14.6%だったらどういうことが言えるのか\\n<https://twitter.com/philomyu/status/1253222057430540288?s=20>',)\n",
      "('何分布かはパッと出てこないですが、「陽性の真の発生確率」が1.7%～14.6%で、その確率の観測値として出て来るということかと思います。\\n\\nそれだけ揺らぎがあるので、「4/67」という数値を持って多い、少ないという議論をするのはナンセンスということではないでしょうか？', '二項分布の信頼区間だと思います。\\n<https://bellcurve.jp/statistics/course/9122.html>', 'ただ、区間があったからといって何か言及するのはかなりミスリードですね。', '統計学的な所を使ってないと頭から抜けますね・・・\\n\\n割と基礎の部分も抜けつつあるのでヤバい・・・', '私は流石に同じことを何度も教えているので忘れないですが。使わないと忘れますよね。', 'ですね。概念は覚えてるのですが、確率分布系とかは結構忘れちゃってますね。', '<@UQGMHCCJ2>\\n区間があると確かに、検査していない未知の集団は\\n1.7%という小さい値から14.6%という感覚的に多い値まで、広い範囲になるよ。サンプルが少ないから。\\nと言えますが「どの」母集団に対してそう言えるかの方がずっとずっと大事です。', '全然違う値になっちゃうんですけど、何か足りてないですかね:face_with_monocle:', 'えまじっすか', '1.96を2.58にするとどうっすかね', '最初ポアソン分布かなと思ったけどどうなんでしょ(信頼区間の求め方がわからなかった)', '(95%じゃないけど)', '母比率でポワソンはないっすね。パラメータが平均なので。', '2.58ならなりましたね', '99%信頼区間か', 'ですね', 'ん？いやよく見りゃ1.7〜14.6にはなってなかった、、', 'Rで計算しましたが、95%だと\\n0.0165044 ~ 0.1458632', 'になりました。Excelの計算がどっか会ってないのかもです', 'ありゃ、、？？これに則ったんですがどこか近似的になっちゃってるんですかね、', 'あぁ、すません。\\n<https://bellcurve.jp/statistics/course/9490.html>\\nこっちでした。\\n私も計算してみます。', 'んん？？？', '違うな。。。', 'やばい。確かに計算合わないっすね。', 'ちょっと後でちゃんと調べて見います', 'ボクももうちょっとちゃんと調べてみます、、どうせ統計学ぶなら確かに発表された数字見てこれくらいはパッと計算できるようになりたいですね、、', 'みなさんありがとうございます！\\n67人中4人というのは6%ぐらいだけど、データ増やしていくと1.7%～14.6%までブレる可能性があるから、なんとも言えないね。って話だったんですかね', 'こういう感じで母集団の推定が活用できるのか。\\n統計学勉強しなきゃなぁ', 'そういうことだと思います！取りうる範囲としてって話なのかも？\\n実際のこういった例を見ないと統計の実際の使い方ってなかなかわからないですよね、、理論は知ってるだけの状態、、', 'すみません、\\n&gt; データ増やしていくと1.7%～14.6%までブレる可能性がある\\nって正しいでしょうか？\\n今の時点では95%の確率で（95なのか主ツイートからわからないですが）その区間に母比率が含まれる、ということだと解釈しました。\\n\\n揚げ足とろうとかそういうわけじゃなく、単に統計に詳しい方がどういう表現するのか知りたかったです。', '結局のところ、真の陽性比率は出てきた数字より高くなることもあるので、外出など控えましょうっていう結論は変わらない（私はこう読み取りました）と思いますが\\nせっかく統計に詳しい方が多いので正確に理解したいと思いまして。', '&gt; 今の時点では95%の確率で（95なのか主ツイートからわからないですが）その区間に母比率が含まれる、ということだと解釈しました。\\n↑そゆことですね。サンプル増やすと収束します。', 'ご本人のレスあったようです↓\\n<https://twitter.com/philomyu/status/1253302456894644224?s=20>', 'あぁなるほど。私もRのBinom.testで何も考えずにやっていたんですが、データが少ない場合は正規近似があまり働かない。で、こういう時は二項分布の自然共役のベータ分布でパラメーターの区間推定を行うってやつっぽいです。確認のため後ほど計算しますが...う〜ん。さっきこれができなかったことにわりかしガチ凹みです...出直してきます', 'いえいえ！即レスしてくださりありがとうございました！', 'Beta分布でもない...!F分布か????', '二項分布で正規近侍を用いるに際して、実用上十分な精度を得るための必要条件はnp&gt;5かつn(1-p)&gt;5である、と統計学入門(p.171)に書かれてるのでn×p_hat=4&lt;5となっているため正規分布による近似は妥当ではないのですね、、何がいいのか、、？？', 'この辺ぽいです。がちょっと別のことしなきゃいけなくて今放置してます。\\n<http://hs-www.hyogo-dai.ac.jp/~kawano/HStat/?plugin=cssj&amp;page=2010%2F11th%2FPopulation_Rate>', 'よく考えたら、Rのソースコード見た方が早いかも..', 'リンク頂いたF分布だと6.12%〜13.118%になりましたね、、これまた、、、、', 'R初触りしちゃうか、、？？眠いから明日かな、、', 'なんかこれ、さっとできる人が増えて欲しいとかいう割には、難易度高くないっすか？（笑）', 'ワカルカボケにわろた', '間違えてた、α=0.025のF分布表の値を使用しなくてはですね、すると上限は0.14586...となり一致しました！\\n下限は相も変わらず6%ほどですが、、', '！すごい！私も後で計算してみます！', '資料にこういうことを普通に書いちゃうから上司に目をつけられる(学べ成長しろ)\\n下限だけどうしても合わないです、、', 'とりあえずボクの計算結果です、もし間違いとか分かったら教えてください、、おやすみなさい、、:zzz:', '<@UT5FYCM6D> 私が送ったソースが誤植です\\nこれで計算が合いました', 'よくよく考えてみると上限の方だけ自由度の使い方が異なるのはおかしい。', 'で、厳密には上記のPLを\\n(1-PL)を下限の区間', '拾いものですが。\\n私もなぜF分布を用いて区間推定が可能なのか、なぜこの式で表すことができるのか、正しく理解できてないので勉強してみようと思います。', 'ちなみに西内さんもR のbinom.testを実行しただけだとおっしゃってました。\\n私も最初その値をみていたので、Rの出力をシェアしておきます。\\nUpper：0.1458632\\nLower：0.0165044', 'ボクもそこ誤植かなと思ってました（n2-&gt;n1）\\nただ、修正しても答えが1.7%にならないのでどうしてかなーと思っていて、今改めて計算してもやはり98.3487….%になってしまいどうして、、？？となっていましたが、これを100%から差し引くと1.7%になるのですね、、、下側確率は分子をn1FL -&gt; n2にすることで正しく求まりそうです！', 'いやほんと勉強になりました。ありがとうございました。', 'ここ（上限/下限関係なく上側確率がこの公式では求まること）に昨日の夜の時点で気付けなかった時点でボクもF分布を使った検定に関してまだまだ勉強不足だと感じさせられました、、Rでの検証ありがとうございます！', 'とりあえずすっきりできてよかった、、笑', 'いやほんとよかったです。\\n特にT検定では等分散の検定で使っていたにもかかわらず、ややこしくて逃げていたんですがちゃんと勉強する気になりましたね。', 'ところで当初の西内さんの問題提起について私なりの解釈を。\\nご本人の意図は聞いてみないとわかないですが、おそらく 4/67 という結果を見た時に上限と加減があるよな。ということに思惑が巡るぐらいのリテラシーがある人が増えたらいいな。ぐらいの意図だと思います。\\nというのも、例えば東京都の人口を下限に当てはめても、罹患人口が約15万人ということになり、とんでもない数字になります。\\nただこれはあまり意味がなくて、大抵の検査はすでに症状がある人達に対して行われており、かつ偽陽性の問題も考慮されていないからです。\\n流石にこの辺りの前提を無視して問題提起をすることはないと思うので、単に統計リテラシーの話なんだろうと理解しました。', '本件クローズだと思うのですが、統計検定のアカウント（？）から回答いただいたので展開します。\\nF分布を利用するのがベストですが、標準正規分布に近似する前提で、母比率を標本比率に近似することを止めたら、\\n2.3% 〜14.4％ となり少しRの出力に近づきました。\\nF分布で表せる理屈は全然理解できていないです:sweat_drops:\\n<https://twitter.com/toukei_kentei/status/1253617059960811521>')\n",
      "('UR',)\n",
      "('村上智之\\u3000ｷﾞﾙﾄﾞ代表\\u3000ﾎﾟｰｶｰで学ぶﾃﾞｰﾀ分析',)\n",
      "('強化学習', '初心者', '初学者', '書籍', '深層学習', 'AI')\n",
      "('みなさんに質問です。\\n強化学習の初心者にお勧めの本ってありますでしょうか。\\n\\n私はというと、最近深層学習のイルカ本や、はじパタを一周して、ある程度数学的な話は聞いたことあるな、というレベル感です。\\n強化学習は完全に初学者なんですが、かといって数学的な考察が無い本はちょっと重みが足りないかなと思っています。\\n\\nもし何かおすすめがあれば教えていただけると幸いです！',)\n",
      "('日本語版出てたと思うのですが、ここら辺とかですかね！\\n\\n<https://www.amazon.co.jp/Bandit-Algorithms-Website-Optimization-Developing-ebook/dp/B00AM86Y0K/ref=sr_1_1?__mk_ja_JP=%E3%82%AB%E3%82%BF%E3%82%AB%E3%83%8A&amp;dchild=1&amp;keywords=John+Myles+White&amp;qid=1587712171&amp;s=digital-text&amp;sr=1-1>', '過去に自分が作った資料です！\\n\\n<https://www.slideshare.net/greenmidori83/ss-28443892>', 'バンディットは強化学習の派生ですが、比較的問題が分かりやすいのでお勧めですー！', 'それとも、深層強化学習文脈です？', 'ありがとうございます！\\nそもそも深層強化学習とか、強化学習に色んなパターンがあることすら知りませんでした。。\\n調べてみたら、深層強化学習が一番興味と近そうです。\\n深層強化学習でおすすめありますでしょうか？？', '<@URXPGQ7U3>\\nあまり読み込んだ物が無いのでどれがおススメかちょっと即答が難しいのですが、Open AI Gymというフレームワークを使っているものが比較的とっつきやすいのでおススメです！\\n\\nまた、chainerRLに関しては比較的分かりやすいのですが、chainer自体が開発終了しているので、こちらをベースにしている書籍などは選ぶのを避けた方が良いという感じですかね。\\n\\nまだまだ新しめの領域なので、Webコンテンツとかの方が情報の鮮度は高くて良いかもしれないです。\\n\\n<https://qiita.com/ishizakiiii/items/75bc2176a1e0b65bdd16>', 'ありがとうございますーー！\\nまずは紹介してもらったやつから見てみます:grinning:')\n",
      "('sho.kumada',)\n",
      "()\n",
      "('Python', 'レコメンド')\n",
      "('レコメンドで使われるMatrix Factorizationについて質問があります。\\nMatrix Factorizationはユーザーが未評価（元の行列で要素が0の箇所）の評価値を予測する手法ですが、\\n\\n①未評価の箇所を0と置いて予測する手法\\n②未評価の箇所を除いたデータで予測する手法\\n\\nの二つがあるようです。以下のサイトを参考に実装したところ、①、②で未評価箇所の予測値が大きく異なりました。\\nPythonでやる場合、`sklearn.decomposition.*NMF*` を使うようですが、デフォルトは①の方法になっているようです。未評価の箇所はあくまで未評価なので、加味しないのが良いと思うのですが、、\\n\\n質問内容は以下のなります。\\n\\n・①はどういう場合（目的）に使うのか？\\n・`sklearn.decomposition.*NMF*` はどういう思想で①をデフォルトにしているのか（使われた方で思い当たる点あれば）\\n\\nよろしくお願いいたします。\\n\\n<https://enjoyworks.jp/tech-blog/633>',)\n",
      "()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/machine_learning/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-33e56bb82cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_talks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_talks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_talks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_ts\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcontainer_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPageDataContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_members\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_members\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-11b8f77c3718>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df_thread)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_members\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_thread\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreply_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#回答したメンバーの表示名のタプル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         self.answer_members = tuple(user for user in df_thread.user_name.unique() \n\u001b[0m\u001b[1;32m     29\u001b[0m                                              if user != df_thread[df_thread.reply_num == 0].user_name[0])\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#会話の中から単語リストに該当する単語のタプル。出現順位順\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-11b8f77c3718>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#回答したメンバーの表示名のタプル\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         self.answer_members = tuple(user for user in df_thread.user_name.unique() \n\u001b[0;32m---> 29\u001b[0;31m                                              if user != df_thread[df_thread.reply_num == 0].user_name[0])\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#会話の中から単語リストに該当する単語のタプル。出現順位順\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         self.tech_topics = tuple(word_tuple[0] for word_tuple in sorted({k: v for k, v in cnt_dict.items()\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/machine_learning/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.3.1/envs/machine_learning/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4410\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4413\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
     ]
    }
   ],
   "source": [
    "input_path = r'../csv/question_talk_data.csv'\n",
    "output_path = r'../xml/temp.xml'\n",
    "\n",
    "df_talks = pd.read_csv(input_path)\n",
    "\n",
    "for ts in df_talks.thread_ts.unique():\n",
    "    df_thread = df_talks[df_talks.thread_ts == ts].reset_index()\n",
    "    container_list = PageDataContainer(df_thread)\n",
    "    '''print(container_list.question_members)\n",
    "    print(container_list.answer_members)\n",
    "    print(container_list.tech_topics)\n",
    "    print(container_list.question_contains)\n",
    "    print(container_list.answer_contains)'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
